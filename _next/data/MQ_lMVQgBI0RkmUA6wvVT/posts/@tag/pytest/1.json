{"pageProps":{"tag":"pytest","page":1,"max_page":1,"tag_counter":[["@all",25],["python",21],["fastapi",14],["sqlmodel",8],["fastapi-users",4],["crud",4],["returns",3],["함수형 프로그래밍",3],["windows",3],["wsl",3],["tdd",2],["anyio",2],["async",2],["vim",1],["js",1],["ts",1],["nextjs",1],["velog",1],["github",1],["restful",1],["pytest",1],["alembic",1],["postgres",1],["black",1],["isort",1],["vscode",1],["asyncio",1],["trio",1]],"posts":[{"name":"fastapi 튜토리얼 -4- pytest 적용 및 실행","content":"\n**`fastapi`** 사용법을 다시 공부할겸, 참고할만한 좋은 [예제](https://www.jeffastor.com/blog/populating-cleaning-jobs-with-user-offers-in-fastapi)가 있어서 이 시리즈를 약간의 변경을 주고 따라가보려 한다.\n지난번처럼 어쩌다 그만둘 수도 있긴 하지만...\n\n---\n\n## `pytest`를 사용한 테스트 코드 작성 및 실행\n\n테스트 코드를 작성하는게 도움이 된다 아니다로 많이 싸우지만, 적어도 **jeffastor** 자신은 이 과정 자체를 즐기고 있다고 밝히며, **`pytest`** 를 적용하는데 한 챕터를 할애한다.\n\n### 패키지 설치\n\n우선 테스트 코드 종속성 패키지부터 설치한다.\n\n```bash\n❯ poetry add --dev pytest pytest-asyncio httpx asgi-lifespan\n```\n\n> **`pytest-asyncio`** 는 비동기로 작성된 api를 테스트하는데 사용하고, **asgi-lifespan`** 은 앱을 실행하지 않고 테스트하기 위해 사용한다.\n\n그리고 이제 **`pytest`** 가 **`docker`** 에서 실행될 수 있게, 개발용 종속성 패키지도 **`docker`** 이미지를 빌드과정에 추가한다.\n\n```bash\n❯ poetry export -f requirements.txt --output backend/requirements.txt --without-hashes --dev\n❯ docker-compose build\n```\n\n### `pytest` 설정 파일 작성\n\n이제 기본적인 테스트 코드를 작성한다.\n\n```bash\n❯ touch backend/tests/__init__.py backend/tests/conftest.py backend/tests/test_cleanings.py\n```\n\n```python\n# backend/tests/conftest.py\nimport os\nimport warnings\nfrom typing import AsyncIterator\n\nimport alembic\nimport pytest\nfrom alembic.config import Config\nfrom asgi_lifespan import LifespanManager\nfrom fastapi import FastAPI\nfrom httpx import AsyncClient\nfrom sqlalchemy.ext.asyncio.engine import AsyncEngine\nfrom sqlmodel.ext.asyncio.session import AsyncSession\n\n\n# Apply migrations at beginning and end of testing session\n@pytest.fixture(scope=\"session\")\ndef apply_migrations():\n    warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n    os.environ[\"TESTING\"] = \"1\"\n    config = Config(\"alembic.ini\")\n\n    alembic.command.upgrade(config, \"head\")  # type: ignore\n    yield\n    alembic.command.downgrade(config, \"base\")  # type: ignore\n\n\n# Create a new application for testing\n@pytest.fixture\ndef app(apply_migrations: None) -> FastAPI:\n    from app.api.server import get_application\n\n    return get_application()\n\n\n# Grab a reference to our database when needed\n@pytest.fixture\ndef engine(app: FastAPI) -> AsyncEngine:\n    return app.state._db\n\n\n@pytest.fixture\nasync def session(engine: AsyncEngine) -> AsyncSession:\n    session = AsyncSession(engine, autoflush=False, autocommit=False)\n    try:\n        return session\n    finally:\n        await session.close()\n\n\n# Make requests in our tests\n@pytest.fixture\nasync def client(app: FastAPI) -> AsyncIterator[AsyncClient]:\n    async with LifespanManager(app):\n        async with AsyncClient(\n            app=app,\n            base_url=\"http://testserver\",\n            headers={\"Content-Type\": \"application/json\"},\n        ) as client:\n            yield client\n\n```\n\n[원문](https://www.jeffastor.com/blog/testing-fastapi-endpoints-with-docker-and-pytest)에 설명이 꽤 있으니 읽어보면 좋을듯.\n\n### 테스트 데이터베이스 엔진 및 마이그레이션 설정\n\n추가로 테스트 환경에서 정상적으로 작동하도록, 기존에 작성한 모듈을 수정한다.\n\n```python\n# backend/app/db/engine.py\nfrom os import getenv\n\nfrom sqlalchemy.engine.url import URL\nfrom sqlalchemy.ext.asyncio import AsyncEngine, create_async_engine\nfrom sqlalchemy.pool import QueuePool\n\nfrom ..core.config import DATABASE_URL\n\n\ndef is_test() -> bool:\n    return (env_val := getenv(\"TESTING\", None)) is not None and bool(env_val)\n\n\ndef get_test_url(url: URL) -> URL:\n    if url.database is None:\n        raise ValueError(\"database name is None\")\n\n    return url.set(database=f\"{url.database}_test\")\n\n\ndef get_test_engine(engine: AsyncEngine) -> AsyncEngine:\n    if not is_test():\n        return engine\n    return create_engine_from_url(get_test_url(engine.url))\n\n\ndef create_engine_from_url(url: str | URL, **kwargs: Any) -> AsyncEngine:\n    return create_async_engine(\n        url, pool_size=10, poolclass=QueuePool, pool_pre_ping=True, **kwargs\n    )\n\n\nengine = create_engine_from_url(DATABASE_URL)\n```\n\n```python\n# backend/app/db/tasks.py\n(...)\n\nfrom .engine import engine, get_test_engine\n\n(...)\n\nasync def connect_to_db(app: FastAPI) -> None:\n    _engine = get_test_engine(engine)\n\n    try:\n        async with _engine.connect():\n            logger.info(\n                f\"connected db: {_engine.url.render_as_string(hide_password=True)}\"\n            )\n        app.state._db = _engine\n    except Exception as e:\n        logger.warning(\"--- DB CONNECTION ERROR ---\")\n        logger.warning(e)\n        logger.warning(\"--- DB CONNECTION ERROR ---\")\n\n(...)\n```\n\n```python\n# backend/app/db/migrations/env.py\nimport asyncio\nimport logging\nimport pathlib\nimport sys\nfrom logging.config import fileConfig\nfrom typing import cast\n\nfrom alembic import context\nfrom sqlalchemy import engine_from_config, pool\nfrom sqlalchemy.exc import InvalidRequestError\nfrom sqlalchemy.ext.asyncio import AsyncEngine\nfrom sqlalchemy.future.engine import Engine\n\nsys.path.append(str(pathlib.Path(__file__).resolve().parents[3]))\nfrom app.db.engine import engine, get_test_url, is_test\n\n# this is the Alembic Config object, which provides\n# access to the values within the .ini file in use.\nconfig = context.config\n\n# Interpret the config file for Python logging.\n# This line sets up loggers basically.\nif config.config_file_name is not None:\n    fileConfig(config.config_file_name)\nlogger = logging.getLogger(\"alembic.env\")\n\n# add your model's MetaData object here\n# for 'autogenerate' support\n# from myapp import mymodel\n# target_metadata = mymodel.Base.metadata\ntarget_metadata = None\n\n# other values from the config, defined by the needs of env.py,\n# can be acquired:\n# my_important_option = config.get_main_option(\"my_important_option\")\n# ... etc.\n\n\ndef run_migrations_offline():\n    \"\"\"Run migrations in 'offline' mode.\n\n    This configures the context with just a URL\n    and not an Engine, though an Engine is acceptable\n    here as well.  By skipping the Engine creation\n    we don't even need a DBAPI to be available.\n\n    Calls to context.execute() here emit the given string to the\n    script output.\n\n    \"\"\"\n    if is_test():\n        raise InvalidRequestError(\n            \"Running testing migrations offline currently not permitted.\"\n        )\n\n    # url = config.get_main_option(\"sqlalchemy.url\")\n    context.configure(\n        # url=url,\n        url=engine.url.render_as_string(hide_password=False),\n        target_metadata=target_metadata,\n        literal_binds=True,\n        dialect_opts={\"paramstyle\": \"named\"},\n    )\n\n    with context.begin_transaction():\n        context.run_migrations()\n\n\ndef do_run_migrations(connection):\n    context.configure(connection=connection, target_metadata=target_metadata)\n\n    with context.begin_transaction():\n        context.run_migrations()\n\n\nasync def run_migrations_online():\n    \"\"\"Run migrations in 'online' mode.\n\n    In this scenario we need to create an Engine\n    and associate a connection with the context.\n\n    \"\"\"\n    url = engine.url\n    if is_test():\n        from sqlalchemy import text\n\n        url = get_test_url(url)\n        async with engine.connect() as conn:\n            conn = await conn.execution_options(isolation_level=\"AUTOCOMMIT\")\n            await conn.execute(text(f\"drop database if exists {url.database}\"))\n            await conn.execute(text(f\"create database {url.database}\"))\n\n    config.set_main_option(\"sqlalchemy.url\", url.render_as_string(hide_password=False))\n    connectable = AsyncEngine(\n        cast(\n            Engine,\n            engine_from_config(\n                config.get_section(config.config_ini_section),\n                prefix=\"sqlalchemy.\",\n                poolclass=pool.NullPool,\n                future=True,\n            ),\n        )\n    )\n\n    async with connectable.connect() as connection:\n        await connection.run_sync(do_run_migrations)\n\n    await connectable.dispose()\n\n\nif context.is_offline_mode():\n    logger.info(\"Running migrations offline\")\n    run_migrations_offline()\nelse:\n    logger.info(\"Running migrations online\")\n    asyncio.run(run_migrations_online())\n```\n\n이제 `TESTING`이라는 환경변수 값이 정상적으로 입력되어 있다면 테스트 DB를 사용한다. 또한, 마이그레이션시 테스트 DB가 이미 생성되어 있다면, 해당 DB를 지우고 새로 생성한다.\n\n### 테스트 코드 작성\n\n이제 이전에 작성한 라우터를 테스트 하는 테스트 코드를 작성한다.\n\n```python\n# backend/tests/test_cleanings.py\nimport pytest\nfrom fastapi import FastAPI\nfrom httpx import AsyncClient\nfrom starlette.status import HTTP_404_NOT_FOUND, HTTP_422_UNPROCESSABLE_ENTITY\n\n\nclass TestCleaningsRoutes:\n    @pytest.mark.asyncio\n    async def test_routes_exist(self, app: FastAPI, client: AsyncClient) -> None:\n        res = await client.post(app.url_path_for(\"cleanings:create-cleaning\"), json={})\n        assert res.status_code != HTTP_404_NOT_FOUND\n\n    @pytest.mark.asyncio\n    async def test_invalid_input_raises_error(\n        self, app: FastAPI, client: AsyncClient\n    ) -> None:\n        res = await client.post(app.url_path_for(\"cleanings:create-cleaning\"), json={})\n        assert res.status_code != HTTP_422_UNPROCESSABLE_ENTITY\n```\n\n이 테스트 코드는 우선 이전 챕터에서 작성한 `cleanings:create-cleaning` api가 존재하는지, 그리고 정상적으로 작동하는지 확인한다.\n\n이전에 어떻게 사용되는지 몰랐던 `conftest.py`에서 `pytest.fixture`로 데코레이트된 함수 `app`, `client`가 여기서 사용된다. `TestCleaningsRoutes`의 각 메소드의 파라미터와 이름이 일치하는 함수를 호출하여, 리턴값을 파라미터로 사용한다.\n\n`TestCleaningsRoutes.test_invalid_input_raises_error`에서 `json` 파라미터로 빈 딕셔너리를 제공했기에, 이전에 작성한 모델인 `cleaning_create`의 필수 값인 `name`과 `price`이 없어서 에러가 발생할 것으로 예상된다.\n\n이제 실제로 테스트를 실행해본다.\n\n```bash\nroot@3190a4d68f18:/backend# pytest -v\n==================================================== test session starts =====================================================\nplatform linux -- Python 3.10.4, pytest-7.1.2, pluggy-1.0.0 -- /usr/local/bin/python\ncachedir: .pytest_cache\nrootdir: /backend\nplugins: anyio-3.5.0, asyncio-0.18.3\nasyncio: mode=legacy\ncollected 2 items\n\ntests/test_cleanings.py::TestCleaningsRoutes::test_routes_exist PASSED                                                 [ 50%]\ntests/test_cleanings.py::TestCleaningsRoutes::test_invalid_input_raises_error FAILED                                   [100%]\ntests/test_cleanings.py::TestCleaningsRoutes::test_invalid_input_raises_error ERROR                                    [100%]\n\n=========================================================== ERRORS ===========================================================\n__________________________ ERROR at teardown of TestCleaningsRoutes.test_invalid_input_raises_error __________________________\n\n    @pytest.fixture(scope=\"session\")\n    def apply_migrations():\n        warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n        os.environ[\"TESTING\"] = \"1\"\n        config = Config(\"alembic.ini\")\n\n        alembic.command.upgrade(config, \"head\")  # type: ignore\n        yield\n>       alembic.command.downgrade(config, \"base\")  # type: ignore\n\ntests/conftest.py:24:\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n(...)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n>   ???\nE   RuntimeError: Task <Task pending name='Task-20' coro=<run_migrations_online() running at /backend/./app/db/migrations/env.py:88> cb=[_run_until_complete_cb() at /usr/local/lib/python3.10/asyncio/base_events.py:184]> got Future <Future pending cb=[Protocol._on_waiter_completed()]> attached to a different loop\n\nasyncpg/protocol/protocol.pyx:338: RuntimeError\n-------------------------------------------------- Captured stderr teardown --------------------------------------------------\nINFO  [alembic.env] Running migrations online\n========================================================== FAILURES ==========================================================\n____________________________________ TestCleaningsRoutes.test_invalid_input_raises_error _____________________________________\n\nself = <tests.test_cleanings.TestCleaningsRoutes object at 0x7fc9e092b610>\napp = <fastapi.applications.FastAPI object at 0x7fc9e0928eb0>, client = <httpx.AsyncClient object at 0x7fc9df873640>\n\n    @pytest.mark.asyncio\n    async def test_invalid_input_raises_error(\n        self, app: FastAPI, client: AsyncClient\n    ) -> None:\n        res = await client.post(app.url_path_for(\"cleanings:create-cleaning\"), json={})\n>       assert res.status_code != HTTP_422_UNPROCESSABLE_ENTITY\nE       assert 422 != 422\nE        +  where 422 = <Response [422 Unprocessable Entity]>.status_code\n\ntests/test_cleanings.py:18: AssertionError\n====================================================== warnings summary ======================================================\n../usr/local/lib/python3.10/site-packages/pytest_asyncio/plugin.py:191\n  /usr/local/lib/python3.10/site-packages/pytest_asyncio/plugin.py:191: DeprecationWarning: The 'asyncio_mode' default value will change to 'strict' in future, please explicitly use 'asyncio_mode=strict' or 'asyncio_mode=auto' in pytest configuration file.\n    config.issue_config_time_warning(LEGACY_MODE, stacklevel=2)\n\n../usr/local/lib/python3.10/site-packages/pytest_asyncio/plugin.py:230\n  /usr/local/lib/python3.10/site-packages/pytest_asyncio/plugin.py:230: DeprecationWarning: '@pytest.fixture' is applied to <fixture client, file=/backend/tests/conftest.py, line=42> in 'legacy' mode, please replace it with '@pytest_asyncio.fixture' as a preparation for switching to 'strict' mode (or use 'auto' mode to seamlessly handle all these fixtures as asyncio-driven).\n    warnings.warn(\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n================================================== short test summary info ===================================================\nFAILED tests/test_cleanings.py::TestCleaningsRoutes::test_invalid_input_raises_error - assert 422 != 422\nERROR tests/test_cleanings.py::TestCleaningsRoutes::test_invalid_input_raises_error - RuntimeError: Task <Task pending name...\n====================================== 1 failed, 1 passed, 2 warnings, 1 error in 0.44s ======================================\nsys:1: SAWarning: The garbage collector is trying to clean up connection <AdaptedConnection <asyncpg.connection.Connection object at 0x7fc9e082a6c0>>. This feature is unsupported on async dbapi, since no IO can be performed at this stage to reset the connection. Please close out all connections when they are no longer used, calling ``close()`` or using a context manager to manage their lifetime.\n```\n\n예상했던 첫번째와 달리, 두번째 에러가 당황스럽다. 확인해보니 비동기 엔진을 **`pytest`** 에서 사용할 때, 이벤트 루프 때문에 런타임 에러가 발생했다. **`pytest`** 에 익숙하지 않기에, 해결할 방법 또한 당장 알아내기가 어렵다. 급한대로 **`alembic`** 사용시 동기 엔진을 사용하기로 했다.\n\n```bash\n❯ poetry add --dev psycopg2-binary\n❯ poetry export -f requirements.txt --output backend/requirements.txt --without-hashes --dev\n❯ docker-compose build\n```\n\n```python\n# backend/app/db/engine.py\nfrom os import getenv\nfrom typing import Any, Literal, overload\n\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.engine.url import URL\nfrom sqlalchemy.ext.asyncio import AsyncEngine, create_async_engine\nfrom sqlalchemy.future.engine import Engine\nfrom sqlalchemy.pool import QueuePool\n\nfrom ..core.config import DATABASE_URL\n\n\ndef is_test() -> bool:\n    return (env_val := getenv(\"TESTING\", None)) is not None and bool(env_val)\n\n\ndef get_test_url(url: URL) -> URL:\n    if url.database is None:\n        raise ValueError(\"database name is None\")\n\n    return url.set(database=f\"{url.database}_test\")\n\n\ndef get_engine_kwargs(**kwargs: Any) -> dict[str, Any]:\n    return {\n        \"pool_size\": 10,\n        \"poolclass\": QueuePool,\n        \"pool_pre_ping\": True,\n        \"future\": True,\n    } | kwargs\n\n\n@overload\ndef get_test_engine(engine: AsyncEngine) -> AsyncEngine:\n    ...\n\n\n@overload\ndef get_test_engine(engine: AsyncEngine, is_sync: Literal[True] = ...) -> Engine:\n    ...\n\n\n@overload\ndef get_test_engine(engine: AsyncEngine, is_sync: Literal[False] = ...) -> AsyncEngine:\n    ...\n\n\n@overload\ndef get_test_engine(engine: AsyncEngine, is_sync: bool = ...) -> AsyncEngine | Engine:\n    ...\n\n\ndef get_test_engine(engine: AsyncEngine, is_sync: bool = False) -> AsyncEngine | Engine:\n    if is_test():\n        engine = create_engine_from_url(\n            get_test_url(engine.url), pool_pre_ping=pool_pre_ping\n        )\n\n    if is_sync:\n        return convert_async_to_sync(engine)\n    return engine\n\n\ndef convert_async_to_sync(engine: AsyncEngine, **kwargs: Any) -> Engine:\n    return create_sync_engine_from_url(\n        engine.url.set(drivername=engine.url.drivername.split(\"+\")[0]), **kwargs\n    )\n\n\ndef create_sync_engine_from_url(url: str | URL, **kwargs: Any) -> Engine:\n    return create_engine(url, **get_engine_kwargs(**kwargs))\n\n\ndef create_engine_from_url(url: str | URL, **kwargs: Any) -> AsyncEngine:\n    return create_async_engine(url, **get_engine_kwargs(**kwargs))\n\n\nengine = create_engine_from_url(DATABASE_URL)\n```\n\n```python\n# backend/app/db/migrations/env.py\nimport logging\nimport pathlib\nimport sys\nfrom logging.config import fileConfig\n\nfrom alembic import context\nfrom sqlalchemy import engine_from_config, pool\nfrom sqlalchemy.exc import InvalidRequestError\n\nsys.path.append(str(pathlib.Path(__file__).resolve().parents[3]))\nfrom app.db.engine import engine, get_test_engine, is_test\n\n# this is the Alembic Config object, which provides\n# access to the values within the .ini file in use.\nconfig = context.config\n\n# Interpret the config file for Python logging.\n# This line sets up loggers basically.\nif config.config_file_name is not None:\n    fileConfig(config.config_file_name)\nlogger = logging.getLogger(\"alembic.env\")\n\n# add your model's MetaData object here\n# for 'autogenerate' support\n# from myapp import mymodel\n# target_metadata = mymodel.Base.metadata\ntarget_metadata = None\n\n# other values from the config, defined by the needs of env.py,\n# can be acquired:\n# my_important_option = config.get_main_option(\"my_important_option\")\n# ... etc.\n\n\ndef run_migrations_offline():\n    \"\"\"Run migrations in 'offline' mode.\n\n    This configures the context with just a URL\n    and not an Engine, though an Engine is acceptable\n    here as well.  By skipping the Engine creation\n    we don't even need a DBAPI to be available.\n\n    Calls to context.execute() here emit the given string to the\n    script output.\n\n    \"\"\"\n    if is_test():\n        raise InvalidRequestError(\n            \"Running testing migrations offline currently not permitted.\"\n        )\n\n    # url = config.get_main_option(\"sqlalchemy.url\")\n    context.configure(\n        # url=url,\n        url=engine.url.render_as_string(hide_password=False),\n        target_metadata=target_metadata,\n        literal_binds=True,\n        dialect_opts={\"paramstyle\": \"named\"},\n    )\n\n    with context.begin_transaction():\n        context.run_migrations()\n\n\ndef do_run_migrations(connection):\n    context.configure(connection=connection, target_metadata=target_metadata)\n\n    with context.begin_transaction():\n        context.run_migrations()\n\n\ndef run_migrations_online():\n    \"\"\"Run migrations in 'online' mode.\n\n    In this scenario we need to create an Engine\n    and associate a connection with the context.\n\n    \"\"\"\n    _engine = get_test_engine(engine, is_sync=True)\n    url = _engine.url\n\n    if is_test():\n        from sqlalchemy import text\n\n        with _engine.connect() as conn:\n            conn = conn.execution_options(isolation_level=\"AUTOCOMMIT\")\n            conn.execute(text(f\"drop database if exists {url.database}\"))\n            conn.execute(text(f\"create database {url.database}\"))\n\n    config.set_main_option(\"sqlalchemy.url\", url.render_as_string(hide_password=False))\n    connectable = engine_from_config(\n        config.get_section(config.config_ini_section),\n        prefix=\"sqlalchemy.\",\n        poolclass=pool.NullPool,\n        future=True,\n    )\n\n    with connectable.connect() as connection:\n        do_run_migrations(connection)\n\n    connectable.dispose()\n\n\nif context.is_offline_mode():\n    logger.info(\"Running migrations offline\")\n    run_migrations_offline()\nelse:\n    logger.info(\"Running migrations online\")\n    run_migrations_online()\n```\n\n이제 다시 **`pytest`** 를 실행해보면\n\n```bash\n(...)\n\n================================================== short test summary info ===================================================\nFAILED tests/test_cleanings.py::TestCleaningsRoutes::test_invalid_input_raises_error - assert 422 != 422\n================================================ 1 failed, 1 passed in 0.35s =================================================\n```\n\n정상적으로 2번째 메소드만 에러를 발생시킨다.\n이제 이전에 작성한 **POST** api에 대한 테스트 코드를 작성해보자.\n\n```python\n# backend/app/models/cleaning.py\n(...)\n\nclass cleaning_update(cleaning_base):\n    cleaning_type: cleaning_type_enum | None = None\n\n(...)\n```\n\n```python\n# backend/tests/test_cleanings.py\nimport orjson\nimport pytest\nfrom app.models.cleaning import cleaning_create\nfrom fastapi import FastAPI\nfrom httpx import AsyncClient\nfrom starlette.status import (\n    HTTP_201_CREATED,\n    HTTP_404_NOT_FOUND,\n    HTTP_422_UNPROCESSABLE_ENTITY,\n)\n\n# decorate all tests with @pytest.mark.asyncio\npytestmark = pytest.mark.asyncio\n\n\n@pytest.fixture\ndef new_cleaning():\n    return cleaning_create.parse_obj(\n        dict(\n            name=\"test cleaning\",\n            description=\"test description\",\n            price=0.00,\n            cleaning_type=\"spot_clean\",\n        )\n    )\n\n\nclass TestCleaningsRoutes:\n    async def test_routes_exist(self, app: FastAPI, client: AsyncClient) -> None:\n        res = await client.post(app.url_path_for(\"cleanings:create-cleaning\"), json={})\n        assert res.status_code != HTTP_404_NOT_FOUND\n\n    async def test_invalid_input_raises_error(\n        self, app: FastAPI, client: AsyncClient\n    ) -> None:\n        res = await client.post(app.url_path_for(\"cleanings:create-cleaning\"), json={})\n        assert res.status_code == HTTP_422_UNPROCESSABLE_ENTITY\n\n\nclass TestCreateCleaning:\n    async def test_valid_input_creates_cleaning(\n        self, app: FastAPI, client: AsyncClient, new_cleaning: cleaning_create\n    ) -> None:\n        res = await client.post(\n            app.url_path_for(\"cleanings:create-cleaning\"),\n            json={\"new_cleaning\": orjson.loads(new_cleaning.json())},\n        )\n        assert res.status_code == HTTP_201_CREATED\n\n        created_cleaning = cleaning_create(**res.json())\n        assert created_cleaning == new_cleaning\n\n    @pytest.mark.parametrize(\n        \"invalid_payload, status_code\",\n        (\n            (None, 422),\n            ({}, 422),\n            ({\"name\": \"test_name\"}, 422),\n            ({\"price\": 10.00}, 422),\n            ({\"name\": \"test_name\", \"description\": \"test\"}, 422),\n        ),\n    )\n    async def test_invalid_input_raises_error(\n        self, app: FastAPI, client: AsyncClient, invalid_payload: dict, status_code: int\n    ) -> None:\n        res = await client.post(\n            app.url_path_for(\"cleanings:create-cleaning\"),\n            json={\"new_cleaning\": invalid_payload},\n        )\n        assert res.status_code == status_code\n```\n\n`cleanings:create-cleaning` api가 의도한대로 데이터를 추가하고, 반환하는지 확인하는 코드가 추가됐다.\n\n또한, 에러를 발생하는 `body`의 형태와, 그러한 `body`에 대해 기대하는 `status_code`를 지정해서 확인한다.\n\n결과는 다음과 같이 정상적으로 나와야 한다.\n\n```bash\n==================================================== test session starts =====================================================\nplatform linux -- Python 3.10.4, pytest-7.1.2, pluggy-1.0.0 -- /usr/local/bin/python\ncachedir: .pytest_cache\nrootdir: /backend\nplugins: anyio-3.5.0, asyncio-0.18.3\nasyncio: mode=auto\ncollected 8 items\n\ntests/test_cleanings.py::TestCleaningsRoutes::test_routes_exist PASSED                                                 [ 12%]\ntests/test_cleanings.py::TestCleaningsRoutes::test_invalid_input_raises_error PASSED                                   [ 25%]\ntests/test_cleanings.py::TestCreateCleaning::test_valid_input_creates_cleaning PASSED                                  [ 37%]\ntests/test_cleanings.py::TestCreateCleaning::test_invalid_input_raises_error[None-422] PASSED                          [ 50%]\ntests/test_cleanings.py::TestCreateCleaning::test_invalid_input_raises_error[invalid_payload1-422] PASSED              [ 62%]\ntests/test_cleanings.py::TestCreateCleaning::test_invalid_input_raises_error[invalid_payload2-422] PASSED              [ 75%]\ntests/test_cleanings.py::TestCreateCleaning::test_invalid_input_raises_error[invalid_payload3-422] PASSED              [ 87%]\ntests/test_cleanings.py::TestCreateCleaning::test_invalid_input_raises_error[invalid_payload4-422] PASSED              [100%]\n\n===================================================== 8 passed in 0.54s ======================================================\n```\n\n## TDD 방법론에 따른 개발 연습\n\n이제 **`pytest`** 를 사용하는 방식에 대해 어느정도 감이 잡히는 느낌이다.\n**jeffastor**는 이러한 테스트 코드를 이용해서, **TDD**(테스트 주도 개발)을 권장하는 것 같다.\n**TDD**는 다음의 3단계 프로세스를 따른다.\n\n> 1. 실패를 확인할 수 있는 테스트 코드를 작성한다.\n> 2. 테스트 코드를 통과할 수 있도록 코드를 작성한다.\n> 3. 자신이 만족할 수준으로 코드를 수정, 테스트, 리팩토링, 모듈화 등을 실시한다.\n\n### `GET` `api` 생성\n\n위 프로세스를 따라서 **GET** api를 생성해보자.\n\n```python\n# backend/tests/test_cleanings.py\n(...)\n\nfrom app.models.cleaning import cleaning_create, cleanings\nfrom starlette.status import (\n    HTTP_200_OK,\n    HTTP_201_CREATED,\n    HTTP_404_NOT_FOUND,\n    HTTP_422_UNPROCESSABLE_ENTITY,\n)\n\n(...)\n\nclass TestGetCleaning:\n    async def test_get_cleaning_by_id(self, app: FastAPI, client: AsyncClient) -> None:\n        res = await client.get(app.url_path_for(\"cleanings:get-cleaning-by-id\", id=\"1\"))\n        assert res.status_code == HTTP_200_OK\n        cleaning = cleanings(**res.json())\n        assert cleaning.id == 1\n```\n\n작성한 테스트 코드의 `TestGetCleaning.test_get_cleaning_by_id` 메소드를 통과할 수 있도록, **GET** api를 작성해보자.\n\n```python\n# backend/app/api/routes/cleanings.py\nfrom fastapi import APIRouter, Body, Depends, HTTPException, Path\nfrom starlette.status import HTTP_201_CREATED, HTTP_404_NOT_FOUND\n\n(...)\n\n@router.get(\n    \"/{id}\", response_model=cleaning_public, name=\"cleanings:get-cleaning-by-id\"\n)\nasync def get_cleaning_by_id(\n    id: int = Path(..., ge=1),\n    session: AsyncSession = Depends(get_session),\n) -> cleanings:\n    if (cleaning := await session.get(cleanings, id)) is None:\n        raise HTTPException(\n            status_code=HTTP_404_NOT_FOUND, detail=\"No cleaning found with that id.\"\n        )\n    return cleaning\n```\n\n확인해본 결과, 모두 잘 작동한다.\n하지만 테스트 코드에 문제가 있다. `id=1`로 하드코딩된 상태이기 때문. 따라서 하드코딩을 제거하기 위한 새로운 `fixture`를 생성할 필요가 있다.\n\n```python\n# backend/tests/test_cleanings.py\n\n(...)\n\nfrom sqlmodel.ext.asyncio.session import AsyncSession\n\n(...)\n\n@pytest.fixture\nasync def test_cleaning(session: AsyncSession) -> cleanings:\n    new_cleaning_create = cleaning_create.parse_obj(\n        dict(\n            name=\"fake cleaning name\",\n            description=\"fake cleaning description\",\n            price=9.99,\n            cleaning_type=\"spot_clean\",\n        )\n    )\n    new_cleaning = cleanings.from_orm(new_cleaning_create)\n    session.add(new_cleaning)\n    await session.commit()\n    await session.refresh(new_cleaning)\n\n    return new_cleaning\n\n\nclass TestGetCleaning:\n    async def test_get_cleaning_by_id(\n        self, app: FastAPI, client: AsyncClient, test_cleaning: cleanings\n    ) -> None:\n        print(test_cleaning)\n        res = await client.get(\n            app.url_path_for(\"cleanings:get-cleaning-by-id\", id=str(test_cleaning.id))\n        )\n        assert res.status_code == HTTP_200_OK\n        cleaning = cleanings.parse_obj(res.json())\n        assert cleaning == test_cleaning\n```\n\n`refresh` 메소드를 사용하여 정확한 id를 가지고 비교를 해서 에러가 없을거라 생각했는데,\n\n```bash\n================================================== short test summary info ===================================================\nERROR tests/test_cleanings.py::TestGetCleaning::test_get_cleaning_by_id - sqlalchemy.exc.OperationalError: (psycopg2.errors...\n================================================= 9 passed, 1 error in 5.74s =================================================\nsys:1: SAWarning: The garbage collector is trying to clean up connection <AdaptedConnection <asyncpg.connection.Connection object at 0x7fabadaffbc0>>. This feature is unsupported on async dbapi, since no IO can be performed at this stage to reset the connection. Please close out all connections when they are no longer used, calling ``close()`` or using a context manager to manage their lifetime.\n```\n\n**`pytest`** 에서 `fixture`를 생성할 때 연결한 `session`을 제대로 정리하지 않아서 에러가 발생했다. **`pytest`** 에서는 `NullPool`을 사용하고, **`pytest`** 에서 `session` 객체를 `fixture`로 사용하지 않도록 하자.\n\n```python\nfrom sqlalchemy.pool import AsyncAdaptedQueuePool, NullPool, QueuePool\n\n(...)\n\ndef get_engine_kwargs(\n    is_sync: bool, is_test: bool = False, **kwargs: Any\n) -> dict[str, Any]:\n    params: dict[str, Any] = {\"pool_pre_ping\": True, \"future\": True}\n\n    if is_test:\n        params[\"poolclass\"] = NullPool\n    else:\n        params[\"pool_size\"] = 10\n        params[\"poolclass\"] = QueuePool\n\n    return params | kwargs\n\n\n(...)\n\ndef get_test_engine(engine: AsyncEngine, is_sync: bool = False) -> AsyncEngine | Engine:\n    if _is_test := is_test():\n        engine = create_engine_from_url(get_test_url(engine.url), is_test=_is_test)\n\n    if is_sync:\n        return convert_async_to_sync(engine, is_test=_is_test)\n    return engine\n\n(...)\n```\n\n```python\n# backend/tests/conftest.py\nimport os\nimport warnings\nfrom typing import AsyncIterator\n\nimport alembic\nimport pytest\nfrom alembic.config import Config\nfrom asgi_lifespan import LifespanManager\nfrom fastapi import FastAPI\nfrom httpx import AsyncClient\nfrom sqlalchemy.ext.asyncio.engine import AsyncEngine\n\n\n# Apply migrations at beginning and end of testing session\n@pytest.fixture(scope=\"session\")\ndef apply_migrations():\n    warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n    os.environ[\"TESTING\"] = \"1\"\n    config = Config(\"alembic.ini\")\n\n    alembic.command.upgrade(config, \"head\")  # type: ignore\n    yield\n    alembic.command.downgrade(config, \"base\")  # type: ignore\n\n\n# Create a new application for testing\n@pytest.fixture\ndef app(apply_migrations: None) -> FastAPI:\n    from app.api.server import get_application\n\n    return get_application()\n\n\n# Grab a reference to our database when needed\n@pytest.fixture\ndef engine(app: FastAPI) -> AsyncEngine:\n    return app.state._db\n\n\n# Make requests in our tests\n@pytest.fixture\nasync def client(app: FastAPI) -> AsyncIterator[AsyncClient]:\n    async with LifespanManager(app):\n        async with AsyncClient(\n            app=app,\n            base_url=\"http://testserver\",\n            headers={\"Content-Type\": \"application/json\"},\n        ) as client:\n            yield client\n```\n\n```python\n# backend/tests/test_cleanings.py\n(...)\n\nfrom sqlalchemy.ext.asyncio import AsyncEngine\nfrom sqlmodel.ext.asyncio.session import AsyncSession\n\n(...)\n\n@pytest.fixture\nasync def test_cleaning(engine: AsyncEngine) -> cleanings:\n    new_cleaning_create = cleaning_create.parse_obj(\n        dict(\n            name=\"fake cleaning name\",\n            description=\"fake cleaning description\",\n            price=9.99,\n            cleaning_type=\"spot_clean\",\n        )\n    )\n    new_cleaning = cleanings.from_orm(new_cleaning_create)\n    async with AsyncSession(engine, autocommit=False) as session:\n        session.add(new_cleaning)\n        await session.commit()\n        await session.refresh(new_cleaning)\n\n    return new_cleaning\n\n(...)\n```\n\n다시 **`pytest`** 를 실행했을 때, 정상적으로 잘 되는 것을 확인했다.\n\n### `GET` `api`에 유효하지 않은 값에 대한 테스트 코드\n\n이어서, 유효하지 않은 값에 대한 테스트 코드를 추가한다.\n원 예제는 `id=-1`에 대해 404 에러 코드를 반환하지만, 이전에 **GET** api를 정의할 때 `id: int = Path(..., ge=1)` 으로 정의했기에 422에러가 반환된다. 따라서 그 부분만 수정했다.\n\n```python\n# backend/tests/test_cleanings.py\n(...)\n\nclass TestGetCleaning:\n    async def test_get_cleaning_by_id(\n        self, app: FastAPI, client: AsyncClient, test_cleaning: cleanings\n    ) -> None:\n        print(test_cleaning)\n        res = await client.get(\n            app.url_path_for(\"cleanings:get-cleaning-by-id\", id=str(test_cleaning.id))\n        )\n        assert res.status_code == HTTP_200_OK\n        cleaning = cleanings.parse_obj(res.json())\n        assert cleaning == test_cleaning\n\n    @pytest.mark.parametrize(\n        \"id, status_code\",\n        (\n            (500, 404),\n            (-1, 422),\n            (None, 422),\n        ),\n    )\n    async def test_wrong_id_returns_error(\n        self, app: FastAPI, client: AsyncClient, id: int, status_code: int\n    ) -> None:\n        res = await client.get(\n            app.url_path_for(\"cleanings:get-cleaning-by-id\", id=str(id))\n        )\n        assert res.status_code == status_code\n```\n\n테스트시, 별 문제 없이 통과한다.\n\n```bash\nroot@5984264d864d:/backend# pytest -v --asyncio-mode=auto\n==================================================== test session starts =====================================================\nplatform linux -- Python 3.10.4, pytest-7.1.2, pluggy-1.0.0 -- /usr/local/bin/python\ncachedir: .pytest_cache\nrootdir: /backend\nplugins: anyio-3.5.0, asyncio-0.18.3\nasyncio: mode=auto\ncollected 12 items\n\ntests/test_cleanings.py::TestCleaningsRoutes::test_routes_exist PASSED                                                 [  8%]\ntests/test_cleanings.py::TestCleaningsRoutes::test_invalid_input_raises_error PASSED                                   [ 16%]\ntests/test_cleanings.py::TestCreateCleaning::test_valid_input_creates_cleaning PASSED                                  [ 25%]\ntests/test_cleanings.py::TestCreateCleaning::test_invalid_input_raises_error[None-422] PASSED                          [ 33%]\ntests/test_cleanings.py::TestCreateCleaning::test_invalid_input_raises_error[invalid_payload1-422] PASSED              [ 41%]\ntests/test_cleanings.py::TestCreateCleaning::test_invalid_input_raises_error[invalid_payload2-422] PASSED              [ 50%]\ntests/test_cleanings.py::TestCreateCleaning::test_invalid_input_raises_error[invalid_payload3-422] PASSED              [ 58%]\ntests/test_cleanings.py::TestCreateCleaning::test_invalid_input_raises_error[invalid_payload4-422] PASSED              [ 66%]\ntests/test_cleanings.py::TestGetCleaning::test_get_cleaning_by_id PASSED                                               [ 75%]\ntests/test_cleanings.py::TestGetCleaning::test_wrong_id_returns_error[500-404] PASSED                                  [ 83%]\ntests/test_cleanings.py::TestGetCleaning::test_wrong_id_returns_error[-1-422] PASSED                                   [ 91%]\ntests/test_cleanings.py::TestGetCleaning::test_wrong_id_returns_error[None-422] PASSED                                 [100%]\n\n===================================================== 12 passed in 0.86s =====================================================\n```\n\n다음 챕터는 CRUD api를 잘 생성하기 위한 작업으로 보인다.\n","mtime":"2022-08-13T00:12:20.000+09:00","href":"velog/fastapi 튜토리얼 -4- pytest 적용 및 실행","data":{"title":"fastapi 튜토리얼 -4- pytest 적용 및 실행","date":"2022-04-30T02:43:31.082+09:00","tags":["fastapi","tdd","pytest","python","@all"],"page":"fastapi 튜토리얼","summary":"fastapi 사용법을 다시 공부할겸, 참고할만한 좋은 예제가 있어서 이 시리즈를 약간의 변경을 주고 따라가보려 한다."}}]},"__N_SSG":true}