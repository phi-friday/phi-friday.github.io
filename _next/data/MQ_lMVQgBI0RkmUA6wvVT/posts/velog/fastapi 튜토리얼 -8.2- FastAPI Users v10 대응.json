{"pageProps":{"post":{"name":"fastapi íŠœí† ë¦¬ì–¼ -8.2- FastAPI Users v10 ëŒ€ì‘","content":"\n**`fastapi`** ì‚¬ìš©ë²•ì„ ë‹¤ì‹œ ê³µë¶€í• ê²¸, ì°¸ê³ í• ë§Œí•œ ì¢‹ì€ [ì˜ˆì œ](https://www.jeffastor.com/blog/populating-cleaning-jobs-with-user-offers-in-fastapi)ê°€ ìˆì–´ì„œ ì´ ì‹œë¦¬ì¦ˆë¥¼ ì•½ê°„ì˜ ë³€ê²½ì„ ì£¼ê³  ë”°ë¼ê°€ë³´ë ¤ í•œë‹¤.\nì§€ë‚œë²ˆì²˜ëŸ¼ ì–´ì©Œë‹¤ ê·¸ë§Œë‘˜ ìˆ˜ë„ ìˆê¸´ í•˜ì§€ë§Œ...\n\n---\n\n## `Breaking` `changes`\n\nì´í‹€ì „ **`fastapi-users`** ì— í° ë³€í™”ê°€ ìƒê²¼ë‹¤. `v10` ë¦´ë¦¬ì¦ˆê°€ ê³µê°œëëŠ”ë°, `db` ëª¨ë¸ê³¼ ì—¬ëŸ¬ ì œë„¤ë¦­ íƒ€ì…ì— ëŒ€í•œ ë³€í™”ê°€ ìƒê²¨ì„œ, `v10`ì„ ì´ìš©í•˜ë ¤ë©´ ëŒ€ì‘ íŒ¨ì¹˜ê°€ í•„ìˆ˜ì ì¸ ìƒí™©..\n\nì•„ë˜ëŠ” í•´ë‹¹ ë¦´ë¦¬ì¦ˆì— ëŒ€í•œ ì „ë¬¸ì´ë‹¤.\n\n> ### [Breaking changes](https://github.com/fastapi-users/fastapi-users/releases/tag/v10.0.0)\n>\n> Version 10 marks important changes in how we manage User models and their ID.\n>\n> Before, we were relying only on Pydantic models to work with users. In particular the current_user dependency would return you an instance of UserDB, a Pydantic model. This proved to be quite problematic with some ORM if you ever needed to retrieve relationship data or make specific requests.\n>\n> Now, FastAPI Users is designed to always return you a native object for your ORM model, whether it's an SQLAlchemy model or a Beanie document. Pydantic models are now only used for validation and serialization inside the API.\n>\n> Before, we were forcing the use of UUID as primary key ID; a consequence of the design above. This proved to be quite problematic on some databases, like MongoDB which uses a special ObjectID format by default. Some SQL folks also prefer to use traditional auto-increment integers.\n>\n> Now, FastAPI Users is designed to use generic ID type. It means that you can use any type you want for your user's ID. By default, SQLAlchemy adapter still use UUID; but you can quite easily switch to another thing, like an integer. Beanie adapter for MongoDB will use native ObjectID by default, but it also can be overriden.\n\n### ìœ ì € ëª¨ë¸ ìƒì„± ë° ìˆ˜ì •\n\nê¸°ì¡´ `fastapi_users.models` ì—ì„œ `fastapi_users.schemas`ë¡œ ë°”ë€ ê²ƒ ì™¸ì— í¬ê²Œ ë‹¬ë¼ì§„ ê²ƒì€ ì—†ë‹¤. ì‚¬ì‹¤ ì´ì „ì— ì–˜ê¸°í–ˆë˜ `user` ì™€ `user_model`ì„ í†µí•©í•˜ëŠ” ì‘ì—…ì„ ì´ë¯¸ í•œ ë‹¤ìŒ `v10` ë¦´ë¦¬ì¦ˆë¥¼ í™•ì¸í–ˆê¸°ì— ë”ìš± ê·¸ë ‡ê²Œ ëŠê»´ì¡Œë‹¤...\n\n```python\n# backend/app/models/user.py\nfrom typing import TypeVar\n\nfrom fastapi_users import schemas\nfrom pydantic import EmailStr\nfrom pydantic import Field as _Field\nfrom sqlmodel import Field, select\n\nfrom ..db.session import async_session\nfrom .core import base_model, datetime_model, uuid_id_model\n\nmin_name_length = 4\nmax_name_length = 20\n\n\n_T = TypeVar(\"_T\", bound=\"user\")\nid_model = uuid_id_model\nuser_id_type = id_model.id_type\n\n\nclass user(id_model, datetime_model, base_model, table=True):\n    __tablename__: str = \"users\"\n\n    name: str = Field(min_length=min_name_length, max_length=max_name_length)\n    hashed_password: str = Field(max_length=2**10)\n    email: EmailStr = Field(index=True)\n    is_active: bool = True\n    is_superuser: bool = False\n    is_verified: bool = False\n\n    @classmethod\n    async def get_from_email(\n        cls: type[_T], session: async_session, email: str\n    ) -> _T | None:\n        is_user_cur = await session.exec(select(cls).where(cls.email == email))\n        return is_user_cur.first()\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.validate(self)\n\n\nclass user_read(schemas.BaseUser[user_id_type], datetime_model):\n    name: str = _Field(min_length=min_name_length, max_length=max_name_length)\n\n\nclass user_create(schemas.BaseUserCreate):\n    name: str = _Field(min_length=min_name_length, max_length=max_name_length)\n\n\nclass user_update(schemas.BaseUserUpdate):\n    name: str = _Field(min_length=min_name_length, max_length=max_name_length)\n```\n\n### ì¸ì¦ ëª¨ë“ˆ ì œë„¤ë¦­ íƒ€ì… ë®ì–´ì”Œìš°ê¸°\n\n**`fastapi-users`** ì—ì„œ ì›í•˜ëŠ” í˜•íƒœëŠ” `SQLAlchemyBaseUserTable`ë¥¼ ìƒì†í•œ í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ì§€ë§Œ, **`sqlmodel`** ë„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ê³  **`fastapi-users`** ì˜ íƒ€ì… íŒíŠ¸ë„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ê³  ì‹¶ê¸°ì—, ë‘ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì—®ì–´ì¤„ ìƒˆë¡œìš´ ì œë„¤ë¦­ í´ë˜ìŠ¤ë¥¼ ìƒì„±í•œë‹¤.\n`# type: ignore`ë¥¼ ë‚¨ë°œí•˜ê¸°ì— ê·¸ë‹¤ì§€ ì¢‹ì€ ëª¨ìŠµì´ë¼ê³  ìƒê°ë˜ì§€ ì•Šì§€ë§Œ, ì´ê±° ì™¸ì— ë‹¹ì¥ ìƒê°ë‚˜ëŠ” ë°©ë²•ì´ ì—†ê¸°ì— ì¼ë‹¨ ë„˜ì–´ê°€ì.\n\n```bash\nâ¯ mkdir backend/app/services/authentication\nâ¯ mv backend/app/services/authentication.py backend/app/services/authentication/authentication.py\nâ¯ touch backend/app/services/authentication/__init__.py backend/app/services/authentication/convert.py\n```\n\n```python\n# backend/app/services/authentication/__init__.py\nfrom .authentication import *\n```\n\n```python\n# backend/app/services/authentication/convert.py\nfrom typing import Generic, TypeVar\n\nfrom fastapi_users import BaseUserManager, FastAPIUsers\nfrom fastapi_users.authentication import AuthenticationBackend, JWTStrategy, Strategy\nfrom fastapi_users.db import SQLAlchemyUserDatabase\n\nfrom ...models.core import base_model\nfrom ...models.user import user\n\nuser_id_type = user.id_type\n_T = TypeVar(\"_T\", bound=base_model)\n_D = TypeVar(\"_D\")\n\n# fmt: off\nclass user_db_class(SQLAlchemyUserDatabase[_T, _D], Generic[_T, _D]): ... # type: ignore\nclass strategy_class(Strategy[_T, _D], Generic[_T, _D]): ... # type: ignore\nclass jwt_strategy_class(JWTStrategy[_T, _D], Generic[_T, _D]): ... # type: ignore\nclass auth_backend_class(AuthenticationBackend[_T, _D], Generic[_T, _D]): ... # type: ignore\nclass user_manager_class(BaseUserManager[_T, _D], Generic[_T, _D]): ...  # type: ignore\nclass fastapi_users_class(FastAPIUsers[_T, _D], Generic[_T, _D]): ...  # type: ignore\n# fmt: on\n\n\nuser_manager_type = user_manager_class[user, user_id_type]\nstrategy_type = strategy_class[user, user_id_type]\n```\n\n### ë³€ê²½ì  ì¸ì¦ ëª¨ë“ˆì— ì ìš©\n\n```python\n# backend/app/services/authentication/authentication.py\nimport re\nfrom dataclasses import dataclass\nfrom re import Pattern\nfrom typing import AsyncGenerator, Sequence\n\nfrom fastapi import Depends, Request\nfrom fastapi_users import IntegerIDMixin, InvalidPasswordException\nfrom fastapi_users.authentication import BearerTransport, Transport\n\nfrom ...core import config\nfrom ...db.session import async_session, get_session\nfrom ...models import user\nfrom .convert import (\n    auth_backend_class,\n    fastapi_users_class,\n    jwt_strategy_class,\n    strategy_class,\n    strategy_type,\n    user_db_class,\n    user_id_type,\n    user_manager_class,\n    user_manager_type,\n)\n\n\nasync def get_user_db(\n    session: async_session = Depends(get_session),\n) -> AsyncGenerator[user_db_class[user.user, user_id_type], None]:\n    yield user_db_class(session, user.user)\n\n\ndef create_transport() -> Transport:\n    return BearerTransport(tokenUrl=config.TOKEN_PREFIX)\n\n\ndef create_strategy() -> strategy_class[user.user, user_id_type]:\n    return jwt_strategy_class(  # type: ignore\n        secret=str(config.SECRET_KEY),\n        lifetime_seconds=config.ACCESS_TOKEN_EXPIRE_SECONDS,\n        token_audience=[config.JWT_AUDIENCE],\n        algorithm=config.JWT_ALGORITHM,\n    )\n\n\ndef create_backend() -> list[auth_backend_class[user.user, user_id_type]]:\n    transport = create_transport()\n    return [\n        auth_backend_class(\n            name=config.AUTH_BACKEND_NAME,\n            transport=transport,\n            get_strategy=create_strategy,\n        )\n    ]\n\n\nclass UserManager(IntegerIDMixin, user_manager_class[user.user, user_id_type]):\n    reset_password_token_secret = str(config.SECRET_KEY)\n    verification_token_secret = str(config.SECRET_KEY)\n\n    min_password_length: int = 10\n    max_password_length: int = 30\n    re_password_need_list: list[Pattern] = [\n        re.compile(r\"[a-zA-Z]\"),\n        re.compile(r\"[0-9]\"),\n        re.compile(r\"[\\{\\}\\[\\]\\/?.,;:|\\)*~`!^\\-_+<>@\\#$%&\\\\\\=\\(\\'\\\"]\"),\n    ]\n    re_password_deny_list: list[Pattern] = []\n\n    async def validate_password(\n        self, password: str, user: user.user_create | user.user\n    ) -> None:\n        if len(password) < self.min_password_length:\n            raise InvalidPasswordException(\n                reason=f\"Password should be at least {self.min_password_length} characters\"\n            )\n        elif len(password) > self.max_password_length:\n            raise InvalidPasswordException(\n                reason=f\"Password should be at most {self.max_password_length} characters\"\n            )\n\n        for pattern in self.re_password_deny_list:\n            if pattern.search(password):\n                raise InvalidPasswordException(\n                    reason=f\"Password should not include {pattern.pattern}\"\n                )\n\n        for pattern in self.re_password_need_list:\n            if not pattern.search(password):\n                raise InvalidPasswordException(\n                    reason=f\"Password must include {pattern.pattern}\"\n                )\n\n    async def on_after_register(self, user: user.user, request: Request | None = None):\n        print(f\"User {user.id} has registered.\")\n\n    async def on_after_forgot_password(\n        self, user: user.user, token: str, request: Request | None = None\n    ):\n        print(f\"User {user.id} has forgot their password. Reset token: {token}\")\n\n    async def on_after_request_verify(\n        self, user: user.user, token: str, request: Request | None = None\n    ):\n        print(f\"Verification requested for user {user.id}. Verification token: {token}\")\n\n\nasync def get_user_manager(\n    user_db=Depends(get_user_db),\n) -> AsyncGenerator[UserManager, None]:\n    yield UserManager(user_db)\n\n\ndef create_fastapi_users(\n    *backends: auth_backend_class[user.user, user_id_type],\n) -> fastapi_users_class[user.user, user_id_type]:\n    return fastapi_users_class(\n        get_user_manager=get_user_manager, auth_backends=backends\n    )\n\n\n@dataclass(frozen=True)\nclass fastapi_user_class:\n    users: fastapi_users_class[user.user, user_id_type]\n\n    @classmethod\n    def init(cls) -> \"fastapi_user_class\":\n        users = create_fastapi_users(*create_backend())\n        return cls(users=users)\n\n    @property\n    def backends(self) -> Sequence[auth_backend_class[user.user, user_id_type]]:\n        return self.users.authenticator.backends  # type: ignore\n\n    @property\n    def user_manager_depends(self) -> user_manager_type:\n        return Depends(self.users.get_user_manager)\n\n    def strategy_depends(self, num: int = 0, /) -> strategy_type:\n        backend = self.backends[num]\n        return Depends(backend.get_strategy)\n```\n\nê½¤ ë§ì´ ë°”ë€Œê¸´ í–ˆì§€ë§Œ, ì‹¤ì œë¡œ ì‚¬ìš©í• ë•ŒëŠ” ì´ë¦„ì •ë„ë§Œ ë°”ë€Œì§€ ì‚¬ìš©ë²• ìì²´ëŠ” ë³€í•œê²Œ ì—†ë‹¤. ë°”ë€ ì´ë¦„ì— ë§ì¶°ì„œ ë¼ìš°í„°ì™€ í…ŒìŠ¤íŠ¸ ì½”ë“œë¥¼ ìˆ˜ì •í•´ì£¼ë©´, ì •ìƒì ìœ¼ë¡œ ì‘ë™í•˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.\n\nì´ë²ˆ ê¸°íšŒì— í…ŒìŠ¤íŠ¸ ì½”ë“œê°€ ì–¼ë§ˆë‚˜ ì¢‹ì€ê±´ì§€ ì•Œê²Œëë‹¤.. ê¸´ê°€ë¯¼ê°€í• ë•Œ `pytest --tb=short` í•œë°©ì´ë©´ ì˜ë¬¸ì´ í•´ê²°ëœë‹¤.\n\nì‚¬ì‹¤ ë³€ê²½í• ê²Œ í•˜ë‚˜ ë” ë‚¨ê¸´ í–ˆì§€ë§Œ, ì´ê±° ì•„ì§ ì‹œë„í•´ë³´ì§€ ì•Šì•˜ë‹¤.\ní˜„ì¬ í—¤ë”ë¥¼ ì‚¬ìš©í•œ ì¸ì¦ ë°©ì‹ì¸ë°, ì¿ í‚¤ë¥¼ ì‚¬ìš©í•˜ê³ , `access-token`ê³¼ `refresh-token`ì„ ì‚¬ìš©í•œ ë°©ì‹ìœ¼ë¡œ ë³€ê²½í•´ë³´ë ¤ í•œë‹¤. ë‹¤ë§Œ **`fastapi-users`** ìì²´ì ìœ¼ë¡œëŠ” ì§€ì›í•˜ì§€ ì•Šê¸°ì—, ì§ì ‘ ì‘ì„±í•  í•„ìš”ê°€ ìˆì–´ì„œ ì•½ê°„ ê³ ë¯¼ì´ í•„ìš”í• ë“¯.\n","mtime":"2022-08-13T00:12:20.000+09:00","href":"velog/fastapi íŠœí† ë¦¬ì–¼ -8.2- FastAPI Users v10 ëŒ€ì‘","data":{"title":"fastapi íŠœí† ë¦¬ì–¼ -8.2- FastAPI Users v10 ëŒ€ì‘","date":"2022-05-07T23:00:58.369+09:00","tags":["fastapi","fastapi-users","python","sqlmodel","@all"],"page":"fastapi íŠœí† ë¦¬ì–¼","summary":"fastapi ì‚¬ìš©ë²•ì„ ë‹¤ì‹œ ê³µë¶€í• ê²¸, ì°¸ê³ í• ë§Œí•œ ì¢‹ì€ ì˜ˆì œê°€ ìˆì–´ì„œ ì´ ì‹œë¦¬ì¦ˆë¥¼ ì•½ê°„ì˜ ë³€ê²½ì„ ì£¼ê³  ë”°ë¼ê°€ë³´ë ¤ í•œë‹¤."}},"prev_post":{"name":"fastapi íŠœí† ë¦¬ì–¼ -8.1- SQLModel AsyncSession ê´€ë ¨ íƒ€ì… ë¬¸ì œ ì„ì‹œ í•´ê²° + ì¶”ê°€ ìˆ˜ì •","content":"\n**`fastapi`** ì‚¬ìš©ë²•ì„ ë‹¤ì‹œ ê³µë¶€í• ê²¸, ì°¸ê³ í• ë§Œí•œ ì¢‹ì€ [ì˜ˆì œ](https://www.jeffastor.com/blog/populating-cleaning-jobs-with-user-offers-in-fastapi)ê°€ ìˆì–´ì„œ ì´ ì‹œë¦¬ì¦ˆë¥¼ ì•½ê°„ì˜ ë³€ê²½ì„ ì£¼ê³  ë”°ë¼ê°€ë³´ë ¤ í•œë‹¤.\nì§€ë‚œë²ˆì²˜ëŸ¼ ì–´ì©Œë‹¤ ê·¸ë§Œë‘˜ ìˆ˜ë„ ìˆê¸´ í•˜ì§€ë§Œ...\n\n---\n\n## `Session`ì˜ ì½”ë“œë¥¼ ê·¸ëŒ€ë¡œ ë³µë¶™\n\nì´ì „ê¹Œì§€ ê¸€ì—ì„œ ê³„ì†í•´ì„œ `AsyncSession`ì˜ íƒ€ì… ê´€ë ¨ ë¬¸ì œê°€ ë°œìƒí•˜ëŠ”ê²Œ ë„ˆë¬´ ì§œì¦ë‚˜ì„œ, ì„ì‹œë¡œ ë•œë¹µìš© í´ë˜ìŠ¤ë¥¼ ìƒì„±í•´ì„œ ì‚¬ìš©í•˜ê¸°ë¡œ í–ˆë‹¤.\n\n````python\n# backend/app/db/session.py\n(...)\n\n_TSelectParam = TypeVar(\"_TSelectParam\")\n\nclass async_session(AsyncSession):\n    # sqlmodel.orm.session.Session\n    @overload\n    async def exec(\n        self,\n        statement: Select[_TSelectParam],\n        *,\n        params: Optional[Union[Mapping[str, Any], Sequence[Mapping[str, Any]]]] = None,\n        execution_options: Mapping[str, Any] = util.EMPTY_DICT,\n        bind_arguments: Optional[Mapping[str, Any]] = None,\n        _parent_execute_state: Optional[Any] = None,\n        _add_event: Optional[Any] = None,\n        **kw: Any,\n    ) -> Result[_TSelectParam]:\n        ...\n\n    @overload\n    async def exec(\n        self,\n        statement: SelectOfScalar[_TSelectParam],\n        *,\n        params: Optional[Union[Mapping[str, Any], Sequence[Mapping[str, Any]]]] = None,\n        execution_options: Mapping[str, Any] = util.EMPTY_DICT,\n        bind_arguments: Optional[Mapping[str, Any]] = None,\n        _parent_execute_state: Optional[Any] = None,\n        _add_event: Optional[Any] = None,\n        **kw: Any,\n    ) -> ScalarResult[_TSelectParam]:\n        ...\n\n    async def exec(\n        self,\n        statement: Union[\n            Select[_TSelectParam],\n            SelectOfScalar[_TSelectParam],\n            Executable[_TSelectParam],\n        ],\n        *,\n        params: Optional[Union[Mapping[str, Any], Sequence[Mapping[str, Any]]]] = None,\n        execution_options: Mapping[str, Any] = util.EMPTY_DICT,\n        bind_arguments: Optional[Mapping[str, Any]] = None,\n        _parent_execute_state: Optional[Any] = None,\n        _add_event: Optional[Any] = None,\n        **kw: Any,\n    ) -> Union[Result[_TSelectParam], ScalarResult[_TSelectParam]]:\n        \"\"\"\n        sqlmodel.orm.session.Session\n        \"\"\"\n        return await super().exec(\n            statement,  # type: ignore\n            params=params,\n            execution_options=execution_options,\n            bind_arguments=bind_arguments,\n            _parent_execute_state=_parent_execute_state,\n            _add_event=_add_event,\n            **kw,\n        )\n\n    async def execute(\n        self,\n        statement: _Executable,\n        params: Optional[Union[Mapping[str, Any], Sequence[Mapping[str, Any]]]] = None,\n        execution_options: Optional[Mapping[str, Any]] = util.EMPTY_DICT,\n        bind_arguments: Optional[Mapping[str, Any]] = None,\n        _parent_execute_state: Optional[Any] = None,\n        _add_event: Optional[Any] = None,\n        **kw: Any,\n    ) -> Result[Any]:\n        \"\"\"\n        sqlmodel.orm.session.Session\n        ***\n\n        ğŸš¨ You probably want to use `session.exec()` instead of `session.execute()`.\n\n        This is the original SQLAlchemy `session.execute()` method that returns objects\n        of type `Row`, and that you have to call `scalars()` to get the model objects.\n\n        For example:\n\n        ```Python\n        heroes = session.execute(select(Hero)).scalars().all()\n        ```\n\n        instead you could use `exec()`:\n\n        ```Python\n        heroes = session.exec(select(Hero)).all()\n        ```\n        \"\"\"\n        return await super().execute(  # type: ignore\n            statement,\n            params=params,\n            execution_options=execution_options,\n            bind_arguments=bind_arguments,\n            _parent_execute_state=_parent_execute_state,\n            _add_event=_add_event,\n            **kw,\n        )\n\n    async def get(\n        self,\n        entity: Type[_TSelectParam],\n        ident: Any,\n        options: Optional[Sequence[Any]] = None,\n        populate_existing: bool = False,\n        with_for_update: Optional[Union[Literal[True], Mapping[str, Any]]] = None,\n        identity_token: Optional[Any] = None,\n    ) -> Optional[_TSelectParam]:\n        \"\"\"\n        sqlmodel.orm.session.Session\n        \"\"\"\n        return await super().get(\n            entity,\n            ident,\n            options=options,\n            populate_existing=populate_existing,\n            with_for_update=with_for_update,\n            identity_token=identity_token,\n        )\n````\n\nì£¼ì„ì„ ë³´ë©´ ì•Œê² ì§€ë§Œ, ê·¸ëƒ¥ `sqlmodel.orm.session.Session` ê°ì²´ì˜ ê° ë©”ì†Œë“œì˜ íƒ€ì… íŒíŠ¸ë¥¼ ê·¸ëŒ€ë¡œ ê°€ì ¸ì™”ë‹¤. ì´ì— ë§ì¶°ì„œ ë‹¤ë¥¸ ìŠ¤í¬ë¦½íŠ¸ì˜ `AsyncSession`ë„ ëª¨ë‘ `async_session`ì— ëŒ€í•œ ìŠ¤í¬ë¦½íŠ¸ë¡œ ë³€í™˜í•´ì¤€ë‹¤. ê·¸ë¦¬ê³  í…ŒìŠ¤íŠ¸ ì½”ë“œë¥¼ ì‹¤í–‰í•´ë³´ë©´ ë¬¸ì œì—†ì´ ì‹¤í–‰ë˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.\n\n---\n\n## `datetime_model` ê´€ë ¨ ë¬¸ì œ í•´ê²°\n\n`datetime_model`ì˜ `datetime_attrs` ì†ì„±ì´ ì˜ë„í•œëŒ€ë¡œ ì¶œë ¤ë˜ì§€ ì•ŠëŠ” ë¬¸ì œê°€ ìˆì–´ì„œ ì¶”ê°€ë¡œ ìˆ˜ì •í–ˆë‹¤. `cls.__fields__.keys()` ë¥¼ `datetime_model.__fields__.keys()`ë¡œ ìˆ˜ì •í•œ ê²ƒì™¸ì— ëª¨ë‘ ë™ì¼í•˜ë‹¤.\n\n```python\n# backend/app/models/core.py\n(...)\n\nclass datetime_model(fix_return_type_model):\n    created_at: datetime = Field(default_factory=datetime.now)\n    updated_at: datetime = Field(default_factory=datetime.now)\n\n    def update(self: _D) -> _D:\n        self.updated_at = datetime.now()\n        return self\n\n    @classmethod\n    @property\n    def datetime_attrs(cls) -> set[str]:\n        return set(datetime_model.__fields__.keys())\n```\n\n## `id_model` ì„¸ë¶„í™”\n\nê¸°ì¡´ì— ì‚¬ìš©í•˜ë˜ `id_model`ì„ `int_id_model`ê³¼ `uuid_id_model`ë¡œ ì„¸ë¶„í™”í•´ì„œ ì‚¬ìš©í•˜ê¸°ë¡œ í–ˆë‹¤.\n\n```python\n# backend/app/models/core.py\nfrom uuid import uuid4\nfrom pydantic import UUID4\n\n(...)\n\nclass id_model(fix_return_type_model):\n    @classmethod\n    @property\n    def id_type(cls) -> Any:\n        return cls.__fields__[\"id\"].type_\n\n\nclass int_id_model(id_model):\n    id: int | None = Field(None, primary_key=True)\n\n\nclass uuid_id_model(id_model):\n    id: UUID4 | None = Field(default_factory=uuid4, primary_key=True)\n```\n\n## `dependencies` ëª¨ë“ˆ ìƒì„±\n\nê¸°ì¡´ì— ì‚¬ìš©í•˜ë˜ `get_session`ì´ë‚˜ `get_current_user`ê°™ì€ `Depends`ì™€ í•¨ê»˜ ì‚¬ìš©í•˜ë˜ í•¨ìˆ˜ë¥¼ ë”°ë¡œ ê´€ë¦¬í•˜ê¸°ë¡œ í–ˆë‹¤.\n\n```python\n# backend/app/dependencies/database.py\nfrom typing import AsyncIterator\n\nfrom fastapi import Depends, Request\nfrom sqlalchemy.ext.asyncio.engine import AsyncEngine\n\nfrom ..db.session import async_session\n\n\nasync def get_database(request: Request) -> AsyncEngine:\n    if (engine := getattr(request.app.state, \"_db\", None)) is None:\n        raise AttributeError(\"there is no database engine in request as state\")\n    return engine\n\n\nasync def get_session(\n    engine: AsyncEngine = Depends(get_database),\n) -> AsyncIterator[async_session]:\n    async with async_session(engine, autoflush=False, autocommit=False) as session:\n        yield session\n```\n\n```python\n# backend/app/dependencies/auth.py\nfrom ..services.authentication import fastapi_user_class\n\nfastapi_user = fastapi_user_class.init()\n\nget_current_user = fastapi_user.users.current_user(\n    optional=False, active=True, verified=False, superuser=False\n)\nget_user_manager = fastapi_user.get_user_manager\nget_backend = fastapi_user.get_backend\nget_transport = fastapi_user.get_transport\nget_strategy = fastapi_user.get_strategy\n```\n\n```python\n# backend/app/services/authentication/authentication.py\n(...)\n\n@dataclass(frozen=True)\nclass fastapi_user_class:\n    users: fastapi_users_class[user.user, user_id_type]\n    named_backends: dict[str, auth_backend_type] = field(default_factory=dict)\n\n    @classmethod\n    def init(cls) -> \"fastapi_user_class\":\n        users = create_fastapi_users(*create_backend())\n        return cls(users=users)\n\n    @property\n    def backends(self) -> Sequence[auth_backend_type]:\n        return self.users.authenticator.backends  # type: ignore\n\n    @property\n    def get_user_manager(self):\n        return self.users.get_user_manager\n\n    def find_backend(self, _val: str, /) -> auth_backend_type:\n        for backend in self.backends:\n            if backend.name == _val:\n                return backend\n        raise IndexError(f\"there is not auth_backend name: {_val}\")\n\n    def get_backend(self, _val: int | str = 0, /) -> auth_backend_type:\n        if isinstance(_val, int):\n            return self.backends[_val]\n\n        if (backend := self.named_backends.get(_val)) is None:\n            backend = self.named_backends[_val] = self.find_backend(_val)\n        return backend\n\n    def get_transport(self, _val: int | str = 0, /) -> Transport:\n        backend = self.get_backend(_val)\n        return backend.transport\n\n    def get_strategy(self, _val: int | str = 0, /):\n        backend = self.get_backend(_val)\n        return backend.get_strategy\n```\n","mtime":"2022-08-13T00:12:20.000+09:00","href":"velog/fastapi íŠœí† ë¦¬ì–¼ -8.1- SQLModel AsyncSession ê´€ë ¨ íƒ€ì… ë¬¸ì œ ì„ì‹œ í•´ê²° + ì¶”ê°€ ìˆ˜ì •","data":{"title":"fastapi íŠœí† ë¦¬ì–¼ -8.1- SQLModel AsyncSession ê´€ë ¨ íƒ€ì… ë¬¸ì œ ì„ì‹œ í•´ê²° + ì¶”ê°€ ìˆ˜ì •","date":"2022-05-07T22:08:12.781+09:00","tags":["fastapi","python","sqlmodel","@all"],"page":"fastapi íŠœí† ë¦¬ì–¼","summary":"fastapi ì‚¬ìš©ë²•ì„ ë‹¤ì‹œ ê³µë¶€í• ê²¸, ì°¸ê³ í• ë§Œí•œ ì¢‹ì€ ì˜ˆì œê°€ ìˆì–´ì„œ ì´ ì‹œë¦¬ì¦ˆë¥¼ ì•½ê°„ì˜ ë³€ê²½ì„ ì£¼ê³  ë”°ë¼ê°€ë³´ë ¤ í•œë‹¤."}},"next_post":{"name":"velogì—ì„œ git pageë¡œ ë¸”ë¡œê·¸ ì´ì „","content":"\n# ì™œ ì˜®ê²¼ë‚˜?\n\nì§€ë‚œ ëª‡ë‹¬ê°„ `velog`ì—ì„œ ëª‡ëª‡ í¬ìŠ¤íŠ¸ë¥¼ ì‘ì„±í–ˆë‹¤.\nì˜ ë§Œë“¤ì–´ì§„ êµ¬ì„±ì´ë‹¤ ë³´ë‹ˆ ë³„ë‹¤ë¥¸ ë¶ˆë§Œ ì—†ì´ ì˜ ì‚¬ìš©í–ˆë‹¤.\ní•˜ì§€ë§Œ ì§€ë‚œ ë©°ì¹ ê°„ì˜ ì—°ìŠµ ëì— `git page`ë¡œ ë¸”ë¡œê·¸ë¥¼ ì´ì „í–ˆë‹¤.\n\n## ì²˜ìŒë¶€í„° `git page`ë¥¼ ì“°ê³  ì‹¶ì—ˆë‹¤.\n\nì‚¬ì‹¤ ì´ì „ë¶€í„° `git page`ë¡œ ë¸”ë¡œê·¸ë¥¼ ë§Œë“¤ê³  ì‹¶ì—ˆë‹¤.\nê°€ì¥ ë§ì´ ì•Œë ¤ì§„ ê°„ë‹¨í•œ ë°©ë²•ì€ `jekyll`ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ë‹¤.\ní•˜ì§€ë§Œ `ruby`ë¡œ ì‘ì„±ëœ ì—”ì§„ì´ë‹¤ ë³´ë‹ˆ ì œëŒ€ë¡œ ì•Œì•„ë³´ëŠ”ë° í˜ì´ ë“¤ì—ˆë‹¤.\nê·¸ë ‡ë‹¤ê³  `ruby`ë¥¼ ë”°ë¡œ ë°°ì›Œë³´ìë‹ˆ, ì‚´ë©´ì„œ `ruby`ë¥¼ ì‚¬ìš©í•  ì¼ì´ ì–¼ë§ˆë‚˜ ìˆì„ê¹Œ í•˜ëŠ” ìƒê°ì´ ë¬¸ë“ ë“¤ì—ˆë‹¤.\nì°¨ë¼ë¦¬ `go`ë‚˜ `rust`ë¼ë©´ ë…¸ë ¥í•´ë³´ê² ì§€ë§Œ, `ruby`ë¼ë‹ˆ..\n\nê·¸ë ‡ê²Œ ê·¸ëƒ¥ í•˜ì§€ ë§ê¹Œ? í•˜ë‹¤ê°€ ì•Œê²Œëœê²Œ `velog`ì˜€ë‹¤.\n`velog`ëŠ” ë‚´ê°€ ì²˜ìŒì— ê¸°ëŒ€í•œ ê±°ì˜ ëª¨ë“  ê²ƒì„ ë§Œì¡±í–ˆë‹¤.\n\n- ë§ˆí¬ë‹¤ìš´ì„ ì´ìš©í•œ í¬ìŠ¤íŒ…\n- ì½”ë“œ ë¸”ë¡ í•˜ì´ë¼ì´íŒ…\n- ì‹¤ì‹œê°„ í¬ìŠ¤íŒ… í”„ë¦¬ë·°\n\nê²¨ìš° ì„¸ê°€ì§€ì§€ë§Œ ì´ ì„¸ê°€ì§€ë¥¼ ë§Œì¡±í•˜ëŠ” ê³³ì´ ì‚¬ì‹¤ìƒ ì—†ë‹¤.\nê·¸ë¦¬ê³  ë”°ë¡œ ë‚´ê°€ ë ˆì´ì•„ì›ƒì„ ìˆ˜ì •í•  í•„ìš”ê°€ ì—†ë‹¤ë³´ë‹ˆ(ì‚¬ì‹¤ ë°©ë²•ë„ ì—†ë‹¤), ê·¸ëƒ¥ ì˜ ë§Œë“¤ì–´ì§„ í”Œë«í¼ì— ê¸€ë§Œ ì“°ë©´ ë‚´ê°€ ì›í•˜ëŠ”ê²Œ ë‹¤ ëë‹¤.\n\n## `velog`ëŠ” ë‹¤ ì¢‹ì€ë° ì´ê²Œ ì—†ë‹¤.\n\ní•˜ì§€ë§Œ ì“°ë‹¤ë³´ë‹ˆ ì—­ì‹œ ì•„ì‰¬ìš´ê²Œ ë³´ì¸ë‹¤.\n\n- ëª…í™•í•œ ê¸°ì¤€ì€ ëª¨ë¥´ê² ì§€ë§Œ, ëª‡ëª‡ ì–‘ì‹ì— ëŒ€í•œ í•˜ì´ë¼ì´íŒ… ë¯¸ì§€ì›(log ë“±)\n- ì‘ì„±ê¸€ ìˆ¨ê¸°ê¸°\n\nê·¸ë¦¬ê³  ë¬´ì—‡ë³´ë‹¤ë„.. ë‚´ê°€ ì§ì ‘ ë§Œë“ ë‹¤ëŠ” ì„±ì·¨ê°ì´ ì—†ì—ˆë‹¤.\nê·¸ë˜ì„œ ê²°êµ­ ì§ì ‘ ë§Œë“¤ê¸°ë¡œ í–ˆë‹¤.\n\në‹¤ë§Œ `velog`ë•ë¶„ì— ì¹´í…Œê³ ë¦¬ê°€ ë¬´ì¡°ê±´ ìˆì–´ì•¼ í•œë‹¤ëŠ” ê³ ì •ê´€ë…ì—ì„œ ë²—ì–´ë‚  ìˆ˜ ìˆì—ˆë‹¤.\níƒœê·¸ë¥¼ ì¶”ê°€í•˜ë©´, íƒœê·¸ê°€ ê¸°ì¡´ì˜ ì¹´í…Œê³ ë¦¬ì²˜ëŸ¼ ì‚¬ìš©ë  ìˆ˜ ìˆê²Œ í•˜ë©´ ëœë‹¤.\në˜í•œ íŠ¹ì • í¬ìŠ¤íŠ¸ê°„ì˜ ì—°ê²°ì´ í•„ìš”í•˜ë‹¤ë©´, ë”°ë¡œ ì§€ì •í•  ìˆ˜ ìˆëŠ” ê¸°ëŠ¥ì´ ìˆìœ¼ë©´ ëœë‹¤.\n\n`velog`ì—ì„œ ì–»ì€ ì†Œì¤‘í•œ ê²½í—˜ì„ í† ëŒ€ë¡œ, `git page`ì— ë¸”ë¡œê·¸ë¥¼ ë§Œë“¤ê¸° ìœ„í•œ ì¤€ë¹„ë¥¼ í–ˆë‹¤.\n\n# ì–´ë–»ê²Œ ì˜®ê²¼ë‚˜?\n\nì²˜ìŒì—ëŠ” ê·¸ëƒ¥ ìµìˆ™í•œ `python`ìœ¼ë¡œ ì‘ì„±í•˜ë ¤ í–ˆë‹¤.\n`pelican`ì´ë¼ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ìˆì–´ì„œ, `jekyll`ì²˜ëŸ¼ ê°„ë‹¨í•˜ê²Œ ì •ì  ì‚¬ì´íŠ¸ë¥¼ ë°°í¬í•  ìˆ˜ ìˆê²Œ í•œë‹¤. ì‚¬ìš© ì–¸ì–´ê°€ `python`ì´ë‹¤ ë³´ë‹ˆ ê´€ë ¨ ìŠ¤í¬ë¦½íŠ¸ë¥¼ í™•ì¸í•˜ë©°, ì‘ë™ ë°©ì‹ì„ íŒŒì•…í•˜ëŠ” ê²ƒë„ í• ë§Œí–ˆë‹¤.\n\ní•˜ì§€ë§Œ ë°˜ì‘í˜•ìœ¼ë¡œ ì‘ì„±í•´ë³´ë ¤ í•˜ë‹ˆ, ê²°êµ­ `javascript`ë¥¼ ì“¸ ìˆ˜ ë°–ì— ì—†ì—ˆë‹¤.\nê·¸ë¦¬ê³  ì–´ì°¨í”¼ `javascript`ë¥¼ ì¨ì•¼í•œë‹¤ë©´.. ì´ë²ˆê¸°íšŒì— ê³µë¶€ë„ í•  ê²¸ ì™„ì „íˆ `javascript`ë¡œ ì‘ì„±í•´ë³´ìëŠ” ìƒê°ì´ ë“¤ì—ˆë‹¤.\n\nì—¬ê¸°ì„œ `vue`ëƒ, `react`ëƒ ë§ì€ ê³ ë¯¼ì´ ìˆì—ˆê³ , ì—¬ëŸ¬ ì‹œë„ê°€ ìˆì—ˆëŠ”ë°, ê²°êµ­ ì„ íƒí•œê±´ `react`ë‹¤.\nê·¸ë¦¬ê³  `react` ì•±ì„ ê°„ë‹¨í•˜ê²Œ ì‘ì„±í•˜ê³  ë°°í¬í•  ìˆ˜ ìˆëŠ” í”„ë ˆì„ì›Œí¬ë¡œ `nextjs`ë¥¼ ì‚¬ìš©í–ˆë‹¤.\n\nì²˜ìŒ ìƒê°ì€ `javascript`ì˜€ëŠ”ë°, `python`ì˜ íƒ€ì… íŒíŠ¸ë¥¼ ì´ìš©í•œ `vscode`ì˜ ìë™ì™„ì„± ê¸°ëŠ¥ì— ë„ˆë¬´ ìµìˆ™í•´ì ¸ì„œ ê·¸ëŸ°ê°€, ì½”ë“œ ì‘ì„±ì´ ë„ˆë¬´ ë¶ˆí¸í–ˆë‹¤.\në§ˆì¹¨ `nextjs`ê°€ `typescript`ë¥¼ ì§€ì›í•˜ê¸°ë„ í•´ì„œ, ì•½ê°„ì˜ ìˆ˜ê³ ê°€ ìˆì—ˆì§€ë§Œ `typescript`ë¡œ ì•±ì„ ì‘ì„±í–ˆë‹¤.\n\në§ì€ ì‚½ì§ˆëì— ê·¸ë˜ë„ `git page`ì— ë°°í¬í•  ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ë§Œë“œëŠ”ë° ì„±ê³µí–ˆë‹¤.\nì´ì œ ë¶€ì¡±í•œ ëª‡ëª‡ ê¸°ëŠ¥ì„ ì¶”ê°€í•˜ê³ , ë””ìì¸ì„ ì†ë³´ê¸°ë§Œ í•˜ë©´ ëœë‹¤.\nê·¸ëŸ¬ê³ ë³´ë‹ˆ... `typescript`ë³´ë‹¤ `css`ê°€ ë” ì–´ë ¤ìš´ ê²ƒ ê°™ë‹¤..\nì•„ë¬´ë¦¬ í•´ë„ ì˜ˆì˜ê²Œ ë³´ì´ì§€ë¥¼ ì•ŠëŠ”ë‹¤..\n\n# ì•ìœ¼ë¡œ ì¶”ê°€í•  ê¸°ëŠ¥\n\n- [ ] ë‹¤í¬ëª¨ë“œ í† ê¸€\n  > ì‚¬ì‹¤ ì´ë¯¸ ê¸°ëŠ¥ ì¶”ê°€ëŠ” í–ˆì§€ë§Œ, css ì‘ì„±í•˜ê¸°ê°€ í˜ë“¤ì–´ì„œ ì£¼ì„ìœ¼ë¡œ ë†”ë‘” ìƒíƒœ\n- [ ] ë¬¸ë‹¨ ì œëª© ì—­ë§í¬\n- [ ] ì½”ë“œ ë¸”ëŸ­ ë¼ì¸ í•˜ì´ë¼ì´íŠ¸\n","mtime":"2022-08-13T00:12:20.000+09:00","href":"js/velogì—ì„œ git pageë¡œ ë¸”ë¡œê·¸ ì´ì „","data":{"title":"velogì—ì„œ git pageë¡œ ë¸”ë¡œê·¸ ì´ì „","tags":["js","ts","nextjs","velog","github","@all"],"page":null,"date":"2022-06-12T04:27:48.097+09:00","summary":"there is no summary"}},"page_posts":[{"name":"fastapi íŠœí† ë¦¬ì–¼ -1- ì´ˆê¸° ì„¤ì •","content":"\n**`fastapi`** ì‚¬ìš©ë²•ì„ ë‹¤ì‹œ ê³µë¶€í• ê²¸, ì°¸ê³ í• ë§Œí•œ ì¢‹ì€ [ì˜ˆì œ](https://www.jeffastor.com/blog/populating-cleaning-jobs-with-user-offers-in-fastapi)ê°€ ìˆì–´ì„œ ì´ ì‹œë¦¬ì¦ˆë¥¼ ì•½ê°„ì˜ ë³€ê²½ì„ ì£¼ê³  ë”°ë¼ê°€ë³´ë ¤ í•œë‹¤.\nì§€ë‚œë²ˆì²˜ëŸ¼ ì–´ì©Œë‹¤ ê·¸ë§Œë‘˜ ìˆ˜ë„ ìˆê¸´ í•˜ì§€ë§Œ...\n\n---\n\n## ì´ˆê¸° ì„¤ì •\n\n### íŒŒì´ì¬ ì„¤ì •\n\nìš°ì„  ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ê°€ìƒ íŒŒì´ì¬ í™˜ê²½ë¶€í„° ì¡ì•„ì¤¬ë‹¤.\n\n```bash\nâ¯ pyenv virtualenv 3.10.4 jeffastor_tutor\nâ¯ pyenv local jeffastor_tutor\n```\n\nì‹¤ì œë¡œëŠ” **`docker`** ë¡œ ì‹¤í–‰í•˜ê² ì§€ë§Œ, **`vscode`** ë¥¼ ì‚¬ìš©í•˜ë©´ì„œ **`pylance`** ì˜ ìë™ì™„ì„±ê³¼ íƒ€ì… ì¶”ë¡  ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´, ë”°ë¡œ ë§Œë“¤ì—ˆë‹¤.\n\nê·¸ë¦¬ê³  í•„ìˆ˜ íŒ¨í‚¤ì§€ì™€ ê°œì¸ì ìœ¼ë¡œ ì„ í˜¸í•˜ëŠ” **`orjson`** ì„ ì„¤ì¹˜í•œë‹¤.\n\n```bash\nâ¯ poetry init\nâ¯ poetry add fastapi \"uvicorn[standard]\" orjson\nâ¯ poetry add --dev black isort\nâ¯ cat pyproject.toml\n[tool.poetry]\nname = \"jeffastor_tutor\"\nversion = \"0.1.0\"\ndescription = \"\"\nauthors = [\"phi <phi.friday@gmail.com>\"]\n\n[tool.poetry.dependencies]\npython = \"^3.10\"\nfastapi = \"^0.75.2\"\nuvicorn = {extras = [\"standard\"], version = \"^0.17.6\"}\norjson = \"^3.6.8\"\n\n[tool.poetry.dev-dependencies]\nblack = \"^22.3.0\"\nisort = \"^5.10.1\"\n\n[build-system]\nrequires = [\"poetry-core>=1.0.0\"]\nbuild-backend = \"poetry.core.masonry.api\"\n```\n\n> - fastapi - ë°±ì—”ë“œ êµ¬ì¶•ì— ì‚¬ìš©í•  í”„ë ˆì„ì›Œí¬\n> - uvicorn - fastapi ì•±ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•œ asgi ì„œë²„\n> - orjson - ì¢€ ë” ë¹ ë¥´ê³ , ì •í™•í•˜ê³ , ë‹¤ì–‘í•˜ê²Œ íŒŒì´ì¬ ê°ì²´ë¥¼ jsonìœ¼ë¡œ ë³€í™˜í•´ì£¼ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬\n\n### `fastapi` ê¸°ë³¸ êµ¬ì„± ì„¤ì •\n\n**JeffAstor**ê°€ ì œì‹œí•œ ë””ë ‰í† ë¦¬/ëª¨ë“ˆ êµ¬ì„±ì€ ëŒ€ë¶€ë¶„ ê·¸ëŒ€ë¡œ ê°€ì ¸ê°ˆ ìƒê°ì´ë‹¤.\n\n```bash\nâ¯ mkdir backend backend/app backend/tests\nâ¯ mkdir backend/app/api backend/app/core\nâ¯ touch backend/app/api/__init__.py backend/app/api/server.py\n```\n\n```python\n# backend/app/api/server.py\nfrom fastapi import FastAPI\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom fastapi.responses import ORJSONResponse\n\n\ndef get_application() -> FastAPI:\n    app = FastAPI(title='jeffastor_tutor', default_response_class=ORJSONResponse)\n\n    app.add_middleware(\n        CORSMiddleware,\n        allow_origins=[\"*\"],\n        allow_credentials=True,\n        allow_methods=[\"*\"],\n        allow_headers=[\"*\"],\n    )\n    return app\n\napp = get_application()\n```\n\n`CORSMiddleware`ì— ëŒ€í•´ì„œëŠ” ì§€ê¸ˆ ì‹ ê²½ì“¸ í•„ìš” ì—†ìœ¼ë©°, ë‚˜ì¤‘ì— ê´€ë ¨í•´ì„œ ìì„¸íˆ ì„¤ëª…í•˜ê² ë‹¤ê³  í•œë‹¤.\n\n`default_response_class`ëŠ” **`fastapi`** ì˜ `response`ë¥¼ ì§ë ¬í™” í•  ë•Œ **`orjson`** ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´ `ORJSONResponse`ë¥¼ ì§€ì •í–ˆë‹¤.\n\n### `docker` ì„¤ì •\n\nì´ì œ ì„œë²„ë¥¼ ì‹¤í–‰í•  **`docker`** ë¥¼ ì„¤ì •í•œë‹¤.\n\n```bash\nâ¯ poetry export -f requirements.txt --output backend/requirements.txt --without-hashes\nâ¯ touch docker-compose.yml backend/Dockerfile backend/.env\n```\n\n```Dockerfile\n# backend/Dockerfile\nFROM python:3.10-slim-bullseye\nWORKDIR /backend\nENV PYTHONDONTWRITEBYTECODE 1\nENV PYTHONBUFFERED 1\n# install system dependencies\n# RUN apt-get update \\\n#   && apt-get -y install netcat gcc postgresql \\\n#   && apt-get clean\n# install python dependencies\n# RUN pip install --upgrade pip\nCOPY ./requirements.txt /backend/requirements.txt\nRUN pip install -r requirements.txt\nCOPY . /backend\n```\n\n```yaml\n# docker-compose.yml\n# prettier-ignore\nversion: \"3.8\"\nservices:\n  server:\n    build:\n      context: ./backend\n      dockerfile: Dockerfile\n    volumes:\n      - ./backend/:/backend/\n    command: uvicorn app.api.server:app --reload --workers 2 --host 0.0.0.0 --port 8000\n    env_file:\n      - ./backend/.env\n    ports:\n      - 8000:8000\n```\n\nsql ì„œë²„ëŠ” ë‹¤ë¥¸ ì»¨í…Œì´ë„ˆë¡œ ê´€ë¦¬í•  ì˜ˆì •ì´ê¸°ì— ì£¼ì„ì²˜ë¦¬í–ˆë‹¤.\n\nì´ì œ **`docker`** ë¥¼ ì‹¤í–‰í•´ë³´ì.\n\n```bash\nâ¯ docker-compose up --build\n\n```\n\në¸Œë¼ìš°ì €ì—ì„œ `localhost:8000`ì— ì ‘ì†í•´ë³´ë©´\n\n```yaml\n{ 'detail': 'Not Found' }\n```\n\nì•„ì§ ì•„ë¬´ëŸ° ë¼ìš°í„°ë¥¼ ì¶”ê°€í•˜ì§€ ì•Šì•˜ê¸°ì— ë‚˜ì˜¤ëŠ” ê¸°ë³¸ê°’ì´ ì¶œë ¥ëœë‹¤.\n\n## ê¸°ë³¸ ë¼ìš°í„° ìƒì„±\n\nì„œë²„ë¥¼ ì¤‘ë‹¨í•˜ì§€ ì•Šê³ , ì´ì–´ì„œ ë¼ìš°í„°ë¥¼ ì¶”ê°€í•œë‹¤.\n\n```bash\nâ¯ mkdir backend/app/api/routes\nâ¯ touch backend/app/api/routes/__init__.py\nâ¯ touch backend/app/api/routes/cleanings.py\n```\n\n```python\n# backend/app/api/routes/cleanings.py\nfrom fastapi import APIRouter\n\nrouter = APIRouter()\n\n@router.get(\"/\")\nasync def get_all_cleanings() -> list[dict]:\n    cleanings = [\n        {\"id\": 1, \"name\": \"My house\", \"cleaning_type\": \"full_clean\", \"price_per_hour\": 29.99},\n        {\"id\": 2, \"name\": \"Someone else's house\", \"cleaning_type\": \"spot_clean\", \"price_per_hour\": 19.99}\n    ]\n    return cleanings\n```\n\n```python\n# backend/app/api/routes/__init__.py\nfrom fastapi import APIRouter\n\nfrom .cleanings import router as cleanings_router\n\nrouter = APIRouter()\n\nrouter.include_router(cleanings_router, prefix=\"/cleanings\", tags=[\"cleanings\"])\n```\n\nì›ë¬¸ì€ ì ˆëŒ€ì°¸ì¡°ë¡œ ì‘ì„±í–ˆì§€ë§Œ, **`docker`** ì‹¤í–‰ í™˜ê²½ì—ì„œëŠ” ì •ìƒì ìœ¼ë¡œ ì‘ë™í•˜ì§€ë§Œ, í¸ì§‘ í™˜ê²½ì—ì„œëŠ” **`pylance`** ê°€ ì •ìƒì ìœ¼ë¡œ ì¸ì‹í•˜ì§€ ëª»í•˜ë¯€ë¡œ ìƒëŒ€ì°¸ì¡°ë¡œ ë³€ê²½í–ˆë‹¤.\n\nëìœ¼ë¡œ `get_application`í•¨ìˆ˜ë¥¼ ìˆ˜ì •í•œë‹¤.\n\n```python\n# backend/app/api/server.py\n(...)\nfrom .routes import router as api_router\n\n\ndef get_application() -> FastAPI:\n    app = FastAPI(title='jeffastor_tutor', default_response_class=ORJSONResponse)\n\n    app.add_middleware(\n        CORSMiddleware,\n        allow_origins=[\"*\"],\n        allow_credentials=True,\n        allow_methods=[\"*\"],\n        allow_headers=[\"*\"],\n    )\n\n    app.include_router(api_router, prefix='/api')\n\n    return app\n(...)\n```\n\n**`uvicorn`** ì˜ `reload` ì˜µì…˜ì„ ì¼°ê¸° ë•Œë¬¸ì—, ë³„ë‹¤ë¥¸ ì¡°ì‘ ì—†ì´ ìˆ˜ì •ì‚¬í•­ì´ ë°˜ì˜ëœ ìƒíƒœë¡œ ì„œë²„ê°€ ë‹¤ì‹œ ì‹¤í–‰ëœë‹¤. [http://localhost:8000/api/cleanings/](http://localhost:8000/api/cleanings/)ì—ì„œ ë‹¤ìŒê³¼ ê°™ì€ ê²°ê³¼ë¥¼ í™•ì¸í•  ìˆ˜ ìˆë‹¤.\n\n```yaml\n[\n  {\n    'id': 1,\n    'name': 'My house',\n    'cleaning_type': 'full_clean',\n    'price_per_hour': 29.99,\n  },\n  {\n    'id': 2,\n    'name': \"Someone else's house\",\n    'cleaning_type': 'spot_clean',\n    'price_per_hour': 19.99,\n  },\n]\n```\n\në‹¤ìŒ ì±•í„°ì—ì„œëŠ” sql ì„œë²„ë¥¼ ì—°ê²°í•˜ê³ , **`pytest`** ë¥¼ ì´ìš©í•˜ì—¬ í…ŒìŠ¤íŠ¸ë¥¼ ì§„í–‰í•œë‹¤.\n\nì°¸ê³ ë¡œ, **`docker`** ë¡œ ì‹¤í–‰ëœ ì„œë²„ëŠ”\n\n```bash\nâ¯ docker-compose down\n```\n\nìœ¼ë¡œ ì¢…ë£Œê°€ ê°€ëŠ¥í•˜ë‹¤.\n","mtime":"2022-08-13T00:12:20.000+09:00","href":"velog/fastapi íŠœí† ë¦¬ì–¼ -1- ì´ˆê¸° ì„¤ì •","data":{"title":"fastapi íŠœí† ë¦¬ì–¼ -1- ì´ˆê¸° ì„¤ì •","date":"2022-04-27T23:30:14.239+09:00","tags":["fastapi","python","@all"],"page":"fastapi íŠœí† ë¦¬ì–¼","summary":"fastapi ì‚¬ìš©ë²•ì„ ë‹¤ì‹œ ê³µë¶€í• ê²¸, ì°¸ê³ í• ë§Œí•œ ì¢‹ì€ ì˜ˆì œê°€ ìˆì–´ì„œ ì´ ì‹œë¦¬ì¦ˆë¥¼ ì•½ê°„ì˜ ë³€ê²½ì„ ì£¼ê³  ë”°ë¼ê°€ë³´ë ¤ í•œë‹¤."}},{"name":"fastapi íŠœí† ë¦¬ì–¼ -2- sql ì„œë²„ ì—°ê²°","content":"\n**`fastapi`** ì‚¬ìš©ë²•ì„ ë‹¤ì‹œ ê³µë¶€í• ê²¸, ì°¸ê³ í• ë§Œí•œ ì¢‹ì€ [ì˜ˆì œ](https://www.jeffastor.com/blog/populating-cleaning-jobs-with-user-offers-in-fastapi)ê°€ ìˆì–´ì„œ ì´ ì‹œë¦¬ì¦ˆë¥¼ ì•½ê°„ì˜ ë³€ê²½ì„ ì£¼ê³  ë”°ë¼ê°€ë³´ë ¤ í•œë‹¤.\nì§€ë‚œë²ˆì²˜ëŸ¼ ì–´ì©Œë‹¤ ê·¸ë§Œë‘˜ ìˆ˜ë„ ìˆê¸´ í•˜ì§€ë§Œ...\n\n---\n\n## `sql` ì„œë²„ ì—°ê²°ì„ ìœ„í•œ ì´ˆê¸° ì„¤ì •\n\n### `docker-compose` ì„¤ì •\n\nsql ì„œë²„ëŠ” **`postgres`** ë¥¼ ì‚¬ìš©í•˜ê¸°ë¡œ í•œë‹¤. ë”°ë¼ì„œ í•„ìš”í•œ íŒŒì´ì¬ íŒ¨í‚¤ì§€ë¥¼ ì¶”ê°€ë¡œ ì„¤ì¹˜í•˜ê³ , `docker-compose.yml` íŒŒì¼ì„ ìˆ˜ì •í•œë‹¤.\n\n```bash\nâ¯ poetry add asyncpg sqlalchemy sqlmodel\nâ¯ poetry export -f requirements.txt --output backend/requirements.txt --without-hashes\n```\n\n```yaml\n# docker-compose.yml\n# prettier-ignore\nversion: \"3.8\"\nservices:\n  server:\n    build:\n      context: ./backend\n      dockerfile: Dockerfile\n    volumes:\n      - ./backend/:/backend/\n    command: uvicorn app.api.server:app --reload --workers 2 --host 0.0.0.0 --port 8000\n    env_file:\n      - ./backend/.env\n    ports:\n      - 8000:8000\n    depends_on:\n      - db\n\n  db:\n    image: postgres:14-alpine\n    volumes:\n      - ./postgres_data:/var/lib/postgresql/data/\n    env_file:\n      - ./backend/.env\n    ports:\n      - 5432:5432\n```\n\n### `git` êµ¬ì„±\n\nì´ìœ ëŠ” ëª¨ë¥´ê² ì§€ë§Œ, **jeffastor**ëŠ” ì´ì „ ê¸€ë¶€í„°ê°€ ì•„ë‹Œ, ì´ë²ˆ ê¸€ ë¶€í„° **`git`** ìœ¼ë¡œ ê´€ë¦¬ë¥¼ ì‹œì‘í•œë‹¤..\n\n```bash\nâ¯ touch .gitignore\n```\n\n```yaml\n# .gitignore\n# Byte-compiled files\n__pycache__/\n# Environment files\n.env\n```\n\n```bash\nâ¯ git init\nâ¯ git add .\nâ¯ git commit -m \"Dockerized FastAPI app with postgres.\"\n```\n\n### í™˜ê²½ë³€ìˆ˜ ì„¤ì •\n\n**`postgres`** ë° ì„œë²„ ì „ë°˜ì ìœ¼ë¡œ ì‚¬ìš©í•  í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•œë‹¤.\n\n```python\n# backend/.env\nSECRET_KEY=supersecret\n\nPOSTGRES_USER=postgres\nPOSTGRES_PASSWORD=postgres\nPOSTGRES_SERVER=db\nPOSTGRES_PORT=5432\nPOSTGRES_DB=postgres\n```\n\n`SECRET_KEY`ì˜ ê²½ìš°, ì§€ê¸ˆì€ ê¸°ë³¸ê°’ìœ¼ë¡œ ì‚¬ìš©í•˜ì§€ë§Œ ë‚˜ì¤‘ì— ìˆ˜ì •í• ê±°ë‹ˆ ê±±ì •í•˜ì§€ ì•Šì•„ë„ ëœë‹¤ê³  í•œë‹¤..\n\n### `config.py` ì„¤ì •\n\nì´ì œ ì„œë²„ì—ì„œ ì‚¬ìš©í•  ì„¤ì • íŒŒì¼ì„ ìƒì„±í•œë‹¤.\n\n```bash\nâ¯ touch backend/app/core/config.py\n```\n\n```python\n# backend/app/core/config.py\nfrom sqlalchemy.engine.url import URL\nfrom starlette.config import Config\nfrom starlette.datastructures import Secret\n\nconfig = Config(\".env\")\n\nPROJECT_NAME = \"jeffastor_tutor\"\nVERSION = \"1.0.0\"\nAPI_PREFIX = \"/api\"\n\nSECRET_KEY = config(\"SECRET_KEY\", cast=Secret, default=\"CHANGEME\")\n\nPOSTGRES_USER = config(\"POSTGRES_USER\", cast=str)\nPOSTGRES_PASSWORD = config(\"POSTGRES_PASSWORD\", cast=Secret)\nPOSTGRES_SERVER = config(\"POSTGRES_SERVER\", cast=str, default=\"db\")\nPOSTGRES_PORT = config(\"POSTGRES_PORT\", cast=int, default=5432)\nPOSTGRES_DB = config(\"POSTGRES_DB\", cast=str)\n\nDATABASE_URL = config(\n    \"DATABASE_URL\",\n    cast=str,\n    default=URL.create(\n        drivername=\"postgresql+asyncpg\",\n        username=POSTGRES_USER,\n        password=POSTGRES_PASSWORD,\n        host=POSTGRES_SERVER,\n        port=POSTGRES_PORT,\n        database=POSTGRES_DB,\n    ).render_as_string(hide_password=False),\n)\n```\n\nì› ì˜ˆì œì™€ ë‹¤ë¥´ê²Œ, **`sqlmodel`** ì„ ì‚¬ìš©í•  ì˜ˆì •ì´ë¼ urlì„ ë‹¤ë¥´ê²Œ ì„¤ì •í–ˆë‹¤.\n\n> ì„¤ëª…ì— ë”°ë¥´ë©´, ê¸°ë³¸ê°’ì´ ì—†ëŠ” `config` ê°ì²´ì— ì„¤ì •ëœ ëª¨ë“  ê°’ì€ `.env`íŒŒì¼ì—ì„œ ê°’ì„ ì œê³µí•´ì•¼í•˜ê³ , ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ ì—ëŸ¬ê°€ ë°œìƒí•œë‹¤ê³  í•œë‹¤.\n\n## `sql` ì„œë²„ ì—°ê²° ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±\n\nì´ì œ sql ì„œë²„ì™€ ì—°ê²°í•˜ê¸° ìœ„í•œ ëª¨ë“ˆê³¼ ì•± ì‹œì‘/ì¢…ë£Œ ì´ë²¤íŠ¸ì™€ ê´€ë ¨í•œ ì‘ì—… íŒŒì¼ì„ ìƒì„±í•œë‹¤.\n\n```bash\nâ¯ mkdir backend/app/db\nâ¯ touch backend/app/db/__init__.py backend/app/db/tasks.py backend/app/db/engine.py  backend/app/core/tasks.py\n```\n\n### ì—”ì§„ ì„¤ì •\n\n```python\n# backend/app/db/engine.py\nfrom sqlalchemy.ext.asyncio import create_async_engine\nfrom sqlalchemy.pool import QueuePool\n\nfrom ..core.config import DATABASE_URL\n\nengine = create_async_engine(\n    DATABASE_URL, pool_size=10, poolclass=QueuePool, pool_pre_ping=True\n)\n```\n\n```python\n# backend/app/db/tasks.py\nimport logging\nfrom typing import cast\n\nfrom fastapi import FastAPI\nfrom sqlalchemy.ext.asyncio.engine import AsyncEngine\n\nfrom .engine import engine\n\nlogger = logging.getLogger(__name__)\n\n\nasync def connect_to_db(app: FastAPI) -> None:\n    try:\n        async with engine.connect():\n            logger.info(\n                f\"connected db: {engine.url.render_as_string(hide_password=True)}\"\n            )\n        app.state._db = engine\n    except Exception as e:\n        logger.warning(\"--- DB CONNECTION ERROR ---\")\n        logger.warning(e)\n        logger.warning(\"--- DB CONNECTION ERROR ---\")\n\n\nasync def close_db_connection(app: FastAPI) -> None:\n    engine = cast(AsyncEngine, app.state._db)\n    try:\n        await engine.dispose()\n    except Exception as e:\n        logger.warning(\"--- DB DISCONNECT ERROR ---\")\n        logger.warning(e)\n        logger.warning(\"--- DB DISCONNECT ERROR ---\")\n```\n\n```python\n# backend/app/core/tasks.py\nfrom typing import Any, Callable, Coroutine\n\nfrom fastapi import FastAPI\n\nfrom ..db.tasks import close_db_connection, connect_to_db\n\n\ndef create_start_app_handler(app: FastAPI) -> Callable[[], Coroutine[Any, Any, None]]:\n    async def start_app() -> None:\n        await connect_to_db(app)\n\n    return start_app\n\n\ndef create_stop_app_handler(app: FastAPI) -> Callable[[], Coroutine[Any, Any, None]]:\n    async def stop_app() -> None:\n        await close_db_connection(app)\n\n    return stop_app\n```\n\n`AsyncEngine` ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•˜ê³ , ì´ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì´ìš©í•´ì„œ ì•±ì„ ì‹œì‘í•  ë•Œì™€ ì¢…ë£Œí•  ë•Œ ì‹¤í–‰í•  ë‘ê°€ì§€ í•¸ë“¤ëŸ¬ë¥¼ ì •ì˜í–ˆë‹¤.\n\n> ê¸°ì¡´ ê¸€ì—ì„œëŠ” ì—”ì§„ì„ ì§ì ‘ ë§Œë“¤ê¸° ë³´ë‹¤ **`databases`** ë¥¼ ì´ìš©í•˜ëŠ”ë°, ì¼ë‹¨ ì´ì „ì— ì‚¬ìš©í•œ ì  ìˆëŠ” **`sqlmodel`** ë¡œ ì§„í–‰í•œë‹¤.\n\nì´ í•¸ë“¤ëŸ¬ëŠ” sql ì„œë²„ ì—°ê²°ì´ ì •ìƒì ìœ¼ë¡œ ì´ë£¨ì–´ì¡Œë‹¤ë©´, ì•±ì˜ `state`ì— `_db`ë¼ëŠ” ì†ì„±ìœ¼ë¡œ `AsyncEngine` ì¸ìŠ¤í„´ìŠ¤ë¥¼ í˜¸ì¶œí•  ìˆ˜ ìˆê²Œ í•œë‹¤.\nê·¸ë¦¬ê³  ì¢…ë£Œí•  ë•Œ, ì´ ì¸ìŠ¤í„´ìŠ¤ì™€ ì—°ê²°ëœ ëª¨ë“  ì„¸ì…˜ì„ ì¢…ë£Œí•œë‹¤.\nì´ì œ ì´ í•¸ë“¤ëŸ¬ë¥¼ ì ìš©í•œë‹¤.\n\n```python\n# backend/app/api/routes/server.py\nfrom fastapi import FastAPI\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom fastapi.responses import ORJSONResponse\n\nfrom ..core import config, tasks\nfrom .routes import router as api_router\n\n\ndef get_application() -> FastAPI:\n    app = FastAPI(\n        title=config.PROJECT_NAME,\n        version=config.VERSION,\n        default_response_class=ORJSONResponse,\n    )\n\n    app.add_middleware(\n        CORSMiddleware,\n        allow_origins=[\"*\"],\n        allow_credentials=True,\n        allow_methods=[\"*\"],\n        allow_headers=[\"*\"],\n    )\n\n    app.add_event_handler(\"startup\", tasks.create_start_app_handler(app))\n    app.add_event_handler(\"shutdown\", tasks.create_stop_app_handler(app))\n\n    app.include_router(api_router, prefix=config.API_PREFIX)\n\n    return app\n\n\napp = get_application()\n```\n\në§Œì•½ **`docker`** ì‹¤í–‰ ì‹œ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•œë‹¤ë©´, sql ì„œë²„ë¥¼ ì‚¬ìš©í•  ì¤€ë¹„ê°€ ëë‚¬ë‹¤.\n\n### `alembic`ì„ ì‚¬ìš©í•œ ë§ˆì´ê·¸ë ˆì´ì…˜\n\nì´ì œ **`alembic`** ì„ ì‚¬ìš©í•œ ë§ˆì´ê·¸ë ˆì´ì…˜ì„ êµ¬ì„±í•œë‹¤ê³  í•˜ëŠ”ë°.. ì‚¬ìš©í•´ë³¸ì ì´ í•œë²ˆë„ ì—†ì–´ì„œ ìƒì†Œí•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë‹¤. ê·¸ëŸ¬ë‹ˆ ì¼ë‹¨ ê·¸ëŒ€ë¡œ ë”°ë¼í•˜ëŠ”ë° ì¤‘ì ì„ ë‘”ë‹¤.\n\n```bash\nâ¯ mkdir backend/app/db/migrations backend/app/db/repositories\nâ¯ touch backend/app/db/migrations/script.py.mako backend/app/db/migrations/env.py backend/app/db/repositories/__init__.py backend/app/db/repositories/base.py backend/alembic.ini\n```\n\n> **`mako`** í™•ì¥ìëŠ” [Mako](https://www.makotemplates.org/) í…œí”Œë¦¿ì´ë¼ê³  í•œë‹¤.\n\n```yaml\n# backend/alembic.ini\n# A generic, single database configuration.\n\n[alembic]\n# path to migration scripts\nscript_location = ./app/db/migrations\n\n# template used to generate migration files\n# file_template = %%(rev)s_%%(slug)s\n\n# sys.path path, will be prepended to sys.path if present.\n# defaults to the current working directory.\n# prepend_sys_path = .\n\n# timezone to use when rendering the date within the migration file\n# as well as the filename.\n# If specified, requires the python-dateutil library that can be\n# installed by adding `alembic[tz]` to the pip requirements\n# string value is passed to dateutil.tz.gettz()\n# leave blank for localtime\n# timezone =\n\n# max length of characters to apply to the\n# \"slug\" field\n# truncate_slug_length = 40\n\n# set to 'true' to run the environment during\n# the 'revision' command, regardless of autogenerate\n# revision_environment = false\n\n# set to 'true' to allow .pyc and .pyo files without\n# a source .py file to be detected as revisions in the\n# versions/ directory\n# sourceless = false\n\n# version location specification; This defaults\n# to test/versions.  When using multiple version\n# directories, initial revisions must be specified with --version-path.\n# The path separator used here should be the separator specified by \"version_path_separator\" below.\n# version_locations = %(here)s/bar:%(here)s/bat:test/versions\nversion_locations = ./app/db/migrations/versions\n\n# version path separator; As mentioned above, this is the character used to split\n# version_locations. The default within new alembic.ini files is \"os\", which uses os.pathsep.\n# If this key is omitted entirely, it falls back to the legacy behavior of splitting on spaces and/or commas.\n# Valid values for version_path_separator are:\n#\n# version_path_separator = :\n# version_path_separator = ;\n# version_path_separator = space\n# version_path_separator = os  # Use os.pathsep. Default configuration used for new projects.\n\n# the output encoding used when revision files\n# are written from script.py.mako\n# output_encoding = utf-8\n\n# sqlalchemy.url = driver://user:pass@localhost/dbname\n\n\n[post_write_hooks]\n# post_write_hooks defines scripts or Python functions that are run\n# on newly generated revision scripts.  See the documentation for further\n# detail and examples\n\n# format using \"black\" - use the bash_scripts runner, against the \"black\" entrypoint\n# hooks = black\n# black.type = bash_scripts\n# black.entrypoint = black\n# black.options = -l 79 REVISION_SCRIPT_FILENAME\n\n# Logging configuration\n[loggers]\nkeys = root,sqlalchemy,alembic\n\n[handlers]\nkeys = bash\n\n[formatters]\nkeys = generic\n\n[logger_root]\nlevel = WARN\nhandlers = bash\nqualname =\n\n[logger_sqlalchemy]\nlevel = WARN\nhandlers =\nqualname = sqlalchemy.engine\n\n[logger_alembic]\nlevel = INFO\nhandlers =\nqualname = alembic\n\n[handler_bash]\nclass = StreamHandler\nargs = (sys.stderr,)\nlevel = NOTSET\nformatter = generic\n\n[formatter_generic]\nformat = %(levelname)-5.5s [%(name)s] %(message)s\ndatefmt = %H:%M:%S\n```\n\n```python\n# backend/app/db/migrations/script.py.mako\n\"\"\"${message}\n\nRevision ID: ${up_revision}\nRevises: ${down_revision | comma,n}\nCreate Date: ${create_date}\n\n\"\"\"\nfrom alembic import op\nimport sqlalchemy as sa\n${imports if imports else \"\"}\n\n# revision identifiers, used by Alembic.\nrevision = ${repr(up_revision)}\ndown_revision = ${repr(down_revision)}\nbranch_labels = ${repr(branch_labels)}\ndepends_on = ${repr(depends_on)}\n\n\ndef upgrade():\n    ${upgrades if upgrades else \"pass\"}\n\n\ndef downgrade():\n    ${downgrades if downgrades else \"pass\"}\n```\n\nê°ì¢… ì„¤ì •ì´ ì¶”ê°€ë˜ëŠ”ë°, **`mako`** í…œí”Œë¦¿ íŒŒì¼ì€ ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ìƒì„±í•˜ê³ , ê·¸ ê³¼ì •ì„ ë¡œê·¸ë¡œ ë‚¨ê¸°ëŠ” ê²ƒì´ë¼ê³  í•œë‹¤... ì‹¤ì œë¡œ ë´ì•¼ ì•Œ ìˆ˜ ìˆì„ ë“¯.\n\nì´ì œ ëìœ¼ë¡œ `env.py`ë¥¼ ì‘ì„±í•´ì•¼í•˜ëŠ”ë°, ì´ì œë³´ë‹ˆ ì²« ê³¼ì •ì—ì„œ **`alembic`** ë¥¼ ì¶”ê°€í•˜ì§€ ì•Šì•˜ê¸°ì—, ê·¸ ê³¼ì •ì„ í•¨ê»˜í•œë‹¤.\n\n```bash\nâ¯ poetry add alembic\nâ¯ poetry export -f requirements.txt --output backend/requirements.txt --without-hashes\n```\n\n```python\n# backend/app/db/migrations/env.py\nimport asyncio\nimport logging\nimport pathlib\nimport sys\nfrom logging.config import fileConfig\nfrom typing import cast\n\nfrom alembic import context\nfrom sqlalchemy import engine_from_config, pool\nfrom sqlalchemy.ext.asyncio import AsyncEngine\nfrom sqlalchemy.future.engine import Engine\n\nsys.path.append(str(pathlib.Path(__file__).resolve().parents[3]))\nfrom app.core.config import DATABASE_URL  # noqa\n\n# this is the Alembic Config object, which provides\n# access to the values within the .ini file in use.\nconfig = context.config\n\n# Interpret the config file for Python logging.\n# This line sets up loggers basically.\nif config.config_file_name is not None:\n    fileConfig(config.config_file_name)\nlogger = logging.getLogger(\"alembic.env\")\n\n# add your model's MetaData object here\n# for 'autogenerate' support\n# from myapp import mymodel\n# target_metadata = mymodel.Base.metadata\ntarget_metadata = None\n\n# other values from the config, defined by the needs of env.py,\n# can be acquired:\n# my_important_option = config.get_main_option(\"my_important_option\")\n# ... etc.\n\n\ndef run_migrations_offline():\n    \"\"\"Run migrations in 'offline' mode.\n\n    This configures the context with just a URL\n    and not an Engine, though an Engine is acceptable\n    here as well.  By skipping the Engine creation\n    we don't even need a DBAPI to be available.\n\n    Calls to context.execute() here emit the given string to the\n    script output.\n\n    \"\"\"\n    # url = config.get_main_option(\"sqlalchemy.url\")\n    context.configure(\n        # url=url,\n        url=DATABASE_URL,\n        target_metadata=target_metadata,\n        literal_binds=True,\n        dialect_opts={\"paramstyle\": \"named\"},\n    )\n\n    with context.begin_transaction():\n        context.run_migrations()\n\n\ndef do_run_migrations(connection):\n    context.configure(connection=connection, target_metadata=target_metadata)\n\n    with context.begin_transaction():\n        context.run_migrations()\n\n\nasync def run_migrations_online():\n    \"\"\"Run migrations in 'online' mode.\n\n    In this scenario we need to create an Engine\n    and associate a connection with the context.\n\n    \"\"\"\n    config.set_main_option(\"sqlalchemy.url\", DATABASE_URL)\n    connectable = AsyncEngine(\n        cast(\n            Engine,\n            engine_from_config(\n                config.get_section(config.config_ini_section),\n                prefix=\"sqlalchemy.\",\n                poolclass=pool.NullPool,\n                future=True,\n            ),\n        )\n    )\n\n    async with connectable.connect() as connection:\n        await connection.run_sync(do_run_migrations)\n\n    await connectable.dispose()\n\n\nif context.is_offline_mode():\n    logger.info(\"Running migrations offline\")\n    run_migrations_offline()\nelse:\n    logger.info(\"Running migrations online\")\n    asyncio.run(run_migrations_online())\n```\n\nì´ì œ ì²«ë²ˆì§¸ ë§ˆì´ê·¸ë ˆì´ì…˜ì„ **`docker`** ë‚´ë¶€ì—ì„œ ì‹¤í–‰í•˜ë©´ ëœë‹¤ê³  í•˜ëŠ”ë°...\n\n```bash\nroot@bad23fe368a6:/backend# ls\nDockerfile  alembic.ini  app  requirements.txt  tests\nroot@bad23fe368a6:/backend# alembic revision -m \"create account table\"\n  Generating\n  /backend/app/db/migrations/versions/f721febf752b_create_account_table.py\n  ...  done\n```\n\në§ˆì´ê·¸ë ˆì´ì…˜ì´ ì •ìƒì ìœ¼ë¡œ ì§„í–‰ëë‹¤!\nê·¸ë¦¬ê³  ë‹¤ìŒê³¼ ê°™ì€ íŒŒì¼ì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.\n\n```python\n# backend/app/db/migrations/versions/f721febf752b_create_account_table.py\n\"\"\"create account table\n\nRevision ID: f721febf752b\nRevises:\nCreate Date: 2022-04-27 17:21:25.945460\n\n\"\"\"\nfrom alembic import op\nimport sqlalchemy as sa\n\n\n# revision identifiers, used by Alembic.\nrevision = 'f721febf752b'\ndown_revision = None\nbranch_labels = None\ndepends_on = None\n\n\ndef upgrade():\n    pass\n\n\ndef downgrade():\n    pass\n```\n\n### ë§ˆì´ê·¸ë ˆì´ì…˜ í…ŒìŠ¤íŠ¸ ëª¨ë¸ ìƒì„± ë° í™•ì¸\n\n`env.py` íŒŒì¼ì˜\n\n```python\n# add your model's MetaData object here\n# for 'autogenerate' support\n# from myapp import mymodel\n# target_metadata = mymodel.Base.metadata\ntarget_metadata = None\n```\n\nì£¼ì„ì— ì í˜€ìˆë“¯ì´, `autogenerate` ì˜µì…˜ì„ ì‚¬ìš©í•˜ë©´ ìë™ìœ¼ë¡œ ëª¨ë¸ ê¸°ë°˜ìœ¼ë¡œ ìƒì„±í•´ì¤€ë‹¤ê³  í•œë‹¤. ë‹¤ë§Œ ì´ ê¸°ëŠ¥ì´ ì™„ë²½í•˜ì§€ëŠ” ì•Šì€ì§€, ì› ì‘ì„±ì **jeffastor**ëŠ” ë§ˆì´ê·¸ë ˆì´ì…˜ìœ¼ë¡œ ì‘ì„±ëœ ìŠ¤í¬ë¦½íŠ¸ì—\n\n```python\ndef create_cleanings_table() -> None:\n    op.create_table(\n        \"cleanings\",\n        sa.Column(\"id\", sa.Integer, primary_key=True),\n        sa.Column(\"name\", sa.Text, nullable=False, index=True),\n        sa.Column(\"description\", sa.Text, nullable=True),\n        sa.Column(\"cleaning_type\", sa.Text, nullable=False, server_default=\"spot_clean\"),\n        sa.Column(\"price\", sa.Numeric(10, 2), nullable=False),\n    )\n```\n\nì´ë¼ëŠ” í•¨ìˆ˜ë¥¼ ìƒˆë¡œ ì‘ì„±í•´ì„œ ì§„í–‰í–ˆë‹¤. **`sqlmodel`** ì„ ì‚¬ìš©í•˜ëŠ” ë§Œí¼, ì„ì‹œë¡œ ëª¨ë¸ì„ ìƒì„±í•˜ê³ , ê·¸ ëª¨ë¸ì—ì„œ ìë™ìœ¼ë¡œ ìƒì„±ëœ í…Œì´ë¸”ì—ì„œ `Column`ì„ ì¶”ì¶œí•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì§„í–‰í•œë‹¤. ì¶”í›„ ëª¨ë¸ì„ ì •ì˜í•  íŒŒì¼ ìœ„ì¹˜ë¥¼ í™•ì¸í•˜ë©´ ì˜®ê¸°ê³  ìˆ˜ì •í•  ì˜ˆì •.\n\n```bash\nâ¯ mkdir backend/app/db/models\nâ¯ touch backend/app/db/models/base.py backend/app/db/models/temp.py\n```\n\n```python\n# touch backend/app/db/models/base.py\nclass base_model(SQLModel):\n    @classmethod\n    def get_table(cls) -> Table:\n        if (table := getattr(cls, \"__table__\", None)) is None:\n            raise ValueError(\"not table\")\n        return table\n```\n\n```python\n# backend/app/db/models/temp.py\nfrom pydantic import condecimal\nfrom sqlmodel import Field\n\nfrom .base import base_model\n\n\nclass cleanings(base_model, table=True):\n    id: int | None = Field(None, primary_key=True)\n    name: str = Field(index=True)\n    description: str | None = None\n    cleaning_type: str = Field(\n        (_default_cleaning_type := \"spot_clean\"),\n        sa_column_kwargs={\"server_default\": _default_cleaning_type},\n    )\n    price: condecimal(max_digits=10, decimal_places=2)  # type: ignore\n```\n\nì´ íŠœí† ë¦¬ì–¼ì€ ì²­ì†Œ ê´€ë ¨ ì£¼ì œë¡œ ì‘ì„±ë˜ê¸°ì—, í…Œì´ë¸” ì´ë¦„ì´ `cleanings`ì´ë‹¤.\n\n> - `id`: ê° í•­ëª©ì— ëŒ€í•œ ê³ ìœ í•œ ì‹ë³„ê°’.\n> - `name`: í•´ë‹¹ í•­ëª©ì— ëŒ€í•œ ì´ë¦„. `index=True` ì˜µì…˜ìœ¼ë¡œ ì¸í•´ ë” ë¹ ë¥¸ ì¡°íšŒê°€ ê°€ëŠ¥í•˜ë‹¤.\n> - `description`: í•´ë‹¹ í•­ëª©ì— ëŒ€í•œ ì„¤ëª…ì´ì§€ë§Œ, `null`ê°’(íŒŒì´ì¬ì—ì„œëŠ” `None`ê°’)ì´ ê°€ëŠ¥í•˜ë‹¤.\n> - `cleaning_type`: í•´ë‹¹ í•­ëª©ì˜ íƒ€ì…\n> - `price`: í•´ë‹¹ í•­ëª©ì˜ ê°€ê²©\n\nëª¨ë¸ì„ ì •ì˜í–ˆìœ¼ë‹ˆ, ì´ì œ ì˜ˆì œë¥¼ ë”°ë¼ í•¨ìˆ˜ë¥¼ ì •ì˜í•œë‹¤.\n\n```python\n# backend/app/db/migrations/versions/f721febf752b_create_account_table.py\n(...)\n\ndef create_cleanings_table() -> None:\n    import sys\n    from pathlib import Path\n    sys.path.append(Path(__file__).resolve().parents[4].as_posix())\n    from app.db.models.temp import cleanings\n\n    table = cleanings.get_table()\n\n    op.create_table(\n        table.name,\n        *table.columns\n    )\n\ndef upgrade():\n    create_cleanings_table()\n\n\ndef downgrade():\n    op.drop_table('cleanings')\n```\n\nëŒ€ë¶€ë¶„ì˜ ê²½ìš° **`sqlmodel`** ì˜ `Field`ì˜ ë³€ìˆ˜ë¡œ ê°€ëŠ¥í•˜ê³ , `server_default`ì— ëŒ€í•´ì„œë§Œ ë”°ë¡œ `sa_column_kwargs`ë¡œ ì²˜ë¦¬í–ˆë‹¤. ì´ë ‡ê²Œ í•˜ì§€ ì•Šì•„ë„ ì¿¼ë¦¬ì— ì •ìƒì ìœ¼ë¡œ ê¸°ë³¸ê°’ì´ ì ìš©ë˜ëŠ” ê²ƒìœ¼ë¡œ ì•Œê³  ìˆì§€ë§Œ, í˜¹ì‹œ ëª°ë¼ì„œ..\n\nì´ì œ ë§ˆì´ê·¸ë ˆì´ì…˜ì„ ì§„í–‰í•œë‹¤.\n\n```bash\nroot@9c425f594efa:/backend# alembic upgrade head\nINFO  [alembic.env] Running migrations online\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Running upgrade  -> f721febf752b, create account table\n```\n\ní…Œì´ë¸”ì´ ì •ìƒì ìœ¼ë¡œ ìƒì„±ëëŠ”ì§€, `db` ì»¨í…Œì´ë„ˆì—ì„œ **`psql`** ì„ ì´ìš©í•´ í™•ì¸í•´ë³¸ë‹¤.\n\n```bash\nbash-5.1# psql -h localhost -U postgres --dbname=postgres\npsql (14.2)\nType \"help\" for help.\n\npostgres=# select * from cleanings;\n id | name | description | cleaning_type | price\n----+------+-------------+---------------+-------\n(0 rows)\n```\n\nì •ìƒì ìœ¼ë¡œ ìƒì„± ëœ ê²ƒì„ í™•ì¸í–ˆë‹¤.\n","mtime":"2022-08-13T00:12:20.000+09:00","href":"velog/fastapi íŠœí† ë¦¬ì–¼ -2- sql ì„œë²„ ì—°ê²°","data":{"title":"fastapi íŠœí† ë¦¬ì–¼ -2- sql ì„œë²„ ì—°ê²°","date":"2022-04-28T19:51:57.390+09:00","tags":["fastapi","alembic","postgres","python","@all"],"page":"fastapi íŠœí† ë¦¬ì–¼","summary":"fastapi ì‚¬ìš©ë²•ì„ ë‹¤ì‹œ ê³µë¶€í• ê²¸, ì°¸ê³ í• ë§Œí•œ ì¢‹ì€ ì˜ˆì œê°€ ìˆì–´ì„œ ì´ ì‹œë¦¬ì¦ˆë¥¼ ì•½ê°„ì˜ ë³€ê²½ì„ ì£¼ê³  ë”°ë¼ê°€ë³´ë ¤ í•œë‹¤."}},{"name":"fastapi íŠœí† ë¦¬ì–¼ -3- sql ëª¨ë¸ ì •ì˜","content":"\n**`fastapi`** ì‚¬ìš©ë²•ì„ ë‹¤ì‹œ ê³µë¶€í• ê²¸, ì°¸ê³ í• ë§Œí•œ ì¢‹ì€ [ì˜ˆì œ](https://www.jeffastor.com/blog/populating-cleaning-jobs-with-user-offers-in-fastapi)ê°€ ìˆì–´ì„œ ì´ ì‹œë¦¬ì¦ˆë¥¼ ì•½ê°„ì˜ ë³€ê²½ì„ ì£¼ê³  ë”°ë¼ê°€ë³´ë ¤ í•œë‹¤.\nì§€ë‚œë²ˆì²˜ëŸ¼ ì–´ì©Œë‹¤ ê·¸ë§Œë‘˜ ìˆ˜ë„ ìˆê¸´ í•˜ì§€ë§Œ...\n\n---\n\n## **cleanings** ëª¨ë¸ ìƒì„±\n\n### ëª¨ë¸ ì •ì˜\n\nì‘ì„± ì „ ë¯¸ë¦¬ ì „ë°˜ì ì¸ ë‚´ìš©ì„ í›‘ì–´ë³´ë‹ˆ, `repository`ëŠ” **`sqlmodel`** ì‚¬ìš©ì‹œ ë”±íˆ ì˜ë¯¸ê°€ ì—†ëŠ” ëª¨ë“ˆì´ë¯€ë¡œ ì œê±°í•˜ì.\në˜í•œ, ì§€ë‚œ ê¸€ì—ì„œ ì„ì‹œë¡œ ìƒì„±í•œ `models`ì˜ ìœ„ì¹˜ê°€ `db`ì˜ í•˜ìœ„ ëª¨ë“ˆì´ ì•„ë‹Œ `app`ì˜ í•˜ìœ„ ëª¨ë“ˆë¡œ ê²°ì •ëê¸°ì— ê°™ì´ ìˆ˜ì •í•œë‹¤.\n\n```bash\nâ¯ rm -rf backend/app/db/repositories\nâ¯ mv backend/app/db/models backend/app/models\nâ¯ touch backend/app/models/__init__.py\nâ¯ mv backend/app/models/base.py backend/app/models/core.py\nâ¯ mv backend/app/models/temp.py backend/app/models/cleaning.py\n```\n\n```python\n# backend/app/models/core.py\nfrom typing import Any, TypeVar, cast\n\nfrom sqlmodel import Field, SQLModel, Table\n\n_T = TypeVar(\"_T\", bound=SQLModel)\n\n\nclass fix_parse_obj_model(SQLModel):\n    \"\"\"\n    sqlmodelì—ì„œ parse_obj ë¦¬í„´ê°’ ì •ìƒì ìœ¼ë¡œ ìˆ˜ì •í•˜ê¸° ì „ê¹Œì§€ ì‚¬ìš©\n    \"\"\"\n    @classmethod\n    def parse_obj(cls: type[_T], obj: Any, update: dict[str, Any] | None = None) -> _T:\n        return cast(_T, super().parse_obj(obj, update))\n\n\nclass base_model(fix_parse_obj_model):\n    @classmethod\n    def get_table(cls) -> Table:\n        if (table := getattr(cls, \"__table__\", None)) is None:\n            raise ValueError(\"not table\")\n        return table\n\n\nclass id_model(fix_parse_obj_model):\n    id: int | None = Field(None, primary_key=True)\n```\n\n```python\n# backend/app/models/cleaning.py\nfrom enum import Enum\n\nfrom pydantic import condecimal\nfrom sqlmodel import Field\n\nfrom .core import base_model, id_model\n\nprice_decimal_type = condecimal(max_digits=10, decimal_places=2)\n\n\nclass cleaning_type_enum(str, Enum):\n    dust_up = \"dust_up\"\n    spot_clean = \"spot_clean\"\n    full_clean = \"full_clean\"\n\n\nclass cleaning_base(base_model):\n    name: str | None = None\n    description: str | None = None\n    cleaning_type: cleaning_type_enum = cleaning_type_enum.spot_clean\n    price: price_decimal_type | None = None\n\n\nclass cleaning_create(cleaning_base):\n    name: str\n    price: price_decimal_type\n\n\nclass cleaning_update(cleaning_base):\n    cleaning_type: cleaning_type_enum | None = None\n\n\nclass cleanings(id_model, cleaning_base, table=True):\n    name: str = Field(index=True)\n    cleaning_type: cleaning_type_enum = Field(\n        cleaning_type_enum.spot_clean,\n        sa_column_kwargs={\"server_default\": cleaning_type_enum.spot_clean},\n    )\n    price: price_decimal_type\n\n\nclass cleaning_public(id_model, cleaning_base):\n    ...\n```\n\n```python\n# backend/app/db/migrations/versions/f721febf752b_create_account_table.py\n(...)\n\ndef create_cleanings_table() -> None:\n    import sys\n    from pathlib import Path\n    sys.path.append(Path(__file__).resolve().parents[4].as_posix())\n    from app.models.cleaning import cleanings\n\n(...)\n```\n\n`get_table` ë©”ì†Œë“œê°€ ì •ì˜ëœ `base_model`ì„ ìƒì†í•˜ëŠ” 5ê°œ ëª¨ë¸ì€ ê° ë¦¬ì†ŒìŠ¤ì— ì‚¬ìš©ë  íŒ¨í„´ì„ ë³´ì—¬ì¤€ë‹¤.\n\n> - `cleaning_base`: ê³µìœ  ì†ì„±\n> - `cleaning_create`: ìƒˆë¡œìš´ ë¦¬ì†ŒìŠ¤ë¥¼ ìƒì„± ~ **POST**\n> - `cleaning_update`: ê¸°ì¡´ ë¦¬ì†ŒìŠ¤ë¥¼ ìˆ˜ì • ~ **PUT**\n> - `cleaning`: ë°ì´í„°ë² ì´ìŠ¤ì— ì •ì˜ë  í…Œì´ë¸”ì´ì ë ˆì½”ë“œ ~ **GET**, **POST**, **PUT**,...\n> - `cleaning_public`: ë ˆì½”ë“œì— ëŒ€í•œ ë°˜í™˜ í˜•íƒœ ~ **GET**, **POST**, **PUT**,...\n\n### `session` ëª¨ë“ˆ ì •ì˜\n\nì› ì‘ì„±ìì¸ **jeffastor**ëŠ” ì´í›„ `repository` ëª¨ë“ˆì„ ìƒì„±í•˜ì—¬ CRUD ê³¼ì •ì— í•„ìš”í•œ í”„ë¡œì„¸ìŠ¤ë¥¼ êµ¬í˜„í–ˆì§€ë§Œ, **`sqlmodel`** ì„ ì‚¬ìš©í•˜ê¸°ì— ê·¸ëŸ¬í•œ ê³¼ì •ì´ ë”°ë¡œ í•„ìš”í•˜ì§€ ì•Šë‹¤.\nì•±ì—ì„œ ì‚¬ìš©í•  `session`ì— ëŒ€í•´ì„œë§Œ ë”°ë¡œ ì •ì˜í•œë‹¤.\n\n```bash\nâ¯ touch backend/app/db/session.py\n```\n\n```python\n# backend/app/db/session.py\nfrom typing import AsyncIterator\n\nfrom fastapi import Depends, Request\nfrom sqlalchemy.ext.asyncio.engine import AsyncEngine\nfrom sqlmodel.ext.asyncio.session import AsyncSession\n\n\nasync def get_database(request: Request) -> AsyncEngine:\n    if (engine := getattr(request.app.state, \"_db\", None)) is None:\n        raise AttributeError(\"there is no database engine in request as state\")\n    return engine\n\n\nasync def get_session(\n    engine: AsyncEngine = Depends(get_database),\n) -> AsyncIterator[AsyncSession]:\n    async with AsyncSession(engine, autoflush=False, autocommit=False) as session:\n        yield session\n```\n\n## `cleanings` ëª¨ë¸ `api` ì˜ˆì‹œ\n\n### `cleanings` ë ˆì½”ë“œ ì¶”ê°€ `POST` `api` ì˜ˆì‹œ\n\nì´ì œ ì„¸ì…˜ì„ í™œìš©í•œ ê°„ë‹¨í•œ í˜•íƒœì˜ **POST** apië¥¼ ìƒì„±í•œë‹¤.\n\n```python\n# backend/app/api/routes/cleanings.py\nfrom fastapi import APIRouter, Body, Depends\nfrom sqlmodel.ext.asyncio.session import AsyncSession\nfrom starlette.status import HTTP_201_CREATED\n\nfrom ...db.session import get_session\nfrom ...models.cleaning import cleaning_create, cleaning_public, cleanings\n\nrouter = APIRouter()\n\n\n@router.get(\"/\")\nasync def get_all_cleanings() -> list[dict]:\n    cleanings = [\n        {\n            \"id\": 1,\n            \"name\": \"My house\",\n            \"cleaning_type\": \"full_clean\",\n            \"price_per_hour\": 29.99,\n        },\n        {\n            \"id\": 2,\n            \"name\": \"Someone else's house\",\n            \"cleaning_type\": \"spot_clean\",\n            \"price_per_hour\": 19.99,\n        },\n    ]\n    return cleanings\n\n\n@router.post(\n    \"/\",\n    response_model=cleaning_public,\n    name=\"cleanings:create-cleaning\",\n    status_code=HTTP_201_CREATED,\n)\nasync def create_new_cleaning(\n    new_cleaning: cleaning_create = Body(..., embed=True),\n    session: AsyncSession = Depends(get_session),\n) -> cleanings:\n    # data = cleanings.from_orm(new_cleaning) ìœ¼ë¡œ í•´ë„ ê°€ëŠ¥\n    # exclude_none=True, exclude_unset=True ì˜µì…˜ì„ ìœ„í•´ parse_obj ì‚¬ìš©\n    data = cleanings.parse_obj(\n        new_cleaning.dict(\n            exclude_none=True,\n            exclude_unset=True,\n        )\n    )\n    session.add(data)\n    await session.flush()\n    await session.commit()\n    await session.refresh(data)\n\n    return data\n```\n\nì´ì œ **`docker`** ë¡œ ì„œë¹„ìŠ¤ë¥¼ ì‹¤í–‰í•˜ê³ , [http://localhost:8000/docs](http://localhost:8000/docs)ì—ì„œ ìƒì„±í•œ **POST** apiê°€ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸í•œë‹¤.\n\n`body`ì— ê°’ì„\n\n```yaml\n{\n  'new_cleaning':\n    { 'name': 'string', 'description': 'string', 'cleaning_type': 'asd', 'price': 0 },\n}\n```\n\nì´ë ‡ê²Œ ì£¼ë©´\n\n```yaml\n{\n  'detail':\n    [\n      {\n        'loc': ['body', 'new_cleaning', 'cleaning_type'],\n        'msg': \"value is not a valid enumeration member; permitted: 'dust_up', 'spot_clean', 'full_clean'\",\n        'type': 'type_error.enum',\n        'ctx': { 'enum_values': ['dust_up', 'spot_clean', 'full_clean'] },\n      },\n    ],\n}\n```\n\nì´ë ‡ê²Œ ì™œ ì—ëŸ¬(422)ê°€ ë‚˜ëŠ”ì§€ ì¹œì ˆí•˜ê²Œ ì„¤ëª…ë„ í•´ì¤€ë‹¤.\nì •ìƒì ì¸ ê°’ì„ ë„£ìœ¼ë©´\n\n```yaml\n{\n  'new_cleaning':\n    { 'name': 'test', 'description': 'test', 'cleaning_type': 'dust_up', 'price': 123 },\n}\n```\n\nì„¤ì •í•œëŒ€ë¡œ\n\n```yaml\n{\n  'name': 'test',\n  'description': 'test',\n  'cleaning_type': 'dust_up',\n  'price': 123,\n  'id': 1,\n}\n```\n\n`cleaning_public`ì˜ ìŠ¤í‚¤ë§ˆì— ë§ê²Œ ê°’ì„ ë°˜í™˜(201)í•œë‹¤. ë§Œì•½ `cleaning_public`ê°€ `id_model`ì„ ìƒì†í•˜ë„ë¡ ì •ì˜í•˜ì§€ ì•Šì•˜ë‹¤ë©´ `id`ì†ì„±ì€ ìƒëµëœ ì±„ë¡œ ë°˜í™˜ëì„ ê²ƒì´ë‹¤.\n\n> **`fastapi`** ê°€ ìœ„ **POST** apiì—ì„œ ì‹¤í–‰í•œ ê³¼ì •\n>\n> 1. **`json`** í˜•íƒœì˜ `body`ë¥¼ ì½ëŠ”ë‹¤.\n> 2. `body`ì˜ ê°’ì„ ê²€ì¦í•œë‹¤. ~ **`pydantic`**\n> 3. ê²€ì¦ ê²°ê³¼ì— ë”°ë¼ ì—ëŸ¬ë¥¼ ë°˜í™˜í•˜ê±°ë‚˜, ìƒì„±í•œ ëª¨ë¸ ê°ì²´ë¡œ ê³„ì‚°í•œ ê²°ê³¼ë¥¼ ë°˜í™˜í•œë‹¤.\n\n### `FastAPI`ì˜ `DI` ì‚¬ìš©ë²•\n\n`Depends`ë¡œ ë³€ìˆ˜ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë°©ì‹ì´ ìƒì†Œí•  ìˆ˜ ìˆë‹¤. ì‚¬ìš©ìì˜ ìš”ì²­ì„ ì²˜ë¦¬í•˜ëŠ” ë°©ì‹ì„ ì‚¬ì „ì— í˜¸ì¶œ ê°€ëŠ¥í•œ í˜•íƒœë¡œ ì •ì˜í•˜ê³ , ê·¸ ê³¼ì •ì„ í•œë²ˆì— ì‹¤í–‰í•œ ê²°ê³¼ë¥¼ íŒŒë¼ë¯¸í„°ë¡œ ë°›ì•„ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ í•œë‹¤.\n\nì§ì „ì— ìƒì„±í•œ `session.py`ì—ì„œ `get_database`ê°€ `request`ë¥¼ ë°›ê³ ,\n`get_session`ì´ `get_database`ë¥¼ ë°›ê³ ,\n`create_new_cleaning`ì´ `get_session`ì„ ë°›ì•„ì„œ `session`ê°ì²´ë¥¼ íŒŒë¼ë¯¸í„°ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ í•œë‹¤.\n\në§ˆì§€ë§‰ìœ¼ë¡œ, sql ì„œë²„ì—ì„œ ì •ìƒì ìœ¼ë¡œ ë ˆì½”ë“œê°€ ì…ë ¥ëëŠ”ì§€ í™•ì¸í•´ë³¸ë‹¤.\n\n```bash\nbash-5.1# psql -h localhost -U postgres --dbname=postgres\npsql (14.2)\nType \"help\" for help.\n\npostgres=# select * from cleanings;\n name | description | cleaning_type | price  | id\n------+-------------+---------------+--------+----\n test | test        | dust_up       | 123.00 |  1\n(1 row)\n```\n\në‹¤ìŒì—ëŠ” **`pytest`** ë¥¼ í™œìš©í•œë‹¤.\n**`alembic`** ì²˜ëŸ¼ ì‚¬ìš©í•´ë³¸ì ì´ ì—†ê¸°ì— ê¸°ëŒ€ê°€ ëœë‹¤.\n","mtime":"2022-08-13T00:12:20.000+09:00","href":"velog/fastapi íŠœí† ë¦¬ì–¼ -3- sql ëª¨ë¸ ì •ì˜","data":{"title":"fastapi íŠœí† ë¦¬ì–¼ -3- sql ëª¨ë¸ ì •ì˜","date":"2022-04-28T21:51:36.869+09:00","tags":["fastapi","python","sqlmodel","@all"],"page":"fastapi íŠœí† ë¦¬ì–¼","summary":"fastapi ì‚¬ìš©ë²•ì„ ë‹¤ì‹œ ê³µë¶€í• ê²¸, ì°¸ê³ í• ë§Œí•œ ì¢‹ì€ ì˜ˆì œê°€ ìˆì–´ì„œ ì´ ì‹œë¦¬ì¦ˆë¥¼ ì•½ê°„ì˜ ë³€ê²½ì„ ì£¼ê³  ë”°ë¼ê°€ë³´ë ¤ í•œë‹¤."}},{"name":"fastapi íŠœí† ë¦¬ì–¼ -4- pytest ì ìš© ë° ì‹¤í–‰","content":"\n**`fastapi`** ì‚¬ìš©ë²•ì„ ë‹¤ì‹œ ê³µë¶€í• ê²¸, ì°¸ê³ í• ë§Œí•œ ì¢‹ì€ [ì˜ˆì œ](https://www.jeffastor.com/blog/populating-cleaning-jobs-with-user-offers-in-fastapi)ê°€ ìˆì–´ì„œ ì´ ì‹œë¦¬ì¦ˆë¥¼ ì•½ê°„ì˜ ë³€ê²½ì„ ì£¼ê³  ë”°ë¼ê°€ë³´ë ¤ í•œë‹¤.\nì§€ë‚œë²ˆì²˜ëŸ¼ ì–´ì©Œë‹¤ ê·¸ë§Œë‘˜ ìˆ˜ë„ ìˆê¸´ í•˜ì§€ë§Œ...\n\n---\n\n## `pytest`ë¥¼ ì‚¬ìš©í•œ í…ŒìŠ¤íŠ¸ ì½”ë“œ ì‘ì„± ë° ì‹¤í–‰\n\ní…ŒìŠ¤íŠ¸ ì½”ë“œë¥¼ ì‘ì„±í•˜ëŠ”ê²Œ ë„ì›€ì´ ëœë‹¤ ì•„ë‹ˆë‹¤ë¡œ ë§ì´ ì‹¸ìš°ì§€ë§Œ, ì ì–´ë„ **jeffastor** ìì‹ ì€ ì´ ê³¼ì • ìì²´ë¥¼ ì¦ê¸°ê³  ìˆë‹¤ê³  ë°íˆë©°, **`pytest`** ë¥¼ ì ìš©í•˜ëŠ”ë° í•œ ì±•í„°ë¥¼ í• ì• í•œë‹¤.\n\n### íŒ¨í‚¤ì§€ ì„¤ì¹˜\n\nìš°ì„  í…ŒìŠ¤íŠ¸ ì½”ë“œ ì¢…ì†ì„± íŒ¨í‚¤ì§€ë¶€í„° ì„¤ì¹˜í•œë‹¤.\n\n```bash\nâ¯ poetry add --dev pytest pytest-asyncio httpx asgi-lifespan\n```\n\n> **`pytest-asyncio`** ëŠ” ë¹„ë™ê¸°ë¡œ ì‘ì„±ëœ apië¥¼ í…ŒìŠ¤íŠ¸í•˜ëŠ”ë° ì‚¬ìš©í•˜ê³ , **asgi-lifespan`** ì€ ì•±ì„ ì‹¤í–‰í•˜ì§€ ì•Šê³  í…ŒìŠ¤íŠ¸í•˜ê¸° ìœ„í•´ ì‚¬ìš©í•œë‹¤.\n\nê·¸ë¦¬ê³  ì´ì œ **`pytest`** ê°€ **`docker`** ì—ì„œ ì‹¤í–‰ë  ìˆ˜ ìˆê²Œ, ê°œë°œìš© ì¢…ì†ì„± íŒ¨í‚¤ì§€ë„ **`docker`** ì´ë¯¸ì§€ë¥¼ ë¹Œë“œê³¼ì •ì— ì¶”ê°€í•œë‹¤.\n\n```bash\nâ¯ poetry export -f requirements.txt --output backend/requirements.txt --without-hashes --dev\nâ¯ docker-compose build\n```\n\n### `pytest` ì„¤ì • íŒŒì¼ ì‘ì„±\n\nì´ì œ ê¸°ë³¸ì ì¸ í…ŒìŠ¤íŠ¸ ì½”ë“œë¥¼ ì‘ì„±í•œë‹¤.\n\n```bash\nâ¯ touch backend/tests/__init__.py backend/tests/conftest.py backend/tests/test_cleanings.py\n```\n\n```python\n# backend/tests/conftest.py\nimport os\nimport warnings\nfrom typing import AsyncIterator\n\nimport alembic\nimport pytest\nfrom alembic.config import Config\nfrom asgi_lifespan import LifespanManager\nfrom fastapi import FastAPI\nfrom httpx import AsyncClient\nfrom sqlalchemy.ext.asyncio.engine import AsyncEngine\nfrom sqlmodel.ext.asyncio.session import AsyncSession\n\n\n# Apply migrations at beginning and end of testing session\n@pytest.fixture(scope=\"session\")\ndef apply_migrations():\n    warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n    os.environ[\"TESTING\"] = \"1\"\n    config = Config(\"alembic.ini\")\n\n    alembic.command.upgrade(config, \"head\")  # type: ignore\n    yield\n    alembic.command.downgrade(config, \"base\")  # type: ignore\n\n\n# Create a new application for testing\n@pytest.fixture\ndef app(apply_migrations: None) -> FastAPI:\n    from app.api.server import get_application\n\n    return get_application()\n\n\n# Grab a reference to our database when needed\n@pytest.fixture\ndef engine(app: FastAPI) -> AsyncEngine:\n    return app.state._db\n\n\n@pytest.fixture\nasync def session(engine: AsyncEngine) -> AsyncSession:\n    session = AsyncSession(engine, autoflush=False, autocommit=False)\n    try:\n        return session\n    finally:\n        await session.close()\n\n\n# Make requests in our tests\n@pytest.fixture\nasync def client(app: FastAPI) -> AsyncIterator[AsyncClient]:\n    async with LifespanManager(app):\n        async with AsyncClient(\n            app=app,\n            base_url=\"http://testserver\",\n            headers={\"Content-Type\": \"application/json\"},\n        ) as client:\n            yield client\n\n```\n\n[ì›ë¬¸](https://www.jeffastor.com/blog/testing-fastapi-endpoints-with-docker-and-pytest)ì— ì„¤ëª…ì´ ê½¤ ìˆìœ¼ë‹ˆ ì½ì–´ë³´ë©´ ì¢‹ì„ë“¯.\n\n### í…ŒìŠ¤íŠ¸ ë°ì´í„°ë² ì´ìŠ¤ ì—”ì§„ ë° ë§ˆì´ê·¸ë ˆì´ì…˜ ì„¤ì •\n\nì¶”ê°€ë¡œ í…ŒìŠ¤íŠ¸ í™˜ê²½ì—ì„œ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•˜ë„ë¡, ê¸°ì¡´ì— ì‘ì„±í•œ ëª¨ë“ˆì„ ìˆ˜ì •í•œë‹¤.\n\n```python\n# backend/app/db/engine.py\nfrom os import getenv\n\nfrom sqlalchemy.engine.url import URL\nfrom sqlalchemy.ext.asyncio import AsyncEngine, create_async_engine\nfrom sqlalchemy.pool import QueuePool\n\nfrom ..core.config import DATABASE_URL\n\n\ndef is_test() -> bool:\n    return (env_val := getenv(\"TESTING\", None)) is not None and bool(env_val)\n\n\ndef get_test_url(url: URL) -> URL:\n    if url.database is None:\n        raise ValueError(\"database name is None\")\n\n    return url.set(database=f\"{url.database}_test\")\n\n\ndef get_test_engine(engine: AsyncEngine) -> AsyncEngine:\n    if not is_test():\n        return engine\n    return create_engine_from_url(get_test_url(engine.url))\n\n\ndef create_engine_from_url(url: str | URL, **kwargs: Any) -> AsyncEngine:\n    return create_async_engine(\n        url, pool_size=10, poolclass=QueuePool, pool_pre_ping=True, **kwargs\n    )\n\n\nengine = create_engine_from_url(DATABASE_URL)\n```\n\n```python\n# backend/app/db/tasks.py\n(...)\n\nfrom .engine import engine, get_test_engine\n\n(...)\n\nasync def connect_to_db(app: FastAPI) -> None:\n    _engine = get_test_engine(engine)\n\n    try:\n        async with _engine.connect():\n            logger.info(\n                f\"connected db: {_engine.url.render_as_string(hide_password=True)}\"\n            )\n        app.state._db = _engine\n    except Exception as e:\n        logger.warning(\"--- DB CONNECTION ERROR ---\")\n        logger.warning(e)\n        logger.warning(\"--- DB CONNECTION ERROR ---\")\n\n(...)\n```\n\n```python\n# backend/app/db/migrations/env.py\nimport asyncio\nimport logging\nimport pathlib\nimport sys\nfrom logging.config import fileConfig\nfrom typing import cast\n\nfrom alembic import context\nfrom sqlalchemy import engine_from_config, pool\nfrom sqlalchemy.exc import InvalidRequestError\nfrom sqlalchemy.ext.asyncio import AsyncEngine\nfrom sqlalchemy.future.engine import Engine\n\nsys.path.append(str(pathlib.Path(__file__).resolve().parents[3]))\nfrom app.db.engine import engine, get_test_url, is_test\n\n# this is the Alembic Config object, which provides\n# access to the values within the .ini file in use.\nconfig = context.config\n\n# Interpret the config file for Python logging.\n# This line sets up loggers basically.\nif config.config_file_name is not None:\n    fileConfig(config.config_file_name)\nlogger = logging.getLogger(\"alembic.env\")\n\n# add your model's MetaData object here\n# for 'autogenerate' support\n# from myapp import mymodel\n# target_metadata = mymodel.Base.metadata\ntarget_metadata = None\n\n# other values from the config, defined by the needs of env.py,\n# can be acquired:\n# my_important_option = config.get_main_option(\"my_important_option\")\n# ... etc.\n\n\ndef run_migrations_offline():\n    \"\"\"Run migrations in 'offline' mode.\n\n    This configures the context with just a URL\n    and not an Engine, though an Engine is acceptable\n    here as well.  By skipping the Engine creation\n    we don't even need a DBAPI to be available.\n\n    Calls to context.execute() here emit the given string to the\n    script output.\n\n    \"\"\"\n    if is_test():\n        raise InvalidRequestError(\n            \"Running testing migrations offline currently not permitted.\"\n        )\n\n    # url = config.get_main_option(\"sqlalchemy.url\")\n    context.configure(\n        # url=url,\n        url=engine.url.render_as_string(hide_password=False),\n        target_metadata=target_metadata,\n        literal_binds=True,\n        dialect_opts={\"paramstyle\": \"named\"},\n    )\n\n    with context.begin_transaction():\n        context.run_migrations()\n\n\ndef do_run_migrations(connection):\n    context.configure(connection=connection, target_metadata=target_metadata)\n\n    with context.begin_transaction():\n        context.run_migrations()\n\n\nasync def run_migrations_online():\n    \"\"\"Run migrations in 'online' mode.\n\n    In this scenario we need to create an Engine\n    and associate a connection with the context.\n\n    \"\"\"\n    url = engine.url\n    if is_test():\n        from sqlalchemy import text\n\n        url = get_test_url(url)\n        async with engine.connect() as conn:\n            conn = await conn.execution_options(isolation_level=\"AUTOCOMMIT\")\n            await conn.execute(text(f\"drop database if exists {url.database}\"))\n            await conn.execute(text(f\"create database {url.database}\"))\n\n    config.set_main_option(\"sqlalchemy.url\", url.render_as_string(hide_password=False))\n    connectable = AsyncEngine(\n        cast(\n            Engine,\n            engine_from_config(\n                config.get_section(config.config_ini_section),\n                prefix=\"sqlalchemy.\",\n                poolclass=pool.NullPool,\n                future=True,\n            ),\n        )\n    )\n\n    async with connectable.connect() as connection:\n        await connection.run_sync(do_run_migrations)\n\n    await connectable.dispose()\n\n\nif context.is_offline_mode():\n    logger.info(\"Running migrations offline\")\n    run_migrations_offline()\nelse:\n    logger.info(\"Running migrations online\")\n    asyncio.run(run_migrations_online())\n```\n\nì´ì œ `TESTING`ì´ë¼ëŠ” í™˜ê²½ë³€ìˆ˜ ê°’ì´ ì •ìƒì ìœ¼ë¡œ ì…ë ¥ë˜ì–´ ìˆë‹¤ë©´ í…ŒìŠ¤íŠ¸ DBë¥¼ ì‚¬ìš©í•œë‹¤. ë˜í•œ, ë§ˆì´ê·¸ë ˆì´ì…˜ì‹œ í…ŒìŠ¤íŠ¸ DBê°€ ì´ë¯¸ ìƒì„±ë˜ì–´ ìˆë‹¤ë©´, í•´ë‹¹ DBë¥¼ ì§€ìš°ê³  ìƒˆë¡œ ìƒì„±í•œë‹¤.\n\n### í…ŒìŠ¤íŠ¸ ì½”ë“œ ì‘ì„±\n\nì´ì œ ì´ì „ì— ì‘ì„±í•œ ë¼ìš°í„°ë¥¼ í…ŒìŠ¤íŠ¸ í•˜ëŠ” í…ŒìŠ¤íŠ¸ ì½”ë“œë¥¼ ì‘ì„±í•œë‹¤.\n\n```python\n# backend/tests/test_cleanings.py\nimport pytest\nfrom fastapi import FastAPI\nfrom httpx import AsyncClient\nfrom starlette.status import HTTP_404_NOT_FOUND, HTTP_422_UNPROCESSABLE_ENTITY\n\n\nclass TestCleaningsRoutes:\n    @pytest.mark.asyncio\n    async def test_routes_exist(self, app: FastAPI, client: AsyncClient) -> None:\n        res = await client.post(app.url_path_for(\"cleanings:create-cleaning\"), json={})\n        assert res.status_code != HTTP_404_NOT_FOUND\n\n    @pytest.mark.asyncio\n    async def test_invalid_input_raises_error(\n        self, app: FastAPI, client: AsyncClient\n    ) -> None:\n        res = await client.post(app.url_path_for(\"cleanings:create-cleaning\"), json={})\n        assert res.status_code != HTTP_422_UNPROCESSABLE_ENTITY\n```\n\nì´ í…ŒìŠ¤íŠ¸ ì½”ë“œëŠ” ìš°ì„  ì´ì „ ì±•í„°ì—ì„œ ì‘ì„±í•œ `cleanings:create-cleaning` apiê°€ ì¡´ì¬í•˜ëŠ”ì§€, ê·¸ë¦¬ê³  ì •ìƒì ìœ¼ë¡œ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸í•œë‹¤.\n\nì´ì „ì— ì–´ë–»ê²Œ ì‚¬ìš©ë˜ëŠ”ì§€ ëª°ëë˜ `conftest.py`ì—ì„œ `pytest.fixture`ë¡œ ë°ì½”ë ˆì´íŠ¸ëœ í•¨ìˆ˜ `app`, `client`ê°€ ì—¬ê¸°ì„œ ì‚¬ìš©ëœë‹¤. `TestCleaningsRoutes`ì˜ ê° ë©”ì†Œë“œì˜ íŒŒë¼ë¯¸í„°ì™€ ì´ë¦„ì´ ì¼ì¹˜í•˜ëŠ” í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬, ë¦¬í„´ê°’ì„ íŒŒë¼ë¯¸í„°ë¡œ ì‚¬ìš©í•œë‹¤.\n\n`TestCleaningsRoutes.test_invalid_input_raises_error`ì—ì„œ `json` íŒŒë¼ë¯¸í„°ë¡œ ë¹ˆ ë”•ì…”ë„ˆë¦¬ë¥¼ ì œê³µí–ˆê¸°ì—, ì´ì „ì— ì‘ì„±í•œ ëª¨ë¸ì¸ `cleaning_create`ì˜ í•„ìˆ˜ ê°’ì¸ `name`ê³¼ `price`ì´ ì—†ì–´ì„œ ì—ëŸ¬ê°€ ë°œìƒí•  ê²ƒìœ¼ë¡œ ì˜ˆìƒëœë‹¤.\n\nì´ì œ ì‹¤ì œë¡œ í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•´ë³¸ë‹¤.\n\n```bash\nroot@3190a4d68f18:/backend# pytest -v\n==================================================== test session starts =====================================================\nplatform linux -- Python 3.10.4, pytest-7.1.2, pluggy-1.0.0 -- /usr/local/bin/python\ncachedir: .pytest_cache\nrootdir: /backend\nplugins: anyio-3.5.0, asyncio-0.18.3\nasyncio: mode=legacy\ncollected 2 items\n\ntests/test_cleanings.py::TestCleaningsRoutes::test_routes_exist PASSED                                                 [ 50%]\ntests/test_cleanings.py::TestCleaningsRoutes::test_invalid_input_raises_error FAILED                                   [100%]\ntests/test_cleanings.py::TestCleaningsRoutes::test_invalid_input_raises_error ERROR                                    [100%]\n\n=========================================================== ERRORS ===========================================================\n__________________________ ERROR at teardown of TestCleaningsRoutes.test_invalid_input_raises_error __________________________\n\n    @pytest.fixture(scope=\"session\")\n    def apply_migrations():\n        warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n        os.environ[\"TESTING\"] = \"1\"\n        config = Config(\"alembic.ini\")\n\n        alembic.command.upgrade(config, \"head\")  # type: ignore\n        yield\n>       alembic.command.downgrade(config, \"base\")  # type: ignore\n\ntests/conftest.py:24:\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n(...)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n>   ???\nE   RuntimeError: Task <Task pending name='Task-20' coro=<run_migrations_online() running at /backend/./app/db/migrations/env.py:88> cb=[_run_until_complete_cb() at /usr/local/lib/python3.10/asyncio/base_events.py:184]> got Future <Future pending cb=[Protocol._on_waiter_completed()]> attached to a different loop\n\nasyncpg/protocol/protocol.pyx:338: RuntimeError\n-------------------------------------------------- Captured stderr teardown --------------------------------------------------\nINFO  [alembic.env] Running migrations online\n========================================================== FAILURES ==========================================================\n____________________________________ TestCleaningsRoutes.test_invalid_input_raises_error _____________________________________\n\nself = <tests.test_cleanings.TestCleaningsRoutes object at 0x7fc9e092b610>\napp = <fastapi.applications.FastAPI object at 0x7fc9e0928eb0>, client = <httpx.AsyncClient object at 0x7fc9df873640>\n\n    @pytest.mark.asyncio\n    async def test_invalid_input_raises_error(\n        self, app: FastAPI, client: AsyncClient\n    ) -> None:\n        res = await client.post(app.url_path_for(\"cleanings:create-cleaning\"), json={})\n>       assert res.status_code != HTTP_422_UNPROCESSABLE_ENTITY\nE       assert 422 != 422\nE        +  where 422 = <Response [422 Unprocessable Entity]>.status_code\n\ntests/test_cleanings.py:18: AssertionError\n====================================================== warnings summary ======================================================\n../usr/local/lib/python3.10/site-packages/pytest_asyncio/plugin.py:191\n  /usr/local/lib/python3.10/site-packages/pytest_asyncio/plugin.py:191: DeprecationWarning: The 'asyncio_mode' default value will change to 'strict' in future, please explicitly use 'asyncio_mode=strict' or 'asyncio_mode=auto' in pytest configuration file.\n    config.issue_config_time_warning(LEGACY_MODE, stacklevel=2)\n\n../usr/local/lib/python3.10/site-packages/pytest_asyncio/plugin.py:230\n  /usr/local/lib/python3.10/site-packages/pytest_asyncio/plugin.py:230: DeprecationWarning: '@pytest.fixture' is applied to <fixture client, file=/backend/tests/conftest.py, line=42> in 'legacy' mode, please replace it with '@pytest_asyncio.fixture' as a preparation for switching to 'strict' mode (or use 'auto' mode to seamlessly handle all these fixtures as asyncio-driven).\n    warnings.warn(\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n================================================== short test summary info ===================================================\nFAILED tests/test_cleanings.py::TestCleaningsRoutes::test_invalid_input_raises_error - assert 422 != 422\nERROR tests/test_cleanings.py::TestCleaningsRoutes::test_invalid_input_raises_error - RuntimeError: Task <Task pending name...\n====================================== 1 failed, 1 passed, 2 warnings, 1 error in 0.44s ======================================\nsys:1: SAWarning: The garbage collector is trying to clean up connection <AdaptedConnection <asyncpg.connection.Connection object at 0x7fc9e082a6c0>>. This feature is unsupported on async dbapi, since no IO can be performed at this stage to reset the connection. Please close out all connections when they are no longer used, calling ``close()`` or using a context manager to manage their lifetime.\n```\n\nì˜ˆìƒí–ˆë˜ ì²«ë²ˆì§¸ì™€ ë‹¬ë¦¬, ë‘ë²ˆì§¸ ì—ëŸ¬ê°€ ë‹¹í™©ìŠ¤ëŸ½ë‹¤. í™•ì¸í•´ë³´ë‹ˆ ë¹„ë™ê¸° ì—”ì§„ì„ **`pytest`** ì—ì„œ ì‚¬ìš©í•  ë•Œ, ì´ë²¤íŠ¸ ë£¨í”„ ë•Œë¬¸ì— ëŸ°íƒ€ì„ ì—ëŸ¬ê°€ ë°œìƒí–ˆë‹¤. **`pytest`** ì— ìµìˆ™í•˜ì§€ ì•Šê¸°ì—, í•´ê²°í•  ë°©ë²• ë˜í•œ ë‹¹ì¥ ì•Œì•„ë‚´ê¸°ê°€ ì–´ë µë‹¤. ê¸‰í•œëŒ€ë¡œ **`alembic`** ì‚¬ìš©ì‹œ ë™ê¸° ì—”ì§„ì„ ì‚¬ìš©í•˜ê¸°ë¡œ í–ˆë‹¤.\n\n```bash\nâ¯ poetry add --dev psycopg2-binary\nâ¯ poetry export -f requirements.txt --output backend/requirements.txt --without-hashes --dev\nâ¯ docker-compose build\n```\n\n```python\n# backend/app/db/engine.py\nfrom os import getenv\nfrom typing import Any, Literal, overload\n\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.engine.url import URL\nfrom sqlalchemy.ext.asyncio import AsyncEngine, create_async_engine\nfrom sqlalchemy.future.engine import Engine\nfrom sqlalchemy.pool import QueuePool\n\nfrom ..core.config import DATABASE_URL\n\n\ndef is_test() -> bool:\n    return (env_val := getenv(\"TESTING\", None)) is not None and bool(env_val)\n\n\ndef get_test_url(url: URL) -> URL:\n    if url.database is None:\n        raise ValueError(\"database name is None\")\n\n    return url.set(database=f\"{url.database}_test\")\n\n\ndef get_engine_kwargs(**kwargs: Any) -> dict[str, Any]:\n    return {\n        \"pool_size\": 10,\n        \"poolclass\": QueuePool,\n        \"pool_pre_ping\": True,\n        \"future\": True,\n    } | kwargs\n\n\n@overload\ndef get_test_engine(engine: AsyncEngine) -> AsyncEngine:\n    ...\n\n\n@overload\ndef get_test_engine(engine: AsyncEngine, is_sync: Literal[True] = ...) -> Engine:\n    ...\n\n\n@overload\ndef get_test_engine(engine: AsyncEngine, is_sync: Literal[False] = ...) -> AsyncEngine:\n    ...\n\n\n@overload\ndef get_test_engine(engine: AsyncEngine, is_sync: bool = ...) -> AsyncEngine | Engine:\n    ...\n\n\ndef get_test_engine(engine: AsyncEngine, is_sync: bool = False) -> AsyncEngine | Engine:\n    if is_test():\n        engine = create_engine_from_url(\n            get_test_url(engine.url), pool_pre_ping=pool_pre_ping\n        )\n\n    if is_sync:\n        return convert_async_to_sync(engine)\n    return engine\n\n\ndef convert_async_to_sync(engine: AsyncEngine, **kwargs: Any) -> Engine:\n    return create_sync_engine_from_url(\n        engine.url.set(drivername=engine.url.drivername.split(\"+\")[0]), **kwargs\n    )\n\n\ndef create_sync_engine_from_url(url: str | URL, **kwargs: Any) -> Engine:\n    return create_engine(url, **get_engine_kwargs(**kwargs))\n\n\ndef create_engine_from_url(url: str | URL, **kwargs: Any) -> AsyncEngine:\n    return create_async_engine(url, **get_engine_kwargs(**kwargs))\n\n\nengine = create_engine_from_url(DATABASE_URL)\n```\n\n```python\n# backend/app/db/migrations/env.py\nimport logging\nimport pathlib\nimport sys\nfrom logging.config import fileConfig\n\nfrom alembic import context\nfrom sqlalchemy import engine_from_config, pool\nfrom sqlalchemy.exc import InvalidRequestError\n\nsys.path.append(str(pathlib.Path(__file__).resolve().parents[3]))\nfrom app.db.engine import engine, get_test_engine, is_test\n\n# this is the Alembic Config object, which provides\n# access to the values within the .ini file in use.\nconfig = context.config\n\n# Interpret the config file for Python logging.\n# This line sets up loggers basically.\nif config.config_file_name is not None:\n    fileConfig(config.config_file_name)\nlogger = logging.getLogger(\"alembic.env\")\n\n# add your model's MetaData object here\n# for 'autogenerate' support\n# from myapp import mymodel\n# target_metadata = mymodel.Base.metadata\ntarget_metadata = None\n\n# other values from the config, defined by the needs of env.py,\n# can be acquired:\n# my_important_option = config.get_main_option(\"my_important_option\")\n# ... etc.\n\n\ndef run_migrations_offline():\n    \"\"\"Run migrations in 'offline' mode.\n\n    This configures the context with just a URL\n    and not an Engine, though an Engine is acceptable\n    here as well.  By skipping the Engine creation\n    we don't even need a DBAPI to be available.\n\n    Calls to context.execute() here emit the given string to the\n    script output.\n\n    \"\"\"\n    if is_test():\n        raise InvalidRequestError(\n            \"Running testing migrations offline currently not permitted.\"\n        )\n\n    # url = config.get_main_option(\"sqlalchemy.url\")\n    context.configure(\n        # url=url,\n        url=engine.url.render_as_string(hide_password=False),\n        target_metadata=target_metadata,\n        literal_binds=True,\n        dialect_opts={\"paramstyle\": \"named\"},\n    )\n\n    with context.begin_transaction():\n        context.run_migrations()\n\n\ndef do_run_migrations(connection):\n    context.configure(connection=connection, target_metadata=target_metadata)\n\n    with context.begin_transaction():\n        context.run_migrations()\n\n\ndef run_migrations_online():\n    \"\"\"Run migrations in 'online' mode.\n\n    In this scenario we need to create an Engine\n    and associate a connection with the context.\n\n    \"\"\"\n    _engine = get_test_engine(engine, is_sync=True)\n    url = _engine.url\n\n    if is_test():\n        from sqlalchemy import text\n\n        with _engine.connect() as conn:\n            conn = conn.execution_options(isolation_level=\"AUTOCOMMIT\")\n            conn.execute(text(f\"drop database if exists {url.database}\"))\n            conn.execute(text(f\"create database {url.database}\"))\n\n    config.set_main_option(\"sqlalchemy.url\", url.render_as_string(hide_password=False))\n    connectable = engine_from_config(\n        config.get_section(config.config_ini_section),\n        prefix=\"sqlalchemy.\",\n        poolclass=pool.NullPool,\n        future=True,\n    )\n\n    with connectable.connect() as connection:\n        do_run_migrations(connection)\n\n    connectable.dispose()\n\n\nif context.is_offline_mode():\n    logger.info(\"Running migrations offline\")\n    run_migrations_offline()\nelse:\n    logger.info(\"Running migrations online\")\n    run_migrations_online()\n```\n\nì´ì œ ë‹¤ì‹œ **`pytest`** ë¥¼ ì‹¤í–‰í•´ë³´ë©´\n\n```bash\n(...)\n\n================================================== short test summary info ===================================================\nFAILED tests/test_cleanings.py::TestCleaningsRoutes::test_invalid_input_raises_error - assert 422 != 422\n================================================ 1 failed, 1 passed in 0.35s =================================================\n```\n\nì •ìƒì ìœ¼ë¡œ 2ë²ˆì§¸ ë©”ì†Œë“œë§Œ ì—ëŸ¬ë¥¼ ë°œìƒì‹œí‚¨ë‹¤.\nì´ì œ ì´ì „ì— ì‘ì„±í•œ **POST** apiì— ëŒ€í•œ í…ŒìŠ¤íŠ¸ ì½”ë“œë¥¼ ì‘ì„±í•´ë³´ì.\n\n```python\n# backend/app/models/cleaning.py\n(...)\n\nclass cleaning_update(cleaning_base):\n    cleaning_type: cleaning_type_enum | None = None\n\n(...)\n```\n\n```python\n# backend/tests/test_cleanings.py\nimport orjson\nimport pytest\nfrom app.models.cleaning import cleaning_create\nfrom fastapi import FastAPI\nfrom httpx import AsyncClient\nfrom starlette.status import (\n    HTTP_201_CREATED,\n    HTTP_404_NOT_FOUND,\n    HTTP_422_UNPROCESSABLE_ENTITY,\n)\n\n# decorate all tests with @pytest.mark.asyncio\npytestmark = pytest.mark.asyncio\n\n\n@pytest.fixture\ndef new_cleaning():\n    return cleaning_create.parse_obj(\n        dict(\n            name=\"test cleaning\",\n            description=\"test description\",\n            price=0.00,\n            cleaning_type=\"spot_clean\",\n        )\n    )\n\n\nclass TestCleaningsRoutes:\n    async def test_routes_exist(self, app: FastAPI, client: AsyncClient) -> None:\n        res = await client.post(app.url_path_for(\"cleanings:create-cleaning\"), json={})\n        assert res.status_code != HTTP_404_NOT_FOUND\n\n    async def test_invalid_input_raises_error(\n        self, app: FastAPI, client: AsyncClient\n    ) -> None:\n        res = await client.post(app.url_path_for(\"cleanings:create-cleaning\"), json={})\n        assert res.status_code == HTTP_422_UNPROCESSABLE_ENTITY\n\n\nclass TestCreateCleaning:\n    async def test_valid_input_creates_cleaning(\n        self, app: FastAPI, client: AsyncClient, new_cleaning: cleaning_create\n    ) -> None:\n        res = await client.post(\n            app.url_path_for(\"cleanings:create-cleaning\"),\n            json={\"new_cleaning\": orjson.loads(new_cleaning.json())},\n        )\n        assert res.status_code == HTTP_201_CREATED\n\n        created_cleaning = cleaning_create(**res.json())\n        assert created_cleaning == new_cleaning\n\n    @pytest.mark.parametrize(\n        \"invalid_payload, status_code\",\n        (\n            (None, 422),\n            ({}, 422),\n            ({\"name\": \"test_name\"}, 422),\n            ({\"price\": 10.00}, 422),\n            ({\"name\": \"test_name\", \"description\": \"test\"}, 422),\n        ),\n    )\n    async def test_invalid_input_raises_error(\n        self, app: FastAPI, client: AsyncClient, invalid_payload: dict, status_code: int\n    ) -> None:\n        res = await client.post(\n            app.url_path_for(\"cleanings:create-cleaning\"),\n            json={\"new_cleaning\": invalid_payload},\n        )\n        assert res.status_code == status_code\n```\n\n`cleanings:create-cleaning` apiê°€ ì˜ë„í•œëŒ€ë¡œ ë°ì´í„°ë¥¼ ì¶”ê°€í•˜ê³ , ë°˜í™˜í•˜ëŠ”ì§€ í™•ì¸í•˜ëŠ” ì½”ë“œê°€ ì¶”ê°€ëë‹¤.\n\në˜í•œ, ì—ëŸ¬ë¥¼ ë°œìƒí•˜ëŠ” `body`ì˜ í˜•íƒœì™€, ê·¸ëŸ¬í•œ `body`ì— ëŒ€í•´ ê¸°ëŒ€í•˜ëŠ” `status_code`ë¥¼ ì§€ì •í•´ì„œ í™•ì¸í•œë‹¤.\n\nê²°ê³¼ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì •ìƒì ìœ¼ë¡œ ë‚˜ì™€ì•¼ í•œë‹¤.\n\n```bash\n==================================================== test session starts =====================================================\nplatform linux -- Python 3.10.4, pytest-7.1.2, pluggy-1.0.0 -- /usr/local/bin/python\ncachedir: .pytest_cache\nrootdir: /backend\nplugins: anyio-3.5.0, asyncio-0.18.3\nasyncio: mode=auto\ncollected 8 items\n\ntests/test_cleanings.py::TestCleaningsRoutes::test_routes_exist PASSED                                                 [ 12%]\ntests/test_cleanings.py::TestCleaningsRoutes::test_invalid_input_raises_error PASSED                                   [ 25%]\ntests/test_cleanings.py::TestCreateCleaning::test_valid_input_creates_cleaning PASSED                                  [ 37%]\ntests/test_cleanings.py::TestCreateCleaning::test_invalid_input_raises_error[None-422] PASSED                          [ 50%]\ntests/test_cleanings.py::TestCreateCleaning::test_invalid_input_raises_error[invalid_payload1-422] PASSED              [ 62%]\ntests/test_cleanings.py::TestCreateCleaning::test_invalid_input_raises_error[invalid_payload2-422] PASSED              [ 75%]\ntests/test_cleanings.py::TestCreateCleaning::test_invalid_input_raises_error[invalid_payload3-422] PASSED              [ 87%]\ntests/test_cleanings.py::TestCreateCleaning::test_invalid_input_raises_error[invalid_payload4-422] PASSED              [100%]\n\n===================================================== 8 passed in 0.54s ======================================================\n```\n\n## TDD ë°©ë²•ë¡ ì— ë”°ë¥¸ ê°œë°œ ì—°ìŠµ\n\nì´ì œ **`pytest`** ë¥¼ ì‚¬ìš©í•˜ëŠ” ë°©ì‹ì— ëŒ€í•´ ì–´ëŠì •ë„ ê°ì´ ì¡íˆëŠ” ëŠë‚Œì´ë‹¤.\n**jeffastor**ëŠ” ì´ëŸ¬í•œ í…ŒìŠ¤íŠ¸ ì½”ë“œë¥¼ ì´ìš©í•´ì„œ, **TDD**(í…ŒìŠ¤íŠ¸ ì£¼ë„ ê°œë°œ)ì„ ê¶Œì¥í•˜ëŠ” ê²ƒ ê°™ë‹¤.\n**TDD**ëŠ” ë‹¤ìŒì˜ 3ë‹¨ê³„ í”„ë¡œì„¸ìŠ¤ë¥¼ ë”°ë¥¸ë‹¤.\n\n> 1. ì‹¤íŒ¨ë¥¼ í™•ì¸í•  ìˆ˜ ìˆëŠ” í…ŒìŠ¤íŠ¸ ì½”ë“œë¥¼ ì‘ì„±í•œë‹¤.\n> 2. í…ŒìŠ¤íŠ¸ ì½”ë“œë¥¼ í†µê³¼í•  ìˆ˜ ìˆë„ë¡ ì½”ë“œë¥¼ ì‘ì„±í•œë‹¤.\n> 3. ìì‹ ì´ ë§Œì¡±í•  ìˆ˜ì¤€ìœ¼ë¡œ ì½”ë“œë¥¼ ìˆ˜ì •, í…ŒìŠ¤íŠ¸, ë¦¬íŒ©í† ë§, ëª¨ë“ˆí™” ë“±ì„ ì‹¤ì‹œí•œë‹¤.\n\n### `GET` `api` ìƒì„±\n\nìœ„ í”„ë¡œì„¸ìŠ¤ë¥¼ ë”°ë¼ì„œ **GET** apië¥¼ ìƒì„±í•´ë³´ì.\n\n```python\n# backend/tests/test_cleanings.py\n(...)\n\nfrom app.models.cleaning import cleaning_create, cleanings\nfrom starlette.status import (\n    HTTP_200_OK,\n    HTTP_201_CREATED,\n    HTTP_404_NOT_FOUND,\n    HTTP_422_UNPROCESSABLE_ENTITY,\n)\n\n(...)\n\nclass TestGetCleaning:\n    async def test_get_cleaning_by_id(self, app: FastAPI, client: AsyncClient) -> None:\n        res = await client.get(app.url_path_for(\"cleanings:get-cleaning-by-id\", id=\"1\"))\n        assert res.status_code == HTTP_200_OK\n        cleaning = cleanings(**res.json())\n        assert cleaning.id == 1\n```\n\nì‘ì„±í•œ í…ŒìŠ¤íŠ¸ ì½”ë“œì˜ `TestGetCleaning.test_get_cleaning_by_id` ë©”ì†Œë“œë¥¼ í†µê³¼í•  ìˆ˜ ìˆë„ë¡, **GET** apië¥¼ ì‘ì„±í•´ë³´ì.\n\n```python\n# backend/app/api/routes/cleanings.py\nfrom fastapi import APIRouter, Body, Depends, HTTPException, Path\nfrom starlette.status import HTTP_201_CREATED, HTTP_404_NOT_FOUND\n\n(...)\n\n@router.get(\n    \"/{id}\", response_model=cleaning_public, name=\"cleanings:get-cleaning-by-id\"\n)\nasync def get_cleaning_by_id(\n    id: int = Path(..., ge=1),\n    session: AsyncSession = Depends(get_session),\n) -> cleanings:\n    if (cleaning := await session.get(cleanings, id)) is None:\n        raise HTTPException(\n            status_code=HTTP_404_NOT_FOUND, detail=\"No cleaning found with that id.\"\n        )\n    return cleaning\n```\n\ní™•ì¸í•´ë³¸ ê²°ê³¼, ëª¨ë‘ ì˜ ì‘ë™í•œë‹¤.\ní•˜ì§€ë§Œ í…ŒìŠ¤íŠ¸ ì½”ë“œì— ë¬¸ì œê°€ ìˆë‹¤. `id=1`ë¡œ í•˜ë“œì½”ë”©ëœ ìƒíƒœì´ê¸° ë•Œë¬¸. ë”°ë¼ì„œ í•˜ë“œì½”ë”©ì„ ì œê±°í•˜ê¸° ìœ„í•œ ìƒˆë¡œìš´ `fixture`ë¥¼ ìƒì„±í•  í•„ìš”ê°€ ìˆë‹¤.\n\n```python\n# backend/tests/test_cleanings.py\n\n(...)\n\nfrom sqlmodel.ext.asyncio.session import AsyncSession\n\n(...)\n\n@pytest.fixture\nasync def test_cleaning(session: AsyncSession) -> cleanings:\n    new_cleaning_create = cleaning_create.parse_obj(\n        dict(\n            name=\"fake cleaning name\",\n            description=\"fake cleaning description\",\n            price=9.99,\n            cleaning_type=\"spot_clean\",\n        )\n    )\n    new_cleaning = cleanings.from_orm(new_cleaning_create)\n    session.add(new_cleaning)\n    await session.commit()\n    await session.refresh(new_cleaning)\n\n    return new_cleaning\n\n\nclass TestGetCleaning:\n    async def test_get_cleaning_by_id(\n        self, app: FastAPI, client: AsyncClient, test_cleaning: cleanings\n    ) -> None:\n        print(test_cleaning)\n        res = await client.get(\n            app.url_path_for(\"cleanings:get-cleaning-by-id\", id=str(test_cleaning.id))\n        )\n        assert res.status_code == HTTP_200_OK\n        cleaning = cleanings.parse_obj(res.json())\n        assert cleaning == test_cleaning\n```\n\n`refresh` ë©”ì†Œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ì •í™•í•œ idë¥¼ ê°€ì§€ê³  ë¹„êµë¥¼ í•´ì„œ ì—ëŸ¬ê°€ ì—†ì„ê±°ë¼ ìƒê°í–ˆëŠ”ë°,\n\n```bash\n================================================== short test summary info ===================================================\nERROR tests/test_cleanings.py::TestGetCleaning::test_get_cleaning_by_id - sqlalchemy.exc.OperationalError: (psycopg2.errors...\n================================================= 9 passed, 1 error in 5.74s =================================================\nsys:1: SAWarning: The garbage collector is trying to clean up connection <AdaptedConnection <asyncpg.connection.Connection object at 0x7fabadaffbc0>>. This feature is unsupported on async dbapi, since no IO can be performed at this stage to reset the connection. Please close out all connections when they are no longer used, calling ``close()`` or using a context manager to manage their lifetime.\n```\n\n**`pytest`** ì—ì„œ `fixture`ë¥¼ ìƒì„±í•  ë•Œ ì—°ê²°í•œ `session`ì„ ì œëŒ€ë¡œ ì •ë¦¬í•˜ì§€ ì•Šì•„ì„œ ì—ëŸ¬ê°€ ë°œìƒí–ˆë‹¤. **`pytest`** ì—ì„œëŠ” `NullPool`ì„ ì‚¬ìš©í•˜ê³ , **`pytest`** ì—ì„œ `session` ê°ì²´ë¥¼ `fixture`ë¡œ ì‚¬ìš©í•˜ì§€ ì•Šë„ë¡ í•˜ì.\n\n```python\nfrom sqlalchemy.pool import AsyncAdaptedQueuePool, NullPool, QueuePool\n\n(...)\n\ndef get_engine_kwargs(\n    is_sync: bool, is_test: bool = False, **kwargs: Any\n) -> dict[str, Any]:\n    params: dict[str, Any] = {\"pool_pre_ping\": True, \"future\": True}\n\n    if is_test:\n        params[\"poolclass\"] = NullPool\n    else:\n        params[\"pool_size\"] = 10\n        params[\"poolclass\"] = QueuePool\n\n    return params | kwargs\n\n\n(...)\n\ndef get_test_engine(engine: AsyncEngine, is_sync: bool = False) -> AsyncEngine | Engine:\n    if _is_test := is_test():\n        engine = create_engine_from_url(get_test_url(engine.url), is_test=_is_test)\n\n    if is_sync:\n        return convert_async_to_sync(engine, is_test=_is_test)\n    return engine\n\n(...)\n```\n\n```python\n# backend/tests/conftest.py\nimport os\nimport warnings\nfrom typing import AsyncIterator\n\nimport alembic\nimport pytest\nfrom alembic.config import Config\nfrom asgi_lifespan import LifespanManager\nfrom fastapi import FastAPI\nfrom httpx import AsyncClient\nfrom sqlalchemy.ext.asyncio.engine import AsyncEngine\n\n\n# Apply migrations at beginning and end of testing session\n@pytest.fixture(scope=\"session\")\ndef apply_migrations():\n    warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n    os.environ[\"TESTING\"] = \"1\"\n    config = Config(\"alembic.ini\")\n\n    alembic.command.upgrade(config, \"head\")  # type: ignore\n    yield\n    alembic.command.downgrade(config, \"base\")  # type: ignore\n\n\n# Create a new application for testing\n@pytest.fixture\ndef app(apply_migrations: None) -> FastAPI:\n    from app.api.server import get_application\n\n    return get_application()\n\n\n# Grab a reference to our database when needed\n@pytest.fixture\ndef engine(app: FastAPI) -> AsyncEngine:\n    return app.state._db\n\n\n# Make requests in our tests\n@pytest.fixture\nasync def client(app: FastAPI) -> AsyncIterator[AsyncClient]:\n    async with LifespanManager(app):\n        async with AsyncClient(\n            app=app,\n            base_url=\"http://testserver\",\n            headers={\"Content-Type\": \"application/json\"},\n        ) as client:\n            yield client\n```\n\n```python\n# backend/tests/test_cleanings.py\n(...)\n\nfrom sqlalchemy.ext.asyncio import AsyncEngine\nfrom sqlmodel.ext.asyncio.session import AsyncSession\n\n(...)\n\n@pytest.fixture\nasync def test_cleaning(engine: AsyncEngine) -> cleanings:\n    new_cleaning_create = cleaning_create.parse_obj(\n        dict(\n            name=\"fake cleaning name\",\n            description=\"fake cleaning description\",\n            price=9.99,\n            cleaning_type=\"spot_clean\",\n        )\n    )\n    new_cleaning = cleanings.from_orm(new_cleaning_create)\n    async with AsyncSession(engine, autocommit=False) as session:\n        session.add(new_cleaning)\n        await session.commit()\n        await session.refresh(new_cleaning)\n\n    return new_cleaning\n\n(...)\n```\n\në‹¤ì‹œ **`pytest`** ë¥¼ ì‹¤í–‰í–ˆì„ ë•Œ, ì •ìƒì ìœ¼ë¡œ ì˜ ë˜ëŠ” ê²ƒì„ í™•ì¸í–ˆë‹¤.\n\n### `GET` `api`ì— ìœ íš¨í•˜ì§€ ì•Šì€ ê°’ì— ëŒ€í•œ í…ŒìŠ¤íŠ¸ ì½”ë“œ\n\nì´ì–´ì„œ, ìœ íš¨í•˜ì§€ ì•Šì€ ê°’ì— ëŒ€í•œ í…ŒìŠ¤íŠ¸ ì½”ë“œë¥¼ ì¶”ê°€í•œë‹¤.\nì› ì˜ˆì œëŠ” `id=-1`ì— ëŒ€í•´ 404 ì—ëŸ¬ ì½”ë“œë¥¼ ë°˜í™˜í•˜ì§€ë§Œ, ì´ì „ì— **GET** apië¥¼ ì •ì˜í•  ë•Œ `id: int = Path(..., ge=1)` ìœ¼ë¡œ ì •ì˜í–ˆê¸°ì— 422ì—ëŸ¬ê°€ ë°˜í™˜ëœë‹¤. ë”°ë¼ì„œ ê·¸ ë¶€ë¶„ë§Œ ìˆ˜ì •í–ˆë‹¤.\n\n```python\n# backend/tests/test_cleanings.py\n(...)\n\nclass TestGetCleaning:\n    async def test_get_cleaning_by_id(\n        self, app: FastAPI, client: AsyncClient, test_cleaning: cleanings\n    ) -> None:\n        print(test_cleaning)\n        res = await client.get(\n            app.url_path_for(\"cleanings:get-cleaning-by-id\", id=str(test_cleaning.id))\n        )\n        assert res.status_code == HTTP_200_OK\n        cleaning = cleanings.parse_obj(res.json())\n        assert cleaning == test_cleaning\n\n    @pytest.mark.parametrize(\n        \"id, status_code\",\n        (\n            (500, 404),\n            (-1, 422),\n            (None, 422),\n        ),\n    )\n    async def test_wrong_id_returns_error(\n        self, app: FastAPI, client: AsyncClient, id: int, status_code: int\n    ) -> None:\n        res = await client.get(\n            app.url_path_for(\"cleanings:get-cleaning-by-id\", id=str(id))\n        )\n        assert res.status_code == status_code\n```\n\ní…ŒìŠ¤íŠ¸ì‹œ, ë³„ ë¬¸ì œ ì—†ì´ í†µê³¼í•œë‹¤.\n\n```bash\nroot@5984264d864d:/backend# pytest -v --asyncio-mode=auto\n==================================================== test session starts =====================================================\nplatform linux -- Python 3.10.4, pytest-7.1.2, pluggy-1.0.0 -- /usr/local/bin/python\ncachedir: .pytest_cache\nrootdir: /backend\nplugins: anyio-3.5.0, asyncio-0.18.3\nasyncio: mode=auto\ncollected 12 items\n\ntests/test_cleanings.py::TestCleaningsRoutes::test_routes_exist PASSED                                                 [  8%]\ntests/test_cleanings.py::TestCleaningsRoutes::test_invalid_input_raises_error PASSED                                   [ 16%]\ntests/test_cleanings.py::TestCreateCleaning::test_valid_input_creates_cleaning PASSED                                  [ 25%]\ntests/test_cleanings.py::TestCreateCleaning::test_invalid_input_raises_error[None-422] PASSED                          [ 33%]\ntests/test_cleanings.py::TestCreateCleaning::test_invalid_input_raises_error[invalid_payload1-422] PASSED              [ 41%]\ntests/test_cleanings.py::TestCreateCleaning::test_invalid_input_raises_error[invalid_payload2-422] PASSED              [ 50%]\ntests/test_cleanings.py::TestCreateCleaning::test_invalid_input_raises_error[invalid_payload3-422] PASSED              [ 58%]\ntests/test_cleanings.py::TestCreateCleaning::test_invalid_input_raises_error[invalid_payload4-422] PASSED              [ 66%]\ntests/test_cleanings.py::TestGetCleaning::test_get_cleaning_by_id PASSED                                               [ 75%]\ntests/test_cleanings.py::TestGetCleaning::test_wrong_id_returns_error[500-404] PASSED                                  [ 83%]\ntests/test_cleanings.py::TestGetCleaning::test_wrong_id_returns_error[-1-422] PASSED                                   [ 91%]\ntests/test_cleanings.py::TestGetCleaning::test_wrong_id_returns_error[None-422] PASSED                                 [100%]\n\n===================================================== 12 passed in 0.86s =====================================================\n```\n\në‹¤ìŒ ì±•í„°ëŠ” CRUD apië¥¼ ì˜ ìƒì„±í•˜ê¸° ìœ„í•œ ì‘ì—…ìœ¼ë¡œ ë³´ì¸ë‹¤.\n","mtime":"2022-08-13T00:12:20.000+09:00","href":"velog/fastapi íŠœí† ë¦¬ì–¼ -4- pytest ì ìš© ë° ì‹¤í–‰","data":{"title":"fastapi íŠœí† ë¦¬ì–¼ -4- pytest ì ìš© ë° ì‹¤í–‰","date":"2022-04-30T02:43:31.082+09:00","tags":["fastapi","tdd","pytest","python","@all"],"page":"fastapi íŠœí† ë¦¬ì–¼","summary":"fastapi ì‚¬ìš©ë²•ì„ ë‹¤ì‹œ ê³µë¶€í• ê²¸, ì°¸ê³ í• ë§Œí•œ ì¢‹ì€ ì˜ˆì œê°€ ìˆì–´ì„œ ì´ ì‹œë¦¬ì¦ˆë¥¼ ì•½ê°„ì˜ ë³€ê²½ì„ ì£¼ê³  ë”°ë¼ê°€ë³´ë ¤ í•œë‹¤."}},{"name":"fastapi íŠœí† ë¦¬ì–¼ -5- TDD ë°©ë²•ë¡ ìœ¼ë¡œ RESTful API ìƒì„±","content":"\n**`fastapi`** ì‚¬ìš©ë²•ì„ ë‹¤ì‹œ ê³µë¶€í• ê²¸, ì°¸ê³ í• ë§Œí•œ ì¢‹ì€ [ì˜ˆì œ](https://www.jeffastor.com/blog/populating-cleaning-jobs-with-user-offers-in-fastapi)ê°€ ìˆì–´ì„œ ì´ ì‹œë¦¬ì¦ˆë¥¼ ì•½ê°„ì˜ ë³€ê²½ì„ ì£¼ê³  ë”°ë¼ê°€ë³´ë ¤ í•œë‹¤.\nì§€ë‚œë²ˆì²˜ëŸ¼ ì–´ì©Œë‹¤ ê·¸ë§Œë‘˜ ìˆ˜ë„ ìˆê¸´ í•˜ì§€ë§Œ...\n\n---\n\nì•„ë˜ ë¬¸ì œë¡œ ì¸í•´ í•´ë‹¹ ì±•í„°ë¥¼ ì§„í–‰í•˜ë©´ì„œ ì´ì „ ì±•í„°ì˜ ê¸€ì„ í¬í•¨í•´ì„œ ìˆ˜ì •í•˜ë‹¤ ë³´ë‹ˆ ì œëŒ€ë¡œ ìˆ˜ì •ì´ ëœê±´ì§€ ì•„ë‹Œì§€ í™•ì¸í•˜ê¸°ê°€ ì–´ë µë‹¤..\nì–´ì©Œë©´ [ì´ê³³](https://github.com/phi-friday/jeffastor_tutor)ì—ì„œ ì½”ë“œë¥¼ í™•ì¸í•˜ëŠ”ê²Œ ë„ì›€ì´ ë  ìˆ˜ ìˆë‹¤.\n\níŠ¹íˆ ì´ ì±•í„°ì˜ í…ŒìŠ¤íŠ¸ ì½”ë“œì— ì ìš©ëœ `Decimal`ì´ë‚˜ `f-string`ë„ ì›ë˜ëŠ” **TDD** ê³¼ì • ì¤‘ì—ì„œ ì ìš©í•œ ê²ƒì´ì§€ë§Œ, ì´ë¯¸ ê¸€ ì“°ëŠ” íë¦„ì´ ë‹¤ ê¼¬ì—¬ì„œ ìƒëµí–ˆë‹¤.\n\n---\n\n## `SQLModel`ì˜ **validataion** ê´€ë ¨ í•´ê²°\n\n[ë§í¬](https://velog.io/@phi0friday/sqlmodel-%EB%9D%BC%EC%9D%B4%EB%B8%8C%EB%9F%AC%EB%A6%AC-%EC%82%AC%EC%9A%A9%EC%8B%9C-%EC%A3%BC%EC%9D%98%EC%82%AC%ED%95%AD-validation)ì™€ ê°™ì€ ì´ìœ ë¡œ ì¸í•´, **`sqlmodel`** ë¡œ ìƒì„±í•œ ëª¨ë¸ì— ëŒ€í•œ ì „ë°˜ì ì¸ ìˆ˜ì •ì´ í•„ìš”í•˜ë¯€ë¡œ, ì•„ë˜ì™€ ê°™ì´ ìˆ˜ì •ì„ ì§„í–‰í–ˆë‹¤.\n\n```python\n# backend/app/models/core.py\nfrom typing import Any, TypeVar, cast\n\nfrom sqlmodel import Field, SQLModel, Table\n\n_T = TypeVar(\"_T\", bound=SQLModel)\n\n\nclass fix_return_type_model(SQLModel):\n    \"\"\"\n    sqlmodelì—ì„œ parse_obj ë¦¬í„´ê°’ ì •ìƒì ìœ¼ë¡œ ìˆ˜ì •í•˜ê¸° ì „ê¹Œì§€ ì‚¬ìš©\n    +\n    validate ë˜í•œ ê°™ì€ ë¬¸ì œ ìˆìŒ\n    \"\"\"\n\n    @classmethod\n    def parse_obj(cls: type[_T], obj: Any, update: dict[str, Any] | None = None) -> _T:\n        return cast(_T, super().parse_obj(obj, update))\n\n    @classmethod\n    def validate(cls: type[_T], value: Any) -> _T:\n        return cast(_T, super().validate(value))\n\n\nclass base_model(fix_return_type_model):\n    @classmethod\n    def get_table(cls) -> Table:\n        if (table := getattr(cls, \"__table__\", None)) is None:\n            raise ValueError(\"not table\")\n        return table\n\n\nclass id_model(fix_return_type_model):\n    id: int | None = Field(None, primary_key=True)\n```\n\n```python\n# backend/app/api/routes/cleanings.py\n(...)\n\n@router.post(\n    \"\",\n    response_model=cleaning_public,\n    name=\"cleanings:create-cleaning\",\n    status_code=HTTP_201_CREATED,\n)\nasync def create_new_cleaning(\n    new_cleaning: cleaning_create = Body(..., embed=True),\n    session: AsyncSession = Depends(get_session),\n) -> cleanings:\n    # data = cleanings.from_orm(new_cleaning) ìœ¼ë¡œ í•´ë„ ê°€ëŠ¥\n    # exclude_none=True, exclude_unset=True ì˜µì…˜ì„ ìœ„í•´ parse_obj ì‚¬ìš©\n    # sqlmodel table=True ê´€ë ¨ validation ë¬¸ì œë¡œ ì¸í•´ validateì‚¬ìš©\n    data = cleanings.validate(\n        new_cleaning.dict(\n            exclude_none=True,\n            exclude_unset=True,\n        )\n    )\n    session.add(data)\n    await session.flush()\n    await session.commit()\n    await session.refresh(data)\n\n    return data\n```\n\n```python\n# backend/tests.py\n(...)\n\n@pytest.fixture\nasync def test_cleaning(engine: AsyncEngine) -> cleanings:\n    new_cleaning_create = cleaning_create.parse_obj(\n        dict(\n            name=\"fake cleaning name\",\n            description=\"fake cleaning description\",\n            price=9.99,\n            cleaning_type=\"spot_clean\",\n        )\n    )\n    new_cleaning = cleanings.validate(new_cleaning_create)\n    async with AsyncSession(engine, autocommit=False) as session:\n        session.add(new_cleaning)\n        await session.commit()\n        await session.refresh(new_cleaning)\n\n    return new_cleaning\n\nclass TestGetCleaning:\n    async def test_get_cleaning_by_id(\n        self, app: FastAPI, client: AsyncClient, test_cleaning: cleanings\n    ) -> None:\n        res = await client.get(\n            app.url_path_for(\"cleanings:get-cleaning-by-id\", id=str(test_cleaning.id))\n        )\n        assert res.status_code == HTTP_200_OK\n        cleaning = cleanings.validate(res.json())\n        assert cleaning == test_cleaning\n\n    @pytest.mark.parametrize(\n        \"id, status_code\",\n        (\n            (500, 404),\n            (-1, 422),\n            (None, 422),\n        ),\n    )\n    async def test_wrong_id_returns_error(\n        self, app: FastAPI, client: AsyncClient, id: int, status_code: int\n    ) -> None:\n        res = await client.get(\n            app.url_path_for(\"cleanings:get-cleaning-by-id\", id=str(id))\n        )\n        assert res.status_code == status_code\n\n    async def test_get_all_cleanings_returns_valid_response(\n        self, app: FastAPI, client: AsyncClient, test_cleaning: cleanings\n    ) -> None:\n        res = await client.get(app.url_path_for(\"cleanings:get-all-cleanings\"))\n        assert res.status_code == HTTP_200_OK\n        assert isinstance((json := res.json()), list)\n        assert len(json) > 0\n        all_cleanings = [cleanings.validate(l) for l in json]\n        assert test_cleaning in all_cleanings\n```\n\n---\n\n## `RESTful` `CRUD` `api` ìƒì„±\n\n**RESTful** í‘œì¤€ì— ë”°ë¼, ë‹¤ìŒê³¼ ê°™ì´ ì—”ë“œí¬ì¸íŠ¸ë¥¼ ìƒì„±í•˜ê³ ì í•œë‹¤.\n\n| ì—”ë“œí¬ì¸íŠ¸     | ë©”ì†Œë“œ | ì„¤ëª…                               |\n| :------------- | :----- | :--------------------------------- |\n| /cleaning      | POST   | ìƒˆë¡œìš´ cleaning ë ˆì½”ë“œ ìƒì„±        |\n| /cleaning/{id} | GET    | idì— í•´ë‹¹í•˜ëŠ” cleaning ë ˆì½”ë“œ í˜¸ì¶œ |\n| /cleaning      | GET    | ì „ì²´ cleaning ë ˆì½”ë“œ í˜¸ì¶œ          |\n| /cleaning/{id} | PATCH  | idì— í•´ë‹¹í•˜ëŠ” cleaning ë ˆì½”ë“œ ìˆ˜ì • |\n| /cleaning/{id} | PUT    | idì— í•´ë‹¹í•˜ëŠ” cleaning ë ˆì½”ë“œ êµì²´ |\n| /cleaning/{id} | DELET  | idì— í•´ë‹¹í•˜ëŠ” cleaning ë ˆì½”ë“œ ì œê±° |\n\nì´ì „ ì±•í„°ì—ì„œ, ìƒˆë¡œìš´ ë ˆì½”ë“œë¥¼ ìƒì„±í•˜ëŠ” ê²ƒê³¼, ê¸°ì¡´ì˜ ë ˆì½”ë“œë¥¼ `id`ë¥¼ ì´ìš©í•˜ì—¬ í˜¸ì¶œí•˜ëŠ”, ë‘ê°œì˜ ì—”ë“œí¬ì¸íŠ¸ë¥¼ ìƒì„±í–ˆë‹¤. ë‹¤ë¥¸ 4ê°€ì§€ ë˜í•œ, **TDD** ë°©ë²•ë¡ ì— ë§ê²Œ ì‘ì„±í•œë‹¤.\n\n> ì› ì˜ˆì œì—ì„œ **jeffastor**ëŠ” **PATCH** apië¥¼ ì‘ì„±í•˜ì§€ ì•Šê³  **PUT** apië§Œ ì‘ì„±í–ˆë‹¤. ê·¸ëŸ°ë° ì‘ë™ ë°©ì‹ì„ ë³´ë©´ **jeffastor**ê°€ ì‘ì„±í•œ **PUT** apiëŠ” **PATCH** apiì²˜ëŸ¼ ì‘ë™í•œë‹¤. ì´ì™€ ê´€ë ¨í•´ ì•½ê°„ì˜ ìˆ˜ì •ì´ í•¨ê»˜ ì§„í–‰ëœë‹¤.\n\n### `GET` `api`\n\n```python\n# backend/tests/test_cleanings.py\n(...)\n\n    async def test_get_all_cleanings_returns_valid_response(\n        self, app: FastAPI, client: AsyncClient, test_cleaning: cleanings\n    ) -> None:\n        res = await client.get(app.url_path_for(\"cleanings:get-all-cleanings\"))\n        assert res.status_code == HTTP_200_OK\n        assert isinstance((json := res.json()), list)\n        assert len(json) > 0\n        all_cleanings = [cleanings.parse_obj(l) for l in json]    async def test_get_all_cleanings_returns_valid_response(\n        self, app: FastAPI, client: AsyncClient, test_cleaning: cleanings\n    ) -> None:\n        res = await client.get(app.url_path_for(\"cleanings:get-all-cleanings\"))\n        assert res.status_code == HTTP_200_OK\n        assert isinstance((json := res.json()), list)\n        assert len(json) > 0\n        all_cleanings = [cleanings.parse_obj(l) for l in json]\n        assert test_cleaning in all_cleanings\n        assert test_cleaning in all_cleanings\n```\n\nì´ì œ **`pytest`** ë¥¼ **`docker`** ì»¨í…Œì´ë„ˆ ë‚´ë¶€ì—ì„œ ì‹¤í–‰í•˜ë©´, ë‹¤ìŒê³¼ ê°™ì€ ì—ëŸ¬ë¥¼ í™•ì¸í•  ìˆ˜ ìˆë‹¤.\n\n```bash\n(...)\n\n================================================= FAILURES ==================================================\n_______________________ TestGetCleaning.test_get_all_cleanings_returns_valid_response _______________________\n\nself = <tests.test_cleanings.TestGetCleaning object at 0x7feb2db9b370>\napp = <fastapi.applications.FastAPI object at 0x7feb2b01fd90>\nclient = <httpx.AsyncClient object at 0x7feb2b01e6e0>\ntest_cleaning = cleanings(name='fake cleaning name', price=Decimal('9.99'), id=3, description='fake cleaning description', cleaning_type='spot_clean')\n\n    async def test_get_all_cleanings_returns_valid_response(\n        self, app: FastAPI, client: AsyncClient, test_cleaning: cleanings\n    ) -> None:\n>       res = await client.get(app.url_path_for(\"cleanings:get-all-cleanings\"))\n\ntests/test_cleanings.py:125:\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n/usr/local/lib/python3.10/site-packages/starlette/applications.py:108: in url_path_for\n    return self.router.url_path_for(name, **path_params)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <fastapi.routing.APIRouter object at 0x7feb2b01d180>, name = 'cleanings:get-all-cleanings'\npath_params = {}, route = <fastapi.routing.APIRoute object at 0x7feb2b045480>\n\n    def url_path_for(self, name: str, **path_params: str) -> URLPath:\n        for route in self.routes:\n            try:\n                return route.url_path_for(name, **path_params)\n            except NoMatchFound:\n                pass\n>       raise NoMatchFound()\nE       starlette.routing.NoMatchFound\n\n/usr/local/lib/python3.10/site-packages/starlette/routing.py:590: NoMatchFound\n\n(...)\n```\n\n> í˜„ì¬ ì„¤ì •ìœ¼ë¡œëŠ”, `test_cleaning`ì„ ì‚¬ìš©í•  ë•Œ ë§ˆë‹¤ ìƒˆë¡œìš´ ë ˆì½”ë“œë¥¼ ìƒì„±í•˜ê³  ìˆë‹¤. ë§Œì•½ `unique` ì„¤ì •ì´ ìˆë‹¤ë©´ ì—ëŸ¬ë¥¼ ë°œìƒì‹œí‚¬ ê²ƒì´ë‹¤. ì´ ë¬¸ì œëŠ” ì´í›„ ë‹¤ë£° ê²ƒì´ë¯€ë¡œ, ì§€ê¸ˆì€ ì‹ ê²½ì“°ì§€ ì•Šì•„ë„ ëœë‹¤ê³  **jeffastor**ëŠ” ë°íŒë‹¤.\n\nì´ì œ í…ŒìŠ¤íŠ¸ë¥¼ í†µê³¼í•  ìˆ˜ ìˆë„ë¡, ë¼ìš°í„°ë¥¼ ìˆ˜ì •í•©ë‹ˆë‹¤. ì •ë§ ì—°ìŠµí•´ë³´ê¸° ìœ„í•´, ì´í›„ ë‚´ìš©ì€ ì œëŒ€ë¡œ ì½ì§€ ì•Šê³  ì§ì ‘ ì½”ë“œë¥¼ ì‘ì„±í•´ë´¤ìŠµë‹ˆë‹¤.\n\n```python\n# backend/app/api/routes/cleanings.py\n(...)\n\nfrom typing import cast\nfrom sqlmodel import select\n\n(...)\n\n@router.get(\n    \"\", response_model=list[cleaning_public], name=\"cleanings:get-all-cleanings\"\n)\nasync def get_all_cleanings(\n    session: AsyncSession = Depends(get_session),\n) -> list[cleanings]:\n    # ì•„ì§ sqlmodelì˜ async sessionì€ type hintì™€ ê´€ë ¨í•´ì„œ ì œëŒ€ë¡œ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n    # ì œëŒ€ë¡œ ì‘ì„±ëœê²Œ ë§ëŠ”ì§€ í™•ì¸í•´ë³´ê³  ì‹¶ë‹¤ë©´,\n    # session.sync_sessionì—ì„œ type hint ê´€ë ¨í•´ì„œë§Œ í™•ì¸í•´ë³´ë©´ ë©ë‹ˆë‹¤.\n    #\n    # sync_session = session.sync_session\n    # table = sync_session.exec(select(cleanings))\n    # rows = table.all()\n    table = await session.exec(select(cleanings))  # type: ignore\n    rows = cast(list[cleanings], table.all())\n    return rows\n\n@router.post(\n    \"\",\n    response_model=cleaning_public,\n    name=\"cleanings:create-cleaning\",\n    status_code=HTTP_201_CREATED,\n)\n\n(...)\n```\n\ní…ŒìŠ¤íŠ¸ ê²°ê³¼ í†µê³¼í–ˆìŠµë‹ˆë‹¤.\n\n> ì› ì‘ì„±ì **jeffator**ì˜ ê²½ìš°, **TDD**ì— ëŒ€í•´ ìµìˆ™í•´ì§€ì§€ ìœ„í•´ ì²˜ìŒì—ëŠ” `None`ì„ ë°˜í™˜í•˜ê³ , ê·¸ ë‹¤ìŒì—ëŠ” ë¹ˆ ë¦¬ìŠ¤íŠ¸ `[]`ë¥¼ ë°˜í™˜í•˜ê³ , ê·¸ ë‹¤ìŒì—ëŠ” ê°€ì§œ ë ˆì½”ë“œ `[{ \"id\": 1, \"name\": \"fake cleaning\", \"price\": 0}]`ë¥¼ ë°˜í™˜í•˜ê³ , ëìœ¼ë¡œ ì„¸ì…˜ì— ì—°ê²°í•´ì„œ ë ˆì½”ë“œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n\n### `PUT` `api`...? `PATCH` `api`\n\në‹¤ìŒê³¼ ê°™ì´ í…ŒìŠ¤íŠ¸ ì½”ë“œë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.\n\n```python\n# backend/tests/test_cleanings.py\nfrom contextlib import suppress\nfrom decimal import Decimal, InvalidOperation\n\n(...)\n\nclass TestPutCleaning:\n    @pytest.mark.parametrize(\n        \"attrs_to_change, values\",\n        (\n            ([\"name\"], [\"new fake cleaning name\"]),\n            ([\"description\"], [\"new fake cleaning description\"]),\n            ([\"price\"], [3.14]),\n            ([\"cleaning_type\"], [\"full_clean\"]),\n            (\n                [\"name\", \"description\"],\n                [\n                    \"extra new fake cleaning name\",\n                    \"extra new fake cleaning description\",\n                ],\n            ),\n            ([\"price\", \"cleaning_type\"], [42.00, \"dust_up\"]),\n        ),\n    )\n    async def test_update_cleaning_with_valid_input(\n        self,\n        app: FastAPI,\n        client: AsyncClient,\n        test_cleaning: cleanings,\n        attrs_to_change: list[str],\n        values: list[str | int | float],\n    ) -> None:\n        update_cleaning = {\"update_cleaning\": dict(zip(attrs_to_change, values))}\n\n        res = await client.put(\n            app.url_path_for(\n                \"cleanings:update-cleaning-by-id-as-put\",\n                id=str(\n                    test_cleaning.id,\n                ),\n            ),\n            json=update_cleaning,\n        )\n        assert res.status_code == HTTP_200_OK\n        updated_cleaning = cleanings.validate(res.json())\n        assert (\n            updated_cleaning.id == test_cleaning.id\n        )  # make sure it's the same cleaning\n        # make sure that any attribute we updated has changed to the correct value\n        for attr, value in zip(attrs_to_change, values):\n            attr_to_change = getattr(updated_cleaning, attr)\n            assert attr_to_change != getattr(test_cleaning, attr)\n            if attr == \"price\":\n                with suppress(InvalidOperation, ValueError):\n                    value = Decimal(f\"{float(value):.2f}\")\n            assert attr_to_change == value\n        # make sure that no other attributes' values have changed\n        for attr, value in updated_cleaning.dict().items():\n            if attr not in attrs_to_change:\n                assert getattr(test_cleaning, attr) == value\n\n    @pytest.mark.parametrize(\n        \"id, payload, status_code\",\n        (\n            (-1, {\"name\": \"test\"}, 422),\n            (0, {\"name\": \"test2\"}, 422),\n            (500, {\"name\": \"test3\"}, 404),\n            (1, None, 422),\n            (1, {\"cleaning_type\": \"invalid cleaning type\"}, 422),\n            (1, {\"cleaning_type\": None}, 400),\n        ),\n    )\n    async def test_update_cleaning_with_invalid_input_throws_error(\n        self,\n        app: FastAPI,\n        client: AsyncClient,\n        id: int,\n        payload: dict,\n        status_code: int,\n    ) -> None:\n        update_cleaning = {\"update_cleaning\": payload}\n        res = await client.put(\n            app.url_path_for(\"cleanings:update-cleaning-by-id-as-put\", id=str(id)),\n            json=update_cleaning,\n        )\n        assert res.status_code == status_code\n```\n\nì²«ë²ˆì§¸ëŠ” **PUT** apiê°€ ì˜ë„í•œëŒ€ë¡œ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸í•˜ê³ , ë‘ë²ˆì§¸ëŠ” ì˜ë„í•œëŒ€ë¡œ ì—ëŸ¬ë¥¼ ë°˜í™˜í•˜ëŠ”ì§€ í™•ì¸í•˜ëŠ” ë©”ì†Œë“œì…ë‹ˆë‹¤.\nì´ì œ ìœ„ í…ŒìŠ¤íŠ¸ ì½”ë“œë¥¼ í†µê³¼í•  ìˆ˜ ìˆë„ë¡ **PUT** ë©”ì†Œë“œë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.\n\n> ë‹¤ë§Œ ìœ„ í…ŒìŠ¤íŠ¸ ì½”ë“œì—ì„œ ì´í•´ê°€ ë˜ì§€ ì•ŠëŠ” ë¶€ë¶„ì´ ìˆëŠ”ë°,\n\n```python\n# make sure that no other attributes' values have changed\nfor attr, value in updated_cleaning.dict().items():\n    if attr not in attrs_to_change:\n        assert getattr(test_cleaning, attr) == value\n```\n\n> ì´ë‹¤. ì´ê±´ **PATCH** ì•„ë‹Œê°€? ì¼ë‹¨ ë”°ë¼ê°€ë³¸ë‹¤.\n\n```python\n# backend/app/api/routes/cleanings.py\n(...)\n\nfrom pydantic import ValidationError\nfrom starlette.status import (\n    HTTP_201_CREATED,\n    HTTP_404_NOT_FOUND,\n    HTTP_422_UNPROCESSABLE_ENTITY,\n)\n\n(...)\n\n@router.put(\n    \"/{id}\",\n    response_model=cleaning_public,\n    name=\"cleanings:update-cleaning-by-id-as-put\",\n)\nasync def update_cleaning_by_id_as_put(\n    id: int = Path(..., ge=1),\n    update_cleaning: cleaning_update = Body(..., embed=True),\n    session: AsyncSession = Depends(get_session),\n) -> cleanings:\n    try:\n        cleanings.from_orm(update_cleaning)\n    except ValidationError as exc:\n        raise HTTPException(\n            status_code=HTTP_422_UNPROCESSABLE_ENTITY, detail=exc.json()\n        )\n\n    if (cleaning := await session.get(cleanings, id)) is None:\n        raise HTTPException(\n            status_code=HTTP_404_NOT_FOUND, detail=\"No cleaning found with that id.\"\n        )\n\n    # validate ê´€ë ¨ ë¬¸ì œ í•´ê²° ì „ê¹Œì§€ëŠ” ì´ë ‡ê²Œ..\n    update_dict = update_cleaning.dict(exclude_unset=True)\n    try:\n        cleanings.validate(cleaning.dict() | update_dict)\n    except ValidationError as exc:\n        raise HTTPException(\n            status_code=HTTP_422_UNPROCESSABLE_ENTITY, detail=exc.json()\n        )\n\n    for attr, value in update_dict.items():\n        setattr(cleaning, attr, value)\n            status_code=HTTP_422_UNPROCESSABLE_ENTITY, detail=exc.json()\n        )\n\n    session.add(cleaning)\n    await session.flush()\n    await session.commit()\n    await session.refresh(cleaning)\n\n    return cleaning\n```\n\n`update_cleaning`ì´ ì •ìƒì ì¸ `cleanings` ë ˆì½”ë“œë¥¼ ìƒì„±í•  ìˆ˜ ìˆëŠ”ì§€ í™•ì¸í•˜ê³ , `id`ì— í•´ë‹¹í•˜ëŠ” `cleanings` ë ˆì½”ë“œë¥¼ í˜¸ì¶œ í•œ ë‹¤ìŒ, í•´ë‹¹ ë ˆì½”ë“œì˜ ê°’ì„ ìˆ˜ì •í•˜ê³  ì»¤ë°‹í–ˆë‹¤.\n\ní…ŒìŠ¤íŠ¸ ì‹¤í–‰ê²°ê³¼ ì´ìƒí•˜ë‹¤ê³  ìƒê°í–ˆë˜ ë¶€ë¶„ì´ ë§ì•˜ë‹¤.\n**`pytest`** ì— ìµìˆ™í•˜ì§€ ì•Šì•„ ì²˜ìŒì— ì•Œì•„ë³´ì§€ ëª»í•œ ë¬¸ì œì¸ë°,\n\n```python\nattrs_to_change = ['cleaning_type']\nvalues = ['full_clean']\n```\n\në‹¤ìŒê³¼ ê°™ì´ ë³€ìˆ˜ê°€ ì •ì˜ëœë‹¤..\në”°ë¼ì„œ, ìœ„ ì˜ˆì œë¥¼ ëª¨ë‘ **PUT**ì—ì„œ **PATCH**ë¡œ ë³€ê²½ í›„ ë‹¤ì‹œ ì§„í–‰í•œë‹¤.\n\n```python\n# backend/tests/test_cleanings.py\n(...)\n\nclass TestPatchCleaning:\n    @pytest.mark.parametrize(\n        \"attrs_to_change, values\",\n        (\n            ([\"name\"], [\"new fake cleaning name\"]),\n            ([\"description\"], [\"new fake cleaning description\"]),\n            ([\"price\"], [3.14]),\n            ([\"cleaning_type\"], [\"full_clean\"]),\n            (\n                [\"name\", \"description\"],\n                [\n                    \"extra new fake cleaning name\",\n                    \"extra new fake cleaning description\",\n                ],\n            ),\n            ([\"price\", \"cleaning_type\"], [42.00, \"dust_up\"]),\n        ),\n    )\n    async def test_update_cleaning_with_valid_input(\n        self,\n        app: FastAPI,\n        client: AsyncClient,\n        test_cleaning: cleanings,\n        attrs_to_change: list[str],\n        values: list[str | int | float],\n    ) -> None:\n        update_cleaning = {\"update_cleaning\": dict(zip(attrs_to_change, values))}\n\n        res = await client.patch(\n            app.url_path_for(\n                \"cleanings:update-cleaning-by-id-as-patch\",\n                id=str(\n                    test_cleaning.id,\n                ),\n            ),\n            json=update_cleaning,\n        )\n        assert res.status_code == HTTP_200_OK\n        updated_cleaning = cleanings.parse_obj(res.json())\n        assert (\n            updated_cleaning.id == test_cleaning.id\n        )  # make sure it's the same cleaning\n        # make sure that any attribute we updated has changed to the correct value\n        for attr, value in zip(attrs_to_change, values):\n            attr_to_change = getattr(updated_cleaning, attr)\n            assert attr_to_change != getattr(test_cleaning, attr)\n            if attr == \"price\":\n                with suppress(InvalidOperation, ValueError):\n                    value = Decimal(f\"{float(value):.2f}\")\n            assert attr_to_change == value\n        # make sure that no other attributes' values have changed\n        for attr, value in updated_cleaning.dict().items():\n            if attr not in attrs_to_change:\n                assert getattr(test_cleaning, attr) == value\n\n    @pytest.mark.parametrize(\n        \"id, payload, status_code\",\n        (\n            (-1, {\"name\": \"test\"}, 422),\n            (0, {\"name\": \"test2\"}, 422),\n            (500, {\"name\": \"test3\"}, 404),\n            (1, None, 422),\n            (1, {\"cleaning_type\": \"invalid cleaning type\"}, 422),\n            (1, {\"cleaning_type\": None}, 400),\n        ),\n    )\n    async def test_update_cleaning_with_invalid_input_throws_error(\n        self,\n        app: FastAPI,\n        client: AsyncClient,\n        id: int,\n        payload: dict,\n        status_code: int,\n    ) -> None:\n        update_cleaning = {\"update_cleaning\": payload}\n        res = await client.patch(\n            app.url_path_for(\"cleanings:update-cleaning-by-id-as-patch\", id=str(id)),\n            json=update_cleaning,\n        )\n        assert res.status_code == status_code\n```\n\n```python\n# backend/app/api/routes/cleanings.py\n(...)\n\n@router.patch(\n    \"/{id}\",\n    response_model=cleaning_public,\n    name=\"cleanings:update-cleaning-by-id-as-patch\",\n)\nasync def update_cleaning_by_id_as_patch(\n    id: int = Path(..., ge=1),\n    update_cleaning: cleaning_update = Body(..., embed=True),\n    session: AsyncSession = Depends(get_session),\n) -> cleanings:\n    if (cleaning := await session.get(cleanings, id)) is None:\n        raise HTTPException(\n            status_code=HTTP_404_NOT_FOUND, detail=\"No cleaning found with that id.\"\n        )\n\n    # validate ê´€ë ¨ ë¬¸ì œ í•´ê²° ì „ê¹Œì§€ëŠ” ì´ë ‡ê²Œ..\n    update_dict = update_cleaning.dict(exclude_unset=True)\n    try:\n        cleanings.validate(cleaning.dict() | update_dict)\n    except ValidationError as exc:\n        raise HTTPException(\n            status_code=HTTP_422_UNPROCESSABLE_ENTITY, detail=exc.json()\n        )\n\n    for attr, value in update_dict.items():\n        setattr(cleaning, attr, value)\n\n    session.add(cleaning)\n    await session.flush()\n    await session.commit()\n    await session.refresh(cleaning)\n\n    return cleaning\n```\n\nê¸°ì¡´ì— ì‘ì„±í•œ **PUT** apiëŠ” ì œê±°í•˜ì§€ ì•Šê³  ë†”ë‘”ë‹¤. ë§ˆì§€ë§‰ì— ë‹¤ì‹œ ì‚¬ìš©í•  ê²ƒì´ë‹¤.\n\ní…ŒìŠ¤íŠ¸ ê²°ê³¼ ëª¨ë‘ ì •ìƒì ìœ¼ë¡œ í†µê³¼í–ˆë‹¤.\n\n### `DELETE` `api`\n\nì´ì–´ì„œ **DELETE** í…ŒìŠ¤íŠ¸ ì½”ë“œì™€ apië¥¼ ìƒì„±í•œë‹¤.\n\n```python\n# backend/tests/test_cleanings.py\n(...)\n\nclass TestDeleteCleaning:\n    async def test_can_delete_cleaning_successfully(\n        self,\n        app: FastAPI,\n        client: AsyncClient,\n        test_cleaning: cleanings,\n    ) -> None:\n        # delete the cleaning\n        res = await client.delete(\n            app.url_path_for(\n                \"cleanings:delete-cleaning-by-id\", id=str(test_cleaning.id)\n            ),\n        )\n        assert res.status_code == HTTP_200_OK\n        # ensure that the cleaning no longer exists\n        res = await client.get(\n            app.url_path_for(\"cleanings:get-cleaning-by-id\", id=str(test_cleaning.id)),\n        )\n        assert res.status_code == HTTP_404_NOT_FOUND\n\n    @pytest.mark.parametrize(\n        \"id, status_code\",\n        (\n            (500, 404),\n            (0, 422),\n            (-1, 422),\n            (None, 422),\n        ),\n    )\n    async def test_delete_cleaning_with_invalid_input_throws_error(\n        self,\n        app: FastAPI,\n        client: AsyncClient,\n        test_cleaning: cleanings,\n        id: int,\n        status_code: int,\n    ) -> None:\n        res = await client.delete(\n            app.url_path_for(\"cleanings:delete-cleaning-by-id\", id=str(id)),\n        )\n        assert res.status_code == status_code\n```\n\n```python\n# backend/app/api/routes/cleanings.py\n(...)\n\n@router.delete(\"/{id}/\", response_model=int, name=\"cleanings:delete-cleaning-by-id\")\nasync def delete_cleaning_by_id(\n    id: int = Path(..., ge=1, title=\"The ID of the cleaning to delete.\"),\n    session: AsyncSession = Depends(get_session),\n) -> int:\n    if (cleaning := await session.get(cleanings, id)) is None:\n        raise HTTPException(\n            status_code=HTTP_404_NOT_FOUND, detail=\"No cleaning found with that id.\"\n        )\n\n    await session.delete(cleaning)\n    await session.flush()\n    await session.commit()\n\n    return id\n```\n\ní…ŒìŠ¤íŠ¸ë„ ì •ìƒì ìœ¼ë¡œ í†µê³¼í•œë‹¤.\n\n```bash\ntests/test_cleanings.py::TestDeleteCleaning::test_can_delete_cleaning_successfully PASSED             [ 86%]\ntests/test_cleanings.py::TestDeleteCleaning::test_delete_cleaning_with_invalid_input_throws_error[500-404] PASSED [ 90%]\ntests/test_cleanings.py::TestDeleteCleaning::test_delete_cleaning_with_invalid_input_throws_error[0-422] PASSED [ 93%]\ntests/test_cleanings.py::TestDeleteCleaning::test_delete_cleaning_with_invalid_input_throws_error[-1-422] PASSED [ 96%]\ntests/test_cleanings.py::TestDeleteCleaning::test_delete_cleaning_with_invalid_input_throws_error[None-422] PASSED [100%]\n```\n\n> **DELETE**ì™€ ê°™ì€ apiëŠ” `status_code=204`ì™€ í•¨ê»˜ `contents`ê°€ ì—†ëŠ” `response`ë¥¼ ë°˜í™˜í•˜ëŠ”ê²Œ ë§ë‹¤ê³  í•œë‹¤. í˜„ì¬ëŠ” ì ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤.\n\n### `PUT` api\n\nì› ì˜ˆì œëŠ” ì—¬ê¸°ì„œ ëì´ì§€ë§Œ, ì¶”ê°€ë¡œ **PUT** apiì— ëŒ€í•´ ì§ì ‘ ì‘ì„±í•´ë³¸ë‹¤.\n\n```python\n# backend/tests/test_cleanings.py\n(...)\n\nclass TestPutCleaning:\n    @pytest.mark.parametrize(\n        \"attrs_to_change, values\",\n        (\n            (\n                [\"name\", \"description\", \"price\"],\n                [\n                    \"new fake cleaning name\",\n                    \"new fake cleaning description\",\n                    \"123.1\",\n                ],\n            ),\n            (\n                [\"name\", \"price\", \"cleaning_type\"],\n                [\"extra new fake cleaning name\", 15555.51, \"dust_up\"],\n            ),\n            (\n                [\"name\", \"price\"],\n                [\"extra new fake cleaning name\", Decimal(\"2.12\")],\n            ),\n        ),\n    )\n    async def test_update_cleaning_with_valid_input(\n        self,\n        app: FastAPI,\n        client: AsyncClient,\n        test_cleaning: cleanings,\n        attrs_to_change: list[str],\n        values: list[str | int | float],\n    ) -> None:\n        update_cleaning = {\"update_cleaning\": dict(zip(attrs_to_change, values))}\n\n        print(orjson.loads(orjson.dumps(update_cleaning, default=str)))\n        res = await client.put(\n            app.url_path_for(\n                \"cleanings:update-cleaning-by-id-as-put\",\n                id=str(test_cleaning.id),\n            ),\n            json=orjson.loads(orjson.dumps(update_cleaning, default=str)),\n        )\n        assert res.status_code == HTTP_200_OK\n        updated_cleaning = cleanings.validate(res.json())\n        assert updated_cleaning.id == test_cleaning.id\n\n        for attr, value in update_cleaning[\"update_cleaning\"].items():\n            if attr == \"price\":\n                with suppress(InvalidOperation, ValueError):\n                    value = Decimal(f\"{float(value):.2f}\")\n            assert value == getattr(updated_cleaning, attr)\n\n        for attr, value in updated_cleaning.dict(exclude={\"id\"}).items():\n            if attr not in attrs_to_change:\n                assert value == cleanings.__fields__[attr].default\n\n    @pytest.mark.parametrize(\n        \"id, payload, status_code\",\n        (\n            (-1, {\"name\": \"test\"}, 422),\n            (0, {\"name\": \"test2\", \"price\": 123}, 422),\n            (500, {\"name\": \"test3\", \"price\": 33.3}, 404),\n            (1, None, 422),\n            (\n                1,\n                {\n                    \"name\": \"test5\",\n                    \"price\": \"123.3\",\n                    \"cleaning_type\": \"invalid cleaning type\",\n                },\n                422,\n            ),\n            (1, {\"name\": \"test6\", \"price\": 123.3, \"cleaning_type\": None}, 422),\n        ),\n    )\n    async def test_update_cleaning_with_invalid_input_throws_error(\n        self,\n        app: FastAPI,\n        client: AsyncClient,\n        id: int,\n        payload: dict,\n        status_code: int,\n    ) -> None:\n        update_cleaning = {\"update_cleaning\": payload}\n        res = await client.patch(\n            app.url_path_for(\"cleanings:update-cleaning-by-id-as-put\", id=str(id)),\n            json=update_cleaning,\n        )\n        assert res.status_code == status_code\n```\n\n```python\n# backend/app/api/routes/cleanings.py\n(...)\n\n@router.put(\n    \"/{id}\",\n    response_model=cleaning_public,\n    name=\"cleanings:update-cleaning-by-id-as-put\",\n)\nasync def update_cleaning_by_id_as_put(\n    id: int = Path(..., ge=1),\n    update_cleaning: cleaning_update = Body(..., embed=True),\n    session: AsyncSession = Depends(get_session),\n) -> cleanings:\n    if (cleaning := await session.get(cleanings, id)) is None:\n        raise HTTPException(\n            status_code=HTTP_404_NOT_FOUND, detail=\"No cleaning found with that id.\"\n        )\n\n    try:\n        new_cleaning = cleanings.validate(update_cleaning.dict(exclude_unset=True))\n    except ValidationError as exc:\n        raise HTTPException(\n            status_code=HTTP_422_UNPROCESSABLE_ENTITY, detail=orjson.loads(exc.json())\n        )\n\n    for attr, value in new_cleaning.dict(exclude={\"id\"}).items():\n        setattr(cleaning, attr, value)\n\n    session.add(cleaning)\n    await session.flush()\n    await session.commit()\n    await session.refresh(cleaning)\n\n    return cleaning\n```\n\në‚˜ë¦„ ì—¬ëŸ¬ ê³¼ì •ì„ ê±°ì³¤ëŠ”ë°, **`sqlmodel`** ê´€ë ¨ ë¬¸ì œë¥¼ ì•Œì•„ë³´ë‹¤ ë³´ë‹ˆ ë„ˆë¬´ ê¼¬ì˜€ë‹¤. ê³¼ì •ì€ ìƒëµ..\n\në‹¤ìŒì€ ë§ˆì´ê·¸ë ˆì´ì…˜ ì§„í–‰ í›„ ìœ ì € ê´€ë ¨ ì„¤ì •ì„ ì¶”ê°€í•˜ëŠ” ê²ƒ ê°™ë‹¤. ìœ ì € ê´€ë ¨í•´ì„œëŠ” **`fastapi-users`** ë¼ëŠ” ì¢‹ì€ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ìˆìœ¼ë‹ˆ, ì› ì˜ˆì œì™€ ê°™ì€ íë¦„ì´ì§€ë§Œ **`fastapi-user`** ë¥¼ ì“°ëŠ” ìª½ìœ¼ë¡œ ì§„í–‰í•  ì˜ˆì •.\n","mtime":"2022-08-13T00:12:20.000+09:00","href":"velog/fastapi íŠœí† ë¦¬ì–¼ -5- TDD ë°©ë²•ë¡ ìœ¼ë¡œ RESTful API ìƒì„±","data":{"title":"fastapi íŠœí† ë¦¬ì–¼ -5- TDD ë°©ë²•ë¡ ìœ¼ë¡œ RESTful API ìƒì„±","date":"2022-05-02T20:47:43.741+09:00","tags":["crud","fastapi","restful","tdd","python","@all"],"page":"fastapi íŠœí† ë¦¬ì–¼","summary":"fastapi ì‚¬ìš©ë²•ì„ ë‹¤ì‹œ ê³µë¶€í• ê²¸, ì°¸ê³ í• ë§Œí•œ ì¢‹ì€ ì˜ˆì œê°€ ìˆì–´ì„œ ì´ ì‹œë¦¬ì¦ˆë¥¼ ì•½ê°„ì˜ ë³€ê²½ì„ ì£¼ê³  ë”°ë¼ê°€ë³´ë ¤ í•œë‹¤."}},{"name":"fastapi íŠœí† ë¦¬ì–¼ -6- FastAPI Usersë¥¼ ì‚¬ìš©í•œ ìœ ì € api ìƒì„±","content":"\n**`fastapi`** ì‚¬ìš©ë²•ì„ ë‹¤ì‹œ ê³µë¶€í• ê²¸, ì°¸ê³ í• ë§Œí•œ ì¢‹ì€ [ì˜ˆì œ](https://www.jeffastor.com/blog/populating-cleaning-jobs-with-user-offers-in-fastapi)ê°€ ìˆì–´ì„œ ì´ ì‹œë¦¬ì¦ˆë¥¼ ì•½ê°„ì˜ ë³€ê²½ì„ ì£¼ê³  ë”°ë¼ê°€ë³´ë ¤ í•œë‹¤.\nì§€ë‚œë²ˆì²˜ëŸ¼ ì–´ì©Œë‹¤ ê·¸ë§Œë‘˜ ìˆ˜ë„ ìˆê¸´ í•˜ì§€ë§Œ...\n\n---\n\n## `cleanings`, `users` ëª¨ë¸ ìƒì„± ë° ìˆ˜ì •\n\nì‹œì‘ë¶€í„° ë§ˆì´ê·¸ë ˆì´ì…˜ì„ ì§„í–‰í•˜ê¸¸ë˜ ì–´ë–¤ê±´ê°€ í–ˆë”ë‹ˆ, ì´ì „ì— ì‘ì„±í–ˆë˜ `cleanings` í…Œì´ë¸”ì— ì‹œê°„ ì†ì„±(ìƒì„±, ìˆ˜ì •)ì„ sql ì„œë²„ì—ì„œ ìë™ìœ¼ë¡œ ì²˜ë¦¬í•˜ë„ë¡ í•˜ëŠ” íŠ¸ë¦¬ê±°ë¥¼ ìƒì„±í•˜ëŠ” ê³¼ì •ì´ ìˆì—ˆë‹¤. sql ì„œë²„ì—ì„œ ì§ì ‘ ì²˜ë¦¬í•˜ëŠ”ê²Œ ê°€ì¥ ê°„ë‹¨í•œ ë°©ë²•ì´ë¼ê³  í•œë‹¤. ì¼ë‹¨ ë¬´ì‹œ.\n\nì´ê²ƒê³¼ëŠ” ë³„ê°œë¡œ, ì´ì „ì— ë§ˆì´ê·¸ë ˆì´ì…˜ ê´€ë ¨ ì½”ë“œ ì‘ì„±ì‹œ ë¬¸ì œê°€ ìˆëŠ” í˜•íƒœë¡œ ì‘ì„±í•œ ê²ƒ ê°™ì•„ì„œ, ê´€ë ¨í•´ì„œ ì¡°ê¸ˆ ìˆ˜ì •í•œë‹¤.\n\n```python\n# backend/app/db/migration/versions/f721febf752b_create_account_table.py\n(...)\n\ndef create_cleanings_table() -> None:\n    import sys\n    from pathlib import Path\n\n    sys.path.append(Path(__file__).resolve().parents[4].as_posix())\n    from app.models.cleaning import cleanings\n\n    table = cleanings.get_table()\n    col_names = {\"id\", \"name\", \"description\", \"cleaning_type\", \"price\"}\n\n    op.create_table(\n        table.name, *[col for col in table.columns if col.name in col_names]\n    )\n\n(...)\n```\n\nì´ì œ ì› ì˜ˆì œì™€ ê°™ì´, ë‹¤ìš´ê·¸ë ˆì´ë“œ í›„, ì‹œê°„ ì†ì„±ë¶€í„° ì¶”ê°€í•œ ë‹¤ìŒ, ìœ ì € ê´€ë ¨ í…Œì´ë¸”ì„ ì„¤ì •í•˜ê³  ì—…ê·¸ë ˆì´ë“œë¥¼ ì‹¤ì‹œí•œë‹¤. ì› ì˜ˆì œì™€ ìˆœì„œë¥¼ ë§ì¶°ê°€ê¸° ìœ„í•´ ì•½ê°„ ê¼¬ì¸ ëŠë‚Œì´ ìˆëŠ”ë°, ì§€ê¸ˆ ì‘ì„±í•˜ëŠ” ìœ ì € í…Œì´ë¸”ì€ **`fastapi-users`** ì—ì„œ ì‘ì„±í•˜ëŠ” ëª¨ë¸ í˜•íƒœë¥¼ ë”°ë¼ê°„ë‹¤.\n\n```bash\nroot@c62cf3d05043:/backend# alembic downgrade base\nINFO  [alembic.env] Running migrations online\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Running downgrade f721febf752b -> , create account table\n```\n\n### ì‹œê°„ ì†ì„± ê´€ë ¨ ì½”ì–´ ëª¨ë¸ ì¶”ê°€\n\n```python\n# backend/app/models/core.py\nfrom datetime import datetime\n\n(...)\n\n_D = TypeVar(\"_D\", bound=\"datetime_model\")\n\n(...)\n\nclass datetime_model(fix_return_type_model):\n    created_at: datetime = Field(default_factory=datetime.now)\n    updated_at: datetime = Field(default_factory=datetime.now)\n\n    def update(self: _D) -> _D:\n        self.updated_at = datetime.now()\n        return self\n\n    @classmethod\n    @property\n    def attrs(cls) -> set[str]:\n        return set(cls.__fields__.keys())\n```\n\n### ì‹œê°„ ì†ì„± ì¶”ê°€ë¡œ ì¸í•œ ê¸°ì¡´ ëª¨ë¸ ë³€ê²½ì  ëŒ€ì‘ ìˆ˜ì •\n\n> ì•„ë˜ ë‚´ìš©ì€ ë‹¨ìˆœíˆ ì‹œê°„ ì†ì„± ì¶”ê°€ë¡œ ì¸í•´ ì½”ë“œê°€ ë„ˆë¬´ ë‚˜ì—´ë¼ìˆì–´ì„œ ì ‘ì–´ë†“ê³  ì‹¶ì§€ë§Œ velogê°€ í•´ë‹¹ ê¸°ëŠ¥ì„ ì§€ì›í•˜ì§€ ì•ŠëŠ”ë‹¤.. velogì—ì„œ ìë™ ìƒì„±ëœ ëª©ì°¨ë¥¼ ì„ íƒí•´ì„œ ë‹¤ìŒ í•­ëª©ìœ¼ë¡œ ë„˜ì–´ê°ˆ ìˆ˜ ìˆë‹¤.\n\n```python\n# backend/app/models/cleaning.py\n(...)\n\nfrom .core import base_model, datetime_model, id_model\n\n(...)\n\nclass cleanings(id_model, datetime_model, cleaning_base, table=True):\n    name: str = Field(index=True)\n    cleaning_type: cleaning_type_enum = Field(\n        cleaning_type_enum.spot_clean,\n        sa_column_kwargs={\"server_default\": cleaning_type_enum.spot_clean},\n    )\n    price: price_decimal_type\n\n(...)\n```\n\n```python\n# backend/tests/test_cleaning.py\nfrom contextlib import suppress\nfrom decimal import Decimal, InvalidOperation\n\nimport orjson\nimport pytest\nfrom app.models.cleaning import cleaning_create, cleanings\nfrom app.models.core import datetime_model\nfrom fastapi import FastAPI\nfrom httpx import AsyncClient\nfrom sqlalchemy.ext.asyncio import AsyncEngine\nfrom sqlmodel.ext.asyncio.session import AsyncSession\nfrom starlette.status import (\n    HTTP_200_OK,\n    HTTP_201_CREATED,\n    HTTP_404_NOT_FOUND,\n    HTTP_422_UNPROCESSABLE_ENTITY,\n)\n\n# decorate all tests with @pytest.mark.asyncio\npytestmark = pytest.mark.asyncio\n\n\n@pytest.fixture\ndef new_cleaning():\n    return cleaning_create.parse_obj(\n        dict(\n            name=\"test cleaning\",\n            description=\"test description\",\n            price=0.00,\n            cleaning_type=\"spot_clean\",\n        )\n    )\n\n\nclass TestCleaningsRoutes:\n    async def test_routes_exist(self, app: FastAPI, client: AsyncClient) -> None:\n        res = await client.post(app.url_path_for(\"cleanings:create-cleaning\"), json={})\n        assert res.status_code != HTTP_404_NOT_FOUND\n\n    async def test_invalid_input_raises_error(\n        self, app: FastAPI, client: AsyncClient\n    ) -> None:\n        res = await client.post(app.url_path_for(\"cleanings:create-cleaning\"), json={})\n        assert res.status_code == HTTP_422_UNPROCESSABLE_ENTITY\n\n\nclass TestCreateCleaning:\n    async def test_valid_input_creates_cleaning(\n        self, app: FastAPI, client: AsyncClient, new_cleaning: cleaning_create\n    ) -> None:\n        res = await client.post(\n            app.url_path_for(\"cleanings:create-cleaning\"),\n            json={\"new_cleaning\": orjson.loads(new_cleaning.json())},\n        )\n        assert res.status_code == HTTP_201_CREATED\n\n        created_cleaning = cleaning_create(**res.json())\n        assert created_cleaning == new_cleaning\n\n    @pytest.mark.parametrize(\n        \"invalid_payload, status_code\",\n        (\n            (None, 422),\n            ({}, 422),\n            ({\"name\": \"test_name\"}, 422),\n            ({\"price\": 10.00}, 422),\n            ({\"name\": \"test_name\", \"description\": \"test\"}, 422),\n        ),\n    )\n    async def test_invalid_input_raises_error(\n        self, app: FastAPI, client: AsyncClient, invalid_payload: dict, status_code: int\n    ) -> None:\n        res = await client.post(\n            app.url_path_for(\"cleanings:create-cleaning\"),\n            json={\"new_cleaning\": invalid_payload},\n        )\n        assert res.status_code == status_code\n\n\n@pytest.fixture\nasync def test_cleaning(engine: AsyncEngine) -> cleanings:\n    new_cleaning_create = cleaning_create.parse_obj(\n        dict(\n            name=\"fake cleaning name\",\n            description=\"fake cleaning description\",\n            price=9.99,\n            cleaning_type=\"spot_clean\",\n        )\n    )\n    new_cleaning = cleanings.validate(new_cleaning_create)\n    async with AsyncSession(engine, autocommit=False) as session:\n        session.add(new_cleaning)\n        await session.commit()\n        await session.refresh(new_cleaning)\n\n    return new_cleaning\n\n\nclass TestGetCleaning:\n    async def test_get_cleaning_by_id(\n        self, app: FastAPI, client: AsyncClient, test_cleaning: cleanings\n    ) -> None:\n        res = await client.get(\n            app.url_path_for(\"cleanings:get-cleaning-by-id\", id=str(test_cleaning.id))\n        )\n        assert res.status_code == HTTP_200_OK\n        cleaning = cleanings.validate(res.json())\n        assert cleaning.dict(exclude=datetime_model.attrs) == test_cleaning.dict(\n            exclude=datetime_model.attrs\n        )\n\n    @pytest.mark.parametrize(\n        \"id, status_code\",\n        (\n            (500, 404),\n            (-1, 422),\n            (None, 422),\n        ),\n    )\n    async def test_wrong_id_returns_error(\n        self, app: FastAPI, client: AsyncClient, id: int, status_code: int\n    ) -> None:\n        res = await client.get(\n            app.url_path_for(\"cleanings:get-cleaning-by-id\", id=str(id))\n        )\n        assert res.status_code == status_code\n\n    async def test_get_all_cleanings_returns_valid_response(\n        self, app: FastAPI, client: AsyncClient, test_cleaning: cleanings\n    ) -> None:\n        res = await client.get(app.url_path_for(\"cleanings:get-all-cleanings\"))\n        assert res.status_code == HTTP_200_OK\n        assert isinstance((json := res.json()), list)\n        assert len(json) > 0\n        all_cleanings = [\n            cleanings.validate(l).dict(exclude=datetime_model.attrs) for l in json\n        ]\n        assert test_cleaning.dict(exclude=datetime_model.attrs) in all_cleanings\n\n\nclass TestPatchCleaning:\n    @pytest.mark.parametrize(\n        \"attrs_to_change, values\",\n        (\n            ([\"name\"], [\"new fake cleaning name\"]),\n            ([\"description\"], [\"new fake cleaning description\"]),\n            ([\"price\"], [3.14]),\n            ([\"cleaning_type\"], [\"full_clean\"]),\n            (\n                [\"name\", \"description\"],\n                [\n                    \"extra new fake cleaning name\",\n                    \"extra new fake cleaning description\",\n                ],\n            ),\n            ([\"price\", \"cleaning_type\"], [42.00, \"dust_up\"]),\n        ),\n    )\n    async def test_update_cleaning_with_valid_input(\n        self,\n        app: FastAPI,\n        client: AsyncClient,\n        test_cleaning: cleanings,\n        attrs_to_change: list[str],\n        values: list[str | int | float],\n    ) -> None:\n        update_cleaning = {\"update_cleaning\": dict(zip(attrs_to_change, values))}\n\n        res = await client.patch(\n            app.url_path_for(\n                \"cleanings:update-cleaning-by-id-as-patch\",\n                id=str(test_cleaning.id),\n            ),\n            json=update_cleaning,\n        )\n        assert res.status_code == HTTP_200_OK\n        updated_cleaning = cleanings.validate(res.json())\n        assert (\n            updated_cleaning.id == test_cleaning.id\n        )  # make sure it's the same cleaning\n        # make sure that any attribute we updated has changed to the correct value\n        for attr, value in zip(attrs_to_change, values):\n            attr_to_change = getattr(updated_cleaning, attr)\n            assert attr_to_change != getattr(test_cleaning, attr)\n            if attr == \"price\":\n                with suppress(InvalidOperation, ValueError):\n                    value = Decimal(f\"{float(value):.2f}\")\n            assert attr_to_change == value\n        # make sure that no other attributes' values have changed\n        for attr, value in updated_cleaning.dict().items():\n            if attr not in attrs_to_change and attr not in datetime_model.attrs:\n                assert getattr(test_cleaning, attr) == value\n\n    @pytest.mark.parametrize(\n        \"id, payload, status_code\",\n        (\n            (-1, {\"name\": \"test\"}, 422),\n            (0, {\"name\": \"test2\"}, 422),\n            (500, {\"name\": \"test3\"}, 404),\n            (1, None, 422),\n            (1, {\"cleaning_type\": \"invalid cleaning type\"}, 422),\n            (1, {\"cleaning_type\": None}, 422),\n        ),\n    )\n    async def test_update_cleaning_with_invalid_input_throws_error(\n        self,\n        app: FastAPI,\n        client: AsyncClient,\n        id: int,\n        payload: dict,\n        status_code: int,\n    ) -> None:\n        update_cleaning = {\"update_cleaning\": payload}\n        res = await client.patch(\n            app.url_path_for(\"cleanings:update-cleaning-by-id-as-patch\", id=str(id)),\n            json=update_cleaning,\n        )\n        assert res.status_code == status_code\n\n\nclass TestDeleteCleaning:\n    async def test_can_delete_cleaning_successfully(\n        self,\n        app: FastAPI,\n        client: AsyncClient,\n        test_cleaning: cleanings,\n    ) -> None:\n        # delete the cleaning\n        res = await client.delete(\n            app.url_path_for(\n                \"cleanings:delete-cleaning-by-id\", id=str(test_cleaning.id)\n            ),\n        )\n        assert res.status_code == HTTP_200_OK\n        # ensure that the cleaning no longer exists\n        res = await client.get(\n            app.url_path_for(\"cleanings:get-cleaning-by-id\", id=str(test_cleaning.id)),\n        )\n        assert res.status_code == HTTP_404_NOT_FOUND\n\n    @pytest.mark.parametrize(\n        \"id, status_code\",\n        (\n            (500, 404),\n            (0, 422),\n            (-1, 422),\n            (None, 422),\n        ),\n    )\n    async def test_delete_cleaning_with_invalid_input_throws_error(\n        self,\n        app: FastAPI,\n        client: AsyncClient,\n        test_cleaning: cleanings,\n        id: int,\n        status_code: int,\n    ) -> None:\n        res = await client.delete(\n            app.url_path_for(\"cleanings:delete-cleaning-by-id\", id=str(id)),\n        )\n        assert res.status_code == status_code\n\n\nclass TestPutCleaning:\n    @pytest.mark.parametrize(\n        \"attrs_to_change, values\",\n        (\n            (\n                [\"name\", \"description\", \"price\"],\n                [\n                    \"new fake cleaning name\",\n                    \"new fake cleaning description\",\n                    \"123.1\",\n                ],\n            ),\n            (\n                [\"name\", \"price\", \"cleaning_type\"],\n                [\"extra new fake cleaning name\", 15555.51, \"dust_up\"],\n            ),\n            (\n                [\"name\", \"price\"],\n                [\"extra new fake cleaning name\", Decimal(\"2.12\")],\n            ),\n        ),\n    )\n    async def test_update_cleaning_with_valid_input(\n        self,\n        app: FastAPI,\n        client: AsyncClient,\n        test_cleaning: cleanings,\n        attrs_to_change: list[str],\n        values: list[str | int | float],\n    ) -> None:\n        update_cleaning = {\"update_cleaning\": dict(zip(attrs_to_change, values))}\n\n        print(orjson.loads(orjson.dumps(update_cleaning, default=str)))\n        res = await client.put(\n            app.url_path_for(\n                \"cleanings:update-cleaning-by-id-as-put\",\n                id=str(test_cleaning.id),\n            ),\n            json=orjson.loads(orjson.dumps(update_cleaning, default=str)),\n        )\n        assert res.status_code == HTTP_200_OK\n        updated_cleaning = cleanings.validate(res.json())\n        assert updated_cleaning.id == test_cleaning.id\n\n        for attr, value in update_cleaning[\"update_cleaning\"].items():\n            if attr == \"price\":\n                with suppress(InvalidOperation, ValueError):\n                    value = Decimal(f\"{float(value):.2f}\")\n            assert value == getattr(updated_cleaning, attr)\n\n        for attr, value in updated_cleaning.dict(exclude={\"id\"}).items():\n            if attr not in attrs_to_change and attr not in datetime_model.attrs:\n                assert value == cleanings.__fields__[attr].default\n\n    @pytest.mark.parametrize(\n        \"id, payload, status_code\",\n        (\n            (-1, {\"name\": \"test\"}, 422),\n            (0, {\"name\": \"test2\", \"price\": 123}, 422),\n            (500, {\"name\": \"test3\", \"price\": 33.3}, 404),\n            (1, None, 422),\n            (\n                1,\n                {\n                    \"name\": \"test5\",\n                    \"price\": \"123.3\",\n                    \"cleaning_type\": \"invalid cleaning type\",\n                },\n                422,\n            ),\n            (1, {\"name\": \"test6\", \"price\": 123.3, \"cleaning_type\": None}, 422),\n        ),\n    )\n    async def test_update_cleaning_with_invalid_input_throws_error(\n        self,\n        app: FastAPI,\n        client: AsyncClient,\n        id: int,\n        payload: dict,\n        status_code: int,\n    ) -> None:\n        update_cleaning = {\"update_cleaning\": payload}\n        res = await client.patch(\n            app.url_path_for(\"cleanings:update-cleaning-by-id-as-put\", id=str(id)),\n            json=update_cleaning,\n        )\n        assert res.status_code == status_code\n```\n\n```python\n# backend/app/api/routes/cleanings.py\n(...)\n\n@router.patch(\n    \"/{id}\",\n    response_model=cleaning_public,\n    name=\"cleanings:update-cleaning-by-id-as-patch\",\n)\nasync def update_cleaning_by_id_as_patch(\n    id: int = Path(..., ge=1),\n    update_cleaning: cleaning_update = Body(..., embed=True),\n    session: AsyncSession = Depends(get_session),\n) -> cleanings:\n    if (cleaning := await session.get(cleanings, id)) is None:\n        raise HTTPException(\n            status_code=HTTP_404_NOT_FOUND, detail=\"No cleaning found with that id.\"\n        )\n\n    # validate ê´€ë ¨ ë¬¸ì œ í•´ê²° ì „ê¹Œì§€ëŠ” ì´ë ‡ê²Œ..\n    update_dict = update_cleaning.dict(exclude_unset=True)\n    try:\n        cleanings.validate(cleaning.dict() | update_dict)\n    except ValidationError as exc:\n        raise HTTPException(\n            status_code=HTTP_422_UNPROCESSABLE_ENTITY, detail=orjson.loads(exc.json())\n        )\n\n    for attr, value in update_dict.items():\n        setattr(cleaning, attr, value)\n\n    session.add(cleaning.update())\n    await session.flush()\n    await session.commit()\n    await session.refresh(cleaning)\n\n    return cleaning\n\n@router.put(\n    \"/{id}\",\n    response_model=cleaning_public,\n    name=\"cleanings:update-cleaning-by-id-as-put\",\n)\nasync def update_cleaning_by_id_as_put(\n    id: int = Path(..., ge=1),\n    update_cleaning: cleaning_update = Body(..., embed=True),\n    session: AsyncSession = Depends(get_session),\n) -> cleanings:\n    if (cleaning := await session.get(cleanings, id)) is None:\n        raise HTTPException(\n            status_code=HTTP_404_NOT_FOUND, detail=\"No cleaning found with that id.\"\n        )\n\n    try:\n        new_cleaning = cleanings.validate(update_cleaning.dict(exclude_unset=True))\n    except ValidationError as exc:\n        raise HTTPException(\n            status_code=HTTP_422_UNPROCESSABLE_ENTITY, detail=orjson.loads(exc.json())\n        )\n\n    for attr, value in new_cleaning.dict(exclude={\"id\"}).items():\n        setattr(cleaning, attr, value)\n\n    session.add(cleaning.update())\n    await session.flush()\n    await session.commit()\n    await session.refresh(cleaning)\n\n    return cleaning\n```\n\n```python\n# backend/app/db/migration/versions/f721febf752b_create_account_table.py\n(...)\n\ndef create_cleanings_table() -> None:\n    import sys\n    from pathlib import Path\n\n    sys.path.append(Path(__file__).resolve().parents[4].as_posix())\n    from app.models.cleaning import cleanings\n    from app.models.core import datetime_model\n\n    table = cleanings.get_table()\n    col_names = {\"id\", \"name\", \"description\", \"cleaning_type\", \"price\"}.union(\n        datetime_model.attrs\n    )\n\n    op.create_table(\n        table.name, *[col for col in table.columns if col.name in col_names]\n    )\n\n(...)\n```\n\nì´ë ‡ê²Œ ìˆ˜ì •í•˜ë©´ ì¶”ê°€, ìˆ˜ì • ì‹œê°„ ì†ì„±ì„ ë¬¸ì œì—†ì´ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤..\ní° ë¬¸ì œê°€ ì—†ë‹¤ë©´ ê·¸ëƒ¥ íŠ¸ë¦¬ê±°ë¥¼ ì´ìš©í•˜ì.\n\n### `users` ëª¨ë¸ ìƒì„±\n\n```bash\nâ¯ poetry add 'fastapi-users[sqlalchemy2]'\nâ¯ poetry export -f requirements.txt --output backend/requirements.txt --without-hashes --dev\nâ¯ touch backend/app/models/user.py\nâ¯ docker-compose up --build\n```\n\nì› ì˜ˆì œì—ì„œ **`JWT`** ë¥¼ ì‚¬ìš©í•˜ê¸°ì— ë”°ë¼ê°„ë‹¤.\n\n```python\n# backend/app/models/user.py\nfrom uuid import uuid4\n\nfrom fastapi_users import models\nfrom pydantic import UUID4, EmailStr\nfrom pydantic import Field as _Field\nfrom sqlmodel import Field\n\nfrom .core import base_model, datetime_model\n\nmin_name_length = 4\nmax_name_length = 20\n\n\nclass user_base(models.BaseUser, datetime_model):\n    name: str = _Field(min_length=min_name_length, max_length=max_name_length)\n\n\nclass user_create(models.BaseUserCreate):\n    name: str = _Field(min_length=min_name_length, max_length=max_name_length)\n\n\nclass user_update(models.BaseUserUpdate):\n    name: str = _Field(min_length=min_name_length, max_length=max_name_length)\n\n\nclass user_read(user_base):\n    ...\n\n\nclass user(user_base, models.BaseUserDB):\n    ...\n\n\nclass user_model(base_model, datetime_model, table=True):\n    __tablename__: str = \"users\"\n\n    id: UUID4 = Field(default_factory=uuid4, primary_key=True)\n    name: str = Field(min_length=min_name_length, max_length=max_name_length)\n    hashed_password: str = Field(max_length=2**10)\n    email: EmailStr = Field(sa_column_kwargs={\"unique\": True})\n    is_active: bool = True\n    is_superuser: bool = False\n    is_verified: bool = False\n```\n\nìœ„ ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ì •ì˜í•œ ëª¨ë¸ì€, **`pydantic`** ì˜ `BaseModel`ì„ ìƒì†ë°›ëŠ”, **`fastapi-users`** ì—ì„œ ì •ì˜ëœ ëª¨ë¸ì„ ìƒì†ë°›ì•„ì„œ ì •ì˜í•œë‹¤. ê¸°ë³¸ì ìœ¼ë¡œ ê°€ì§€ê³  ìˆëŠ” ì†ì„±ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.\n\n> `id` : `UUID`ë¡œ ì„ì˜ ìƒì„±\n> `email`: `xxx@yyy.zz`ì˜ í˜•íƒœë¡œ êµ¬ì„±ëœ ë¬¸ìì—´\n> `is_active`: í•´ë‹¹ ìœ ì € ë ˆì½”ë“œê°€ í™œì„±í™”ëœ ìƒíƒœì¸ì§€ í™•ì¸\n> `is_superuser`: í•´ë‹¹ ìœ ì €ê°€ ê´€ë¦¬ìì¸ì§€ í™•ì¸\n> `is_verified`: ì„ íƒì ìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ, í•´ë‹¹ ìœ ì €ì— ëŒ€í•œ ì¶”ê°€ì ì¸ ê²€ì¦ í†µê³¼ ì—¬ë¶€ë¥¼ í™•ì¸. í”íˆ ì´ë©”ì¼ë¡œ ê²€ì¦ì„ ì§„í–‰í•¨.\n> `password`: í•´ë‹¹ ìœ ì €ê°€ ë¡œê·¸ì¸ì‹œ ì‚¬ìš©í•˜ëŠ” ë¹„ë°€ë²ˆí˜¸ë¡œ, ì‹¤ì œ ë°ì´í„°ë² ì´ìŠ¤ì—ëŠ” `hashed_password` ì†ì„±ìœ¼ë¡œ ì•”í˜¸í™” í›„ ì €ì¥ëœë‹¤.\n\nì¶”ê°€ì ìœ¼ë¡œ í•„ìš”í•œ ì†ì„±ì´ ìˆë‹¤ë˜ê°€, ì œì•½ì‚¬í•­ì´ ìˆë‹¤ë©´ ìœ„ ìŠ¤í¬ë¦½íŠ¸ì™€ ê°™ì´ ëª¨ë¸ì— ìƒˆë¡œ ì •ì˜ë¥¼ í•´ë„ ì¢‹ê³ , ì´í›„ ì •ì˜í•  `UserManager` í´ë˜ìŠ¤ì˜ `on_after_register` ë“±ì˜ ë©”ì†Œë“œì— ì œì•½ì‚¬í•­ì„ ì ìš©í•´ë„ ëœë‹¤.\n\nê·¸ë¦¬ê³  ì¶”ê°€ëœ ëª¨ë¸ì„ ë§ˆì´ê·¸ë ˆì´ì…˜ ì„¤ì •ì— ì¶”ê°€í•œë‹¤.\n\n```python\n# backend/app/db/migrations/versions/f721febf752b_create_account_table.py\n\"\"\"create account table\n\nRevision ID: f721febf752b\nRevises:\nCreate Date: 2022-04-27 17:21:25.945460\n\n\"\"\"\nimport sys\nfrom pathlib import Path\n\nimport sqlalchemy as sa\nfrom alembic import op\n\nsys.path.append(Path(__file__).resolve().parents[4].as_posix())\nfrom app.models.cleaning import cleanings\nfrom app.models.core import datetime_model\nfrom app.models.user import user_model\n\n# revision identifiers, used by Alembic.\nrevision = \"f721febf752b\"\ndown_revision = None\nbranch_labels = None\ndepends_on = None\n\ncleanings_table = cleanings.get_table()\nusers_table = user_model.get_table()\n\n\ndef create_cleanings_table() -> None:\n    col_names = {\"id\", \"name\", \"description\", \"cleaning_type\", \"price\"}.union(\n        datetime_model.attrs\n    )\n\n    op.create_table(\n        cleanings_table.name,\n        *[col for col in cleanings_table.columns if col.name in col_names]\n    )\n\n\ndef create_user_table() -> None:\n    col_names = {\n        \"id\",\n        \"name\",\n        \"hashed_password\",\n        \"email\",\n        \"is_active\",\n        \"is_superuser\",\n        \"is_verified\",\n    }.union(datetime_model.attrs)\n\n    op.create_table(\n        users_table.name, *[col for col in users_table.columns if col.name in col_names]\n    )\n\n\ndef upgrade():\n    create_cleanings_table()\n    create_user_table()\n\n\ndef downgrade():\n    op.drop_table(cleanings_table.name)\n    op.drop_table(users_table.name)\n```\n\nì´ì œ ë“œë””ì–´ ë§ˆì´ê·¸ë ˆì´ì…˜ì„ í•  ì¤€ë¹„ê°€ ëë‚¬ë‹¤.\n\n```bash\nroot@77f86a971288:/backend# alembic upgrade head\nINFO  [alembic.env] Running migrations online\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\nINFO  [alembic.runtime.migration] Running upgrade  -> f721febf752b, create account table\n```\n\n## `FastAPI-Users`\n\nì› ì˜ˆì œì—ì„œëŠ” ì´ì œ í…ŒìŠ¤íŠ¸ ì½”ë“œë¥¼ ì‘ì„±í•œë‹¤. í•˜ì§€ë§Œ `fastapi-users`ë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ì„œ, ì‚¬ì „ ì‘ì—…ì´ ëª‡ê°€ì§€ í•„ìš”í•œë°, ì§€ê¸ˆ ì§„í–‰í•˜ëŠ” ì‘ì—…ì´ ë‹¤ìŒ ì±•í„°ë‚˜ ê·¸ ë‹¤ìŒ ì±•í„°ì— ë‚˜ì˜¤ëŠ” ë‚´ìš©ê³¼ ë¹„ìŠ·í•  ìˆ˜ ìˆë‹¤..\n\n### ê°„ë‹¨í•œ ì„¤ëª…\n\n**`fastapi-users`** ì˜ ì„¤ëª…ì— ë”°ë¥´ë©´, **`fastapi-users`** ëŠ” `Transport`ì™€ `Strategy` ì´ ë‘ê°€ì§€ë¥¼ ì¡°í•©í•´ì„œ ì‚¬ìš©í•˜ëŠ” ë°©ì‹ì´ë‹¤. ì§€ê¸ˆ ì´ ì˜ˆì œëŠ” **`Bearer`** ì™€ **`JWT`** ë¥¼ ì¡°í•©í•´ì„œ ì“°ëŠ” ë°©ì‹ì´ë¼ê³  ìƒê°í•  ìˆ˜ ìˆë‹¤.\n\n> - **`Bearer`** : `header`ì— í† í°ì„ ì €ì¥\n> - **`JWT`** : `JSON`í˜•íƒœì˜ í† í°ì„ ì•”í˜¸í™” í•˜ì—¬ ì €ì¥(í† í° ë°œí–‰ ì´í›„ ì„œë²„ì—ì„œ ë¬´íš¨í™” ë¶ˆê°€ëŠ¥). ìì„¸í•œ ì„¤ëª…ì€ [ì—¬ê¸°](https://jwt.io/introduction)ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆë‹¤.\n\n### ì¸ì¦ ë°±ì—”ë“œ ì„¤ì •\n\nì¸ì¦ê³¼ ê´€ë ¨í•œ ëª¨ë“ˆì„ ì €ì¥í•  ê²½ë¡œë¥¼ ìƒì„±í•˜ê³  ë°±ì—”ë“œë¶€í„° ì•ì—ì„œ ê°„ëµí•˜ê²Œ ì„¤ëª…í•œ ì¸ì¦ ë°±ì—”ë“œë¶€í„° ìƒì„±í•œë‹¤.\n\n```bash\nâ¯ mkdir backend/app/services\nâ¯ touch backend/app/services/__init__.py backend/app/services/authentication.py\n```\n\n```python\n# backend/app/services/authentication.py\nfrom dataclasses import dataclass\n\nfrom fastapi import Depends, Request\nfrom fastapi_users import BaseUserManager, FastAPIUsers\nfrom fastapi_users.authentication import (\n    AuthenticationBackend,\n    BearerTransport,\n    JWTStrategy,\n    Strategy,\n    Transport,\n)\nfrom fastapi_users.db import SQLAlchemyUserDatabase\nfrom sqlmodel.ext.asyncio.session import AsyncSession\n\nfrom ..core.config import SECRET_KEY\nfrom ..db.session import get_session\nfrom ..models.user import user, user_base, user_create, user_model, user_update\n\n\nasync def get_user_db(session: AsyncSession = Depends(get_session)):\n    yield SQLAlchemyUserDatabase(user, session, user_model)  # type: ignore\n\n\ndef create_transport() -> Transport:\n    return BearerTransport(tokenUrl=\"api/auth/token\")\n\n\ndef create_strategy() -> Strategy:\n    return JWTStrategy(secret=str(config.SECRET_KEY), lifetime_seconds=3600)\n\n\ndef create_backend() -> list[AuthenticationBackend]:\n    transport = create_transport()\n    return [\n        AuthenticationBackend(\n            name=\"bearer_jwt\", transport=transport, get_strategy=create_strategy\n        )\n    ]\n\n\nclass UserManager(BaseUserManager[user_create, user]):\n    user_db_model = user\n    reset_password_token_secret = str(SECRET_KEY)\n    verification_token_secret = str(SECRET_KEY)\n\n    async def on_after_register(self, user: user, request: Request | None = None):\n        print(f\"User {user.id} has registered.\")\n\n    async def on_after_forgot_password(\n        self, user: user, token: str, request: Request | None = None\n    ):\n        print(f\"User {user.id} has forgot their password. Reset token: {token}\")\n\n    async def on_after_request_verify(\n        self, user: user, token: str, request: Request | None = None\n    ):\n        print(f\"Verification requested for user {user.id}. Verification token: {token}\")\n\n\nasync def get_user_manager(user_db=Depends(get_user_db)):\n    yield UserManager(user_db)\n\n\ndef create_fastapi_users(*backends: AuthenticationBackend) -> FastAPIUsers:\n    return FastAPIUsers(\n        get_user_manager=get_user_manager,\n        auth_backends=backends,\n        user_model=user_base,\n        user_create_model=user_create,\n        user_update_model=user_update,\n        user_db_model=user,\n    )\n\n\n@dataclass(frozen=True)\nclass fastapi_user:\n    users: FastAPIUsers\n    backends: list[AuthenticationBackend]\n\n    @classmethod\n    def init(cls) -> \"fastapi_user\":\n        backends = create_backend()\n        users = create_fastapi_users(*backends)\n        return cls(users=users, backends=backends)\n\n```\n\në­”ê°€ ë§ì´ ì ì—ˆì§€ë§Œ ì‹¤ì œë¡œ ì§ì ‘ ì‘ì„±í–ˆë‹¤ê³  í• ë§Œí•œê±´ ë°ì´í„°í´ë˜ìŠ¤ **`fastapi_user`** ì •ë„ ë°–ì— ì—†ë‹¤. ì „ë¶€ **`fastapi-users`** ë ˆí¼ëŸ°ìŠ¤ì— ìˆëŠ” ë‚´ìš©ì´ë‹¤.\n\n`UserManager` ì™€ `AuthenticationBackend` ì¸ìŠ¤í„´ìŠ¤ëŠ” ì´í›„ ê³„ì •ê³¼ ê´€ë ¨ëœ ì‘ì—…ì„ í• ë•Œ ìì£¼ ì‚¬ìš©ëœë‹¤.\n\n### í† í° `api` ìƒì„±\n\nì´ì œ í† í°ì„ ìƒì„±í•˜ëŠ” apië¥¼ ìƒì„±í•œë‹¤. ì´ apiì˜ ì—”ë“œí¬ì¸íŠ¸ëŠ” `Transport`ë¥¼ ìƒì„±í•  ë•Œ ì‚¬ìš©í•œ `tokenUrl`ì˜ ê°’ê³¼ ì¼ì¹˜í•´ì•¼í•œë‹¤.\n\n```python\n# backend/app/api/routes/token.py\nfrom fastapi import APIRouter, Depends, HTTPException\nfrom fastapi.security import OAuth2PasswordRequestForm\nfrom fastapi_users import models\nfrom fastapi_users.authentication import Strategy\nfrom fastapi_users.manager import BaseUserManager\nfrom fastapi_users.router import ErrorCode\nfrom starlette.status import HTTP_400_BAD_REQUEST\n\nfrom .authentication import fastapi_user as fastapi_user_class\nfrom .authentication import get_user_manager\n\nfastapi_user = fastapi_user_class.init()\nrouter = APIRouter()\n\n\n@router.post(\"/token\")\nasync def create_token(\n    credentials: OAuth2PasswordRequestForm = Depends(),\n    user_manager: BaseUserManager[models.UC, models.UD] = Depends(get_user_manager),\n    strategy: Strategy[models.UC, models.UD] = Depends(\n        fastapi_user.backends[0].get_strategy\n    ),\n) -> dict[str, str]:\n    user = await user_manager.authenticate(credentials)\n    if user is None or not user.is_active:\n        raise HTTPException(\n            status_code=HTTP_400_BAD_REQUEST,\n            detail=ErrorCode.LOGIN_BAD_CREDENTIALS,\n        )\n    if not user.is_verified:\n        raise HTTPException(\n            status_code=HTTP_400_BAD_REQUEST,\n            detail=ErrorCode.LOGIN_USER_NOT_VERIFIED,\n        )\n\n    token = await strategy.write_token(user)\n    return {\"access_token\": token, \"token_type\": \"bearer\"}\n```\n\n### ì¸ì¦ ë°±ì—”ë“œ í™•ì¸ìš© ì„ì‹œ `api` ìƒì„±\n\nì´ì–´ì„œ ì¸ì¦ ë°±ì—”ë“œ ì„¤ì •ì´ ì˜ ëëŠ”ì§€ í™•ì¸í•´ë³¼ ì„ì‹œ ë¼ìš°í„°ë¥¼ ìƒì„±í•œë‹¤. ì‹¤ì œë¡œ ì‚¬ìš©í•  ìƒê°ì€ ì•„ë‹ˆê³ , ë§ ê·¸ëŒ€ë¡œ ì„ì‹œ í™•ì¸ìš©ì´ë‹¤.\n\n```python\n# backend/app/api/routes/users.py\nfrom fastapi import APIRouter\n\nfrom ...services.authentication import fastapi_user as fastapi_user_class\n\nfastapi_user = fastapi_user_class.init()\nrouter = APIRouter()\n\n\nrouter.include_router(\n    fastapi_user.users.get_auth_router(fastapi_user.backends[0]), prefix=\"/auth\"\n)\nrouter.include_router(fastapi_user.users.get_register_router(), prefix=\"/auth\")\nrouter.include_router(fastapi_user.users.get_verify_router(), prefix=\"/auth\")\n```\n\n```python\n# backend/api/routes/__init__.py\nfrom fastapi import APIRouter\n\nfrom .cleanings import router as cleanings_router\nfrom .token import router as token_router\nfrom .users import router as users_router\n\nrouter = APIRouter()\n\nrouter.include_router(cleanings_router, prefix=\"/cleanings\", tags=[\"cleanings\"])\nrouter.include_router(users_router, prefix=\"/users\", tags=[\"users\"])\nrouter.include_router(token_router, prefix=\"/auth\", tags=[\"token\"])\n```\n\nì´ì œ [http://localhost:8000/docs](http://localhost:8000/docs)ì—ì„œ í™•ì¸í•´ë³´ë©´ **`fastapi-users`** ì—ì„œ ì„¤ì •í•œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ìƒì„±í•´ë†“ì€ ìœ ì € ê´€ë ¨ apië¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤. ë˜í•œ, ë¡œê·¸ì¸ì‹œ ìƒì„±ë˜ëŠ” í† í°ì„ í—¤ë”ì— ì¶”ê°€í•˜ë©´ **`swagger`** ì—ì„œ ë¡œê·¸ì¸ì„ ì‹œë„í•´ë³¼ ìˆ˜ ìˆë‹¤.\n\në‹¤ìŒì€ ì´ë²ˆì— ì‘ì„±í•œ ë‚´ìš©ì„ ì¢€ ë” ë‹¤ë“¬ê³ , ì´ì „ê¹Œì§€ í–ˆë˜ ë°©ì‹ìœ¼ë¡œ **TDD** ë°©ë²•ë¡ ì— ë”°ë¼ apië¥¼ ìƒì„±í•  ìƒê°ì´ë‹¤.\n","mtime":"2022-08-13T00:12:20.000+09:00","href":"velog/fastapi íŠœí† ë¦¬ì–¼ -6- FastAPI Usersë¥¼ ì‚¬ìš©í•œ ìœ ì € api ìƒì„±","data":{"title":"fastapi íŠœí† ë¦¬ì–¼ -6- FastAPI Usersë¥¼ ì‚¬ìš©í•œ ìœ ì € api ìƒì„±","date":"2022-05-03T01:35:06.494+09:00","tags":["fastapi","fastapi-users","python","@all"],"page":"fastapi íŠœí† ë¦¬ì–¼","summary":"fastapi ì‚¬ìš©ë²•ì„ ë‹¤ì‹œ ê³µë¶€í• ê²¸, ì°¸ê³ í• ë§Œí•œ ì¢‹ì€ ì˜ˆì œê°€ ìˆì–´ì„œ ì´ ì‹œë¦¬ì¦ˆë¥¼ ì•½ê°„ì˜ ë³€ê²½ì„ ì£¼ê³  ë”°ë¼ê°€ë³´ë ¤ í•œë‹¤."}},{"name":"fastapi íŠœí† ë¦¬ì–¼ -7- FastAPI Usersë¥¼ ì‚¬ìš©í•œ ìœ ì € api ìƒì„± 2","content":"\n**`fastapi`** ì‚¬ìš©ë²•ì„ ë‹¤ì‹œ ê³µë¶€í• ê²¸, ì°¸ê³ í• ë§Œí•œ ì¢‹ì€ [ì˜ˆì œ](https://www.jeffastor.com/blog/populating-cleaning-jobs-with-user-offers-in-fastapi)ê°€ ìˆì–´ì„œ ì´ ì‹œë¦¬ì¦ˆë¥¼ ì•½ê°„ì˜ ë³€ê²½ì„ ì£¼ê³  ë”°ë¼ê°€ë³´ë ¤ í•œë‹¤.\nì§€ë‚œë²ˆì²˜ëŸ¼ ì–´ì©Œë‹¤ ê·¸ë§Œë‘˜ ìˆ˜ë„ ìˆê¸´ í•˜ì§€ë§Œ...\n\n---\n\n## ì‹œì‘í•˜ê¸° ì „ ë³€ê²½ì‚¬í•­\n\nì´ì „ ì±•í„°ì—ì„œ ë°íŒ ê²ƒ ì²˜ëŸ¼, ë‹¤ì†Œ ë‚œì¡í•˜ë‹¤ê³  ìƒê°ë˜ëŠ” ë¶€ë¶„ ëª‡ê°€ì§€ë¥¼ ìˆ˜ì •í•˜ì. ì§€ê¸ˆ ìˆ˜ì •í•œ ë¶€ë¶„ì´ ë‚˜ì¤‘ì— ì› ì˜ˆì œì—ì„œ ë‹¤ë¥¸ ë°©í–¥ìœ¼ë¡œ ìˆ˜ì •ë  ìˆ˜ë„ ìˆì§€ë§Œ, ê·¸ë•Œ ê°€ì„œ ìƒê°í•˜ì.\n\n> ### backend/app/core/config.py\n>\n> $\\rightarrow$ 1ê°œ ì„¤ì • ë³€ìˆ˜ ìƒì„±\n\n```python\nTOKEN_PREFIX = API_PREFIX + \"/token\"\n```\n\n> ### backend/app/db/engine.py\n\n```python\nfrom ..core.config import DATABASE_URL\n```\n\n$\\rightarrow$ `core.config` ì—ì„œ ê°’ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ë°©ì‹ìœ¼ë¡œ\n\n```python\nfrom ..core import config\n```\n\n> ### backend/app/models/user.py\n\n```python\nclass user_model(base_model, datetime_model, table=True):\n    __tablename__: str = \"users\"\n>\n    id: UUID4 = Field(default_factory=uuid4, primary_key=True)\n    name: str = Field(min_length=min_name_length, max_length=max_name_length)\n    hashed_password: str = Field(max_length=2**10)\n    email: EmailStr = Field(sa_column_kwargs={\"unique\": True})\n    is_active: bool = True\n    is_superuser: bool = False\n    is_verified: bool = False\n```\n\n$\\rightarrow$ `unique=True`ëŒ€ì‹  `index=True`ë¡œ ë³€ê²½\n\n```pythonê²½\nclass user_model(base_model, datetime_model, table=True):\n    __tablename__: str = \"users\"\n>\n    id: UUID4 = Field(default_factory=uuid4, primary_key=True)\n    name: str = Field(min_length=min_name_length, max_length=max_name_length)\n    hashed_password: str = Field(max_length=2**10)\n    email: EmailStr = Field(index=True)\n    is_active: bool = True\n    is_superuser: bool = False\n    is_verified: bool = False\n```\n\n> ### backend/app/services/authentication.py\n\n```python\nfrom ..core.config import SECRET_KEY\n```\n\n$\\rightarrow$ `core.config` ì—ì„œ ê°’ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ë°©ì‹ìœ¼ë¡œ\n\n```python\nfrom ..core import config\n```\n\n---\n\n```python\nfrom ..models.user import user, user_base, user_create, user_model, user_update\n```\n\n$\\rightarrow$ `models.user` ì—ì„œ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ë°©ì‹ìœ¼ë¡œ\n\n```python\nfrom ..models import user\n```\n\n---\n\n```python\nfrom pydantic import BaseModel\n>\n(...)\n>\nuser_manager_type = BaseUserManager[user.user_create, user.user]\nstrategy_type = Strategy[user.user_create, user.user]\n>\nclass token_model(BaseModel):\n    access_token: str\n    token_type: str = \"bearer\"\n>\n    @classmethod\n    def from_token(cls, token: str) -> \"token_model\":\n        return cls(access_token=token)\n```\n\n$\\rightarrow$ ìƒˆë¡œ ì •ì˜\n\n---\n\n```python\ndef create_transport() -> Transport:\n    return BearerTransport(tokenUrl=\"api/auth/token\")\n```\n\n$\\rightarrow$ `config.TOKEN_PREFIX` ì„¤ì • ë³€ìˆ˜ ì°¸ì¡°\n\n```python\ndef create_transport() -> Transport:\n    return BearerTransport(tokenUrl=config.TOKEN_PREFIX)\n```\n\n---\n\n```python\nclass UserManager(BaseUserManager[user.user_create, user.user]):\n    user_db_model = user.user\n    reset_password_token_secret = str(config.SECRET_KEY)\n    verification_token_secret = str(config.SECRET_KEY)\n>\n    min_password_length: int = 10\n    max_password_length: int = 30\n    re_password_need_list: list[Pattern] = [\n        re.compile(r\"[a-zA-Z]\"),\n        re.compile(r\"[0-9]\"),\n        re.compile(r\"[\\{\\}\\[\\]\\/?.,;:|\\)*~`!^\\-_+<>@\\#$%&\\\\\\=\\(\\'\\\"]\"),\n    ]\n    re_password_deny_list: list[Pattern] = []\n>\n    async def validate_password(\n        self, password: str, user: user.user_create | user.user\n    ) -> None:\n        if len(password) < self.min_password_length:\n            raise InvalidPasswordException(\n                reason=f\"Password should be at least {self.min_password_length} characters\"\n            )\n        elif len(password) > self.max_password_length:\n            raise InvalidPasswordException(\n                reason=f\"Password should be at most {self.max_password_length} characters\"\n            )\n>\n        for pattern in self.re_password_deny_list:\n            if pattern.match(password):\n                raise InvalidPasswordException(\n                    reason=f\"Password should not include {pattern.pattern}\"\n                )\n>\n        for pattern in self.re_password_need_list:\n            if not pattern.match(password):\n                raise InvalidPasswordException(\n                    reason=f\"Password must include {pattern.pattern}\"\n                )\n```\n\n$\\rightarrow$ ë¹„ë°€ë²ˆí˜¸ ìœ íš¨ì„± ê²€ì‚¬ ë¡œì§ ì¶”ê°€\n\n---\n\n```python\n@dataclass(frozen=True)\nclass fastapi_user:\n    users: FastAPIUsers\n    backends: list[AuthenticationBackend]\n>\n    @classmethod\n    def init(cls) -> \"fastapi_user\":\n        backends = create_backend()\n        users = create_fastapi_users(*backends)\n        return cls(users=users, backends=backends)\n```\n\n$\\rightarrow$ ì›ë˜ëŠ” ì‚­ì œí•˜ë ¤ í–ˆìœ¼ë‚˜, íŠ¹ì • ê¸°ëŠ¥ ì¶”ê°€ í›„ ì‚¬ìš©. ì˜ì¡´ì„±ì´ ë§ˆìŒì— ë“¤ì§€ ì•Šì§€ë§Œ, ì‚¬ì‹¤ìƒ ì„¤ì •ìš© ê°ì²´ë¼ ì¼ë‹¨ ë¬´ì‹œ.\n\n```python\n@dataclass(frozen=True)\nclass fastapi_user_class:\n    users: FastAPIUsers[user.user_base, user.user_create, user.user_update, user.user]\n>\n    @classmethod\n    def init(cls) -> \"fastapi_user_class\":\n        users = create_fastapi_users(*create_backend())\n        return cls(users=users)\n>\n    @property\n    def backends(self) -> Sequence[AuthenticationBackend[user.user_create, user.user]]:\n        return self.users.authenticator.backends\n>\n    @property\n    def user_manager_depends(self) -> user_manager_type:\n        return Depends(self.users.get_user_manager)\n>\n    def strategy_depends(self, num: int = 0, /) -> strategy_type:\n        backend = self.backends[num]\n        return Depends(backend.get_strategy)\n```\n\n---\n\nëìœ¼ë¡œ, **`fastapi-users`** ì˜ ê° í´ë˜ìŠ¤ê°€ ì œë„¤ë¦­ì¸ ê²ƒì„ í™•ì¸í•´ì„œ, ì´ì „ì— ì •ì˜í•œ ìœ ì € ëª¨ë¸ì„ ì´ìš©í•´ì„œ íƒ€ì… íŒíŠ¸ë¥¼ ì¶”ê°€í–ˆë‹¤. ì´í•˜ ìŠ¤í¬ë¦½íŠ¸ ì „ë¬¸\n\n```python\n# backend/app/services/authentication.py\nfrom dataclasses import dataclass\nfrom typing import AsyncGenerator, Sequence\n>\nfrom fastapi import Depends, Request\nfrom fastapi_users import BaseUserManager, FastAPIUsers\nfrom fastapi_users.authentication import (\n    AuthenticationBackend,\n    BearerTransport,\n    JWTStrategy,\n    Strategy,\n    Transport,\n)\nfrom fastapi_users.db import SQLAlchemyUserDatabase\nfrom pydantic import BaseModel\nfrom sqlmodel.ext.asyncio.session import AsyncSession\n>\nfrom ..core import config\nfrom ..db.session import get_session\nfrom ..models import user\n>\nuser_manager_type = BaseUserManager[user.user_create, user.user]\nstrategy_type = Strategy[user.user_create, user.user]\n>\n>\nclass token_model(BaseModel):\n    access_token: str\n    token_type: str = \"bearer\"\n>\n    @classmethod\n    def from_token(cls, token: str) -> \"token_model\":\n        return cls(access_token=token)\n>\n>\nasync def get_user_db(session: AsyncSession = Depends(get_session)):\n    yield SQLAlchemyUserDatabase(user.user, session, user.user_model)  # type: ignore\n>\n>\ndef create_transport() -> Transport:\n    return BearerTransport(tokenUrl=config.TOKEN_PREFIX)\n>\n>\ndef create_strategy() -> Strategy[user.user_create, user.user]:\n    return JWTStrategy(secret=str(config.SECRET_KEY), lifetime_seconds=3600)\n>\n>\ndef create_backend() -> list[AuthenticationBackend[user.user_create, user.user]]:\n    transport = create_transport()\n    return [\n        AuthenticationBackend(\n            name=\"bearer_jwt\", transport=transport, get_strategy=create_strategy\n        )\n    ]\n>\n>\nclass UserManager(BaseUserManager[user.user_create, user.user]):\n    user_db_model = user.user\n    reset_password_token_secret = str(config.SECRET_KEY)\n    verification_token_secret = str(config.SECRET_KEY)\n>\n    async def on_after_register(self, user: user.user, request: Request | None = None):\n        print(f\"User {user.id} has registered.\")\n>\n    async def on_after_forgot_password(\n        self, user: user.user, token: str, request: Request | None = None\n    ):\n        print(f\"User {user.id} has forgot their password. Reset token: {token}\")\n>\n    async def on_after_request_verify(\n        self, user: user.user, token: str, request: Request | None = None\n    ):\n        print(f\"Verification requested for user {user.id}. Verification token: {token}\")\n>\n>\nasync def get_user_manager(\n    user_db=Depends(get_user_db),\n) -> AsyncGenerator[UserManager, None]:\n    yield UserManager(user_db)\n>\n>\ndef create_fastapi_users(\n    *backends: AuthenticationBackend[user.user_create, user.user],\n) -> FastAPIUsers[user.user_base, user.user_create, user.user_update, user.user]:\n    return FastAPIUsers(\n        get_user_manager=get_user_manager,\n        auth_backends=backends,\n        user_model=user.user_base,\n        user_create_model=user.user_create,\n        user_update_model=user.user_update,\n        user_db_model=user.user,\n    )\n>\n>\n@dataclass(frozen=True)\nclass fastapi_user_class:\n    users: FastAPIUsers[user.user_base, user.user_create, user.user_update, user.user]\n>\n    @classmethod\n    def init(cls) -> \"fastapi_user_class\":\n        users = create_fastapi_users(*create_backend())\n        return cls(users=users)\n>\n    @property\n    def backends(self) -> Sequence[AuthenticationBackend[user.user_create, user.user]]:\n        return self.users.authenticator.backends\n>\n    @property\n    def user_manager_depends(self) -> user_manager_type:\n        return Depends(self.users.get_user_manager)\n>\n    def strategy_depends(self, num: int = 0, /) -> strategy_type:\n        backend = self.backends[num]\n        return Depends(backend.get_strategy)\n```\n\n> ### backend/app/services/token.py\n\n#### ìœ„ì¹˜ ë³€ê²½\n\n`backend/app/services/token.py`\n$\\rightarrow$ `backend/app/api/routes/token.py`\n\n---\n\n```python\nfrom ...services.authentication import fastapi_user as fastapi_user_class\n```\n\n$\\rightarrow$ í´ë˜ìŠ¤ ì´ë¦„ ë³€ê²½ì— ë”°ë¥¸ ìˆ˜ì •\n\n```python\nfrom ...services.authentication import fastapi_user_class\n```\n\n---\n\n```python\nfrom starlette.status import HTTP_400_BAD_REQUEST\n```\n\n$\\rightarrow$ `fastapi.status` ì—ì„œ ê°’ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ë°©ì‹ìœ¼ë¡œ\n\n```pyhon\nfrom fastapi import status\n```\n\n---\n\n```python\nfrom fastapi_users import models\n>\n@router.post(\"/token\")\nasync def create_token(\n    credentials: OAuth2PasswordRequestForm = Depends(),\n    user_manager: BaseUserManager[models.UC, models.UD] = Depends(get_user_manager),\n    strategy: Strategy[models.UC, models.UD] = Depends(\n        fastapi_user.backends[0].get_strategy\n    ),\n) -> dict[str, str]:\n    user = await user_manager.authenticate(credentials)\n    if user is None or not user.is_active:\n        raise HTTPException(\n            status_code=HTTP_400_BAD_REQUEST,\n            detail=ErrorCode.LOGIN_BAD_CREDENTIALS,\n        )\n    if not user.is_verified:\n        raise HTTPException(\n            status_code=HTTP_400_BAD_REQUEST,\n            detail=ErrorCode.LOGIN_USER_NOT_VERIFIED,\n        )\n>\n    token = await strategy.write_token(user)\n    return {\"access_token\": token, \"token_type\": \"bearer\"}\n```\n\n$\\rightarrow$ ìµœìƒìœ„ ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš© + `user_manager_type`, `strategy_type`, `token_model` ì‚¬ìš©\n\n```python\nfrom ...services.authentication import strategy_type, token_model, user_manager_type\n>\n(...)\n>\n@router.post(\"\", name=\"users:create-token\")\nasync def create_token(\n    credentials: OAuth2PasswordRequestForm = Depends(),\n    user_manager: user_manager_type = fastapi_user.user_manager_depends,\n    strategy: strategy_type = fastapi_user.strategy_depends(),\n) -> token_model:\n    get_user = await user_manager.authenticate(credentials)\n    if get_user is None or not get_user.is_active:\n        raise HTTPException(\n            status_code=status.HTTP_400_BAD_REQUEST,\n            detail=ErrorCode.LOGIN_BAD_CREDENTIALS,\n        )\n    if not get_user.is_verified:\n        raise HTTPException(\n            status_code=status.HTTP_400_BAD_REQUEST,\n            detail=ErrorCode.LOGIN_USER_NOT_VERIFIED,\n        )\n>\n    token = await strategy.write_token(get_user)\n    return token_model.from_token(token)\n```\n\n> ### backend/app/api/routes/cleanings.py\n\n```python\nfrom ...services.authentication import fastapi_user as fastapi_user_class\n```\n\n$\\rightarrow$ í´ë˜ìŠ¤ ì´ë¦„ ë³€ê²½ì— ë”°ë¥¸ ìˆ˜ì •\n\n```python\nfrom ...services.authentication import fastapi_user_class\n```\n\n---\n\n```python\nfrom starlette.status import (\n    HTTP_201_CREATED,\n    HTTP_404_NOT_FOUND,\n    HTTP_422_UNPROCESSABLE_ENTITY,\n)\n```\n\n$\\rightarrow$ `fastapi.status` ì—ì„œ ê°’ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ë°©ì‹ìœ¼ë¡œ\n\n```python\nfrom fastapi import status\n```\n\n---\n\n```python\nfrom ...models.cleaning import (\n    cleaning_create,\n    cleaning_public,\n    cleaning_update,\n    cleanings,\n)\n```\n\n$\\rightarrow$ `models.cleaning` ì—ì„œ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ë°©ì‹ìœ¼ë¡œ\n\n```python\nfrom ...models import cleaning\n```\n\n> ### backend/app/api/routes/\\_\\_init\\_\\_.py\n\n```python\nrouter.include_router(token_router, prefix=\"/auth\", tags=[\"token\"])\n```\n\n$\\rightarrow$ `auth` ëŒ€ì‹  `token`ìœ¼ë¡œ ë‹¨ì¼í™”\n\n```python\nrouter.include_router(token_router, prefix=\"/token\", tags=[\"token\"])\n```\n\n> ### backend/tests/conftest.py\n\n```python\n@pytest.fixture(\n    params=[pytest.param((\"asyncio\", {\"use_uvloop\": True}), id=\"asyncio+uvloop\")]\n)\ndef anyio_backend(request):\n    return request.param\n```\n\n$\\rightarrow$ **`pytest`** ë°±ì—”ë“œë¡œ **`anyio+uvloop`** ë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•œ ì„¤ì • ì¶”ê°€\n\n> ### backend/tests/test_cleanings.py\n\n```python\npytestmark = pytest.mark.asyncio\n```\n\n$\\rightarrow$ **`pytest`** ë°±ì—”ë“œë¡œ **`anyio+uvloop`** ë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•œ ì„¤ì • ì¶”ê°€\n\n```python\npytestmark = pytest.mark.anyio\n```\n\n---\n\n```python\nfrom starlette.status import (\n    HTTP_200_OK,\n    HTTP_201_CREATED,\n    HTTP_404_NOT_FOUND,\n    HTTP_422_UNPROCESSABLE_ENTITY,\n)\n```\n\n$\\rightarrow$ `fastapi.status` ì—ì„œ ê°’ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ë°©ì‹ìœ¼ë¡œ\n\n```python\nfrom fastapi import status\n```\n\n> ### ì‹ ê·œ ìƒì„±) backend/pytest.ini\n\n```bash\nâ¯ touch backend/pytest.ini\n```\n\n```yaml\n[pytest]\nfilterwarnings =\n    ignore::sqlalchemy.exc.SAWarning\n```\n\n$\\rightarrow$ **`sqlalchemy`** ì—ì„œ ë³´ë‚´ëŠ” ê²½ê³ ë¥¼ **`pytest`** ì—ì„œ ì¶œë ¥í•˜ì§€ ì•Šë„ë¡ ì„¤ì •\n\nìœ„ ìˆ˜ì •ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆë“¯ì´, **`pytest`** ë°±ì—”ë“œë¡œ **`anyio`** ë¥¼ ì“°ê¸° ë•Œë¬¸ì—, **`pytest-asyncio`** ëŠ” ì´ì œ í•„ìš”ê°€ ì—†ìœ¼ë¯€ë¡œ ì œê±°í•œë‹¤.\n\n```bash\nâ¯ poetry remove --dev pytest-asyncio\nâ¯ poetry export -f requirements.txt --output backend/requirements.txt --without-hashes --dev\nâ¯ docker-compose build\n```\n\nê¹œë°•í•˜ê³  ë„˜ì–´ê°„ ê²½ìš°ê°€ ìˆì„í…ë°, í…ŒìŠ¤íŠ¸ ì½”ë“œë¥¼ ì‹¤í–‰í•´ë³´ë©´ ê¸ˆë°© ìˆ˜ì •í•  ìˆ˜ ìˆë‹¤.\n\n## `TDD` ë°©ë²•ë¡ ì— ë”°ë¥¸ ìœ ì € ìƒì„± `api` ë§Œë“¤ê¸°\n\n### ë¼ìš°í„° ì¡´ì¬ í™•ì¸\n\nì› ì˜ˆì œì˜ **jeffastor**ëŠ” íšŒì›ê°€ì… apiì— ìš”ì²­ì„ ë³´ë‚´ê³  ì—ëŸ¬ ì½”ë“œë¥¼ í™•ì¸í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ë§Œë“¤ì—ˆì§€ë§Œ, ìµœê·¼ì— **RESTful** api ìƒì„±ê³¼ ê´€ë ¨í•´ì„œ [ì¢‹ì€ ê¸€](https://sanghaklee.tistory.com/57)ì„ í™•ì¸í–ˆê¸°ì—, **OPTIONS** apië¡œ ëŒ€ì‹ í•˜ê³ ì í•œë‹¤.\n\n```bash\nâ¯ touch backend/tests/test_users.py\n```\n\n```python\n# backend/tests/test_users.py\nimport pytest\nfrom fastapi import FastAPI, status\nfrom httpx import AsyncClient\n\npytestmark = pytest.mark.anyio\n\n\nclass TestUserRoutes:\n    api_name = \"users:get-allowed-methods\"\n\n    async def test_routes_exist(self, app: FastAPI, client: AsyncClient) -> None:\n        res = await client.options(app.url_path_for(self.api_name))\n        assert res.status_code == status.HTTP_204_NO_CONTENT\n        assert not res.content\n        headers = res.headers\n        assert \"Allow\" in headers\n        allowed_methods_str = headers[\"Allow\"]\n        allowed_methods = {\n            method_str.strip().lower() for method_str in allowed_methods_str.split(\",\")\n        }\n        assert len(allowed_methods) > 0\n        for method_str in (\"post\",):\n            assert method_str in allowed_methods\n```\n\ní…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•´ë³´ë©´ ë‹¹ì—°íˆ ì—ëŸ¬ê°€ ë‚˜ì˜¨ë‹¤.\n\n```bash\nroot@90b2a10bcb6d:/backend# pytest --tb=short\n============================================ test session starts ============================================\nplatform linux -- Python 3.10.4, pytest-7.1.2, pluggy-1.0.0\nrootdir: /backend, configfile: pytest.ini\nplugins: anyio-3.5.0\ncollected 40 items\n\ntests/test_cleanings.py .......................................                                       [ 97%]\ntests/test_users.py F                                                                                 [100%]\n\n================================================= FAILURES ==================================================\n_____________________________ TestUserRoutes.test_routes_exist[asyncio+uvloop] ______________________________\ntests/test_users.py:10: in test_routes_exist\n    res = await client.options(app.url_path_for(\"users:get-allowed-methods\"))\n/usr/local/lib/python3.10/site-packages/starlette/applications.py:108: in url_path_for\n    return self.router.url_path_for(name, **path_params)\n/usr/local/lib/python3.10/site-packages/starlette/routing.py:590: in url_path_for\n    raise NoMatchFound()\nE   starlette.routing.NoMatchFound\n----------------------------------------- Captured stderr teardown ------------------------------------------\nINFO  [alembic.env] Running migrations online\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\n========================================== short test summary info ==========================================\nFAILED tests/test_users.py::TestUserRoutes::test_routes_exist[asyncio+uvloop] - starlette.routing.NoMatchF...\n======================================= 1 failed, 39 passed in 4.52s ========================================\n```\n\nì´ì œ ì—ëŸ¬ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ ë¼ìš°í„°ë¥¼ ìƒì„±í•œë‹¤.\n\n```python\n# backend/app/api/routes/users.py\nfrom fastapi import APIRouter, Response, status\n\nfrom ...services.authentication import fastapi_user_class\n\nfastapi_user = fastapi_user_class.init()\nrouter = APIRouter()\n\n\n@router.options(\"\", name=\"users:get-allowed-methods\")\nasync def get_allowed_user_methods() -> Response:\n    from functools import reduce\n\n    method_sets = [getattr(route, \"methods\") for route in router.routes]\n    all_methods = reduce(lambda left, right: left | right, method_sets, set())\n    all_methods_str = \", \".join(all_methods)\n\n    return Response(\n        status_code=status.HTTP_204_NO_CONTENT, headers={\"Allow\": all_methods_str}\n    )\n\n\n@router.post(\"\")\nasync def post_temp():\n    ...\n```\n\nì„ì‹œë¡œ ê°€ì§œ **POST** apië¥¼ ì •ì˜í–ˆê¸°ì—, í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•´ë„ ì—ëŸ¬ê°€ ë°œìƒí•˜ì§€ ì•ŠëŠ”ë‹¤.\n\n```bash\nroot@96deef95611e:/backend# pytest --tb=short\n============================================ test session starts ============================================\nplatform linux -- Python 3.10.4, pytest-7.1.2, pluggy-1.0.0\nrootdir: /backend, configfile: pytest.ini\nplugins: anyio-3.5.0\ncollected 40 items\n\ntests/test_cleanings.py .......................................                                       [ 97%]\ntests/test_users.py .                                                                                 [100%]\n\n============================================ 40 passed in 4.03s =============================================\n```\n\n### íšŒì›ê°€ì…\n\nìš°ì„ , ê¸°ì¡´ì— ì‘ì„±í–ˆë˜ ìœ ì € ëª¨ë¸ì— ëŒ€í•´ ì´ë©”ì¼ë¡œ ê²€ìƒ‰í•  ìˆ˜ ìˆëŠ” ë©”ì†Œë“œë¥¼ í•˜ë‚˜ ìƒì„±í•œë‹¤. ê´€ë ¨í•´ì„œ ì¢…ì¢… ì“°ì´ê¸° ë•Œë¬¸.\n\n```python\n# backend/app/models/user.py\nfrom typing import TypeVar, cast\nfrom sqlmodel import select\nfrom sqlmodel.ext.asyncio.session import AsyncSession\nfrom sqlmodel.sql.expression import Select\n\n(...)\n\n_T = TypeVar(\"_T\", bound=\"user_model\")\n\n(...)\n\nclass user(user_base, models.BaseUserDB):\n    def to_model(self) -> \"user_model\":\n        return user_model.validate(self)\n\n\nclass user_model(base_model, datetime_model, table=True):\n    __tablename__: str = \"users\"\n\n    id: UUID4 = Field(default_factory=uuid4, primary_key=True)\n    name: str = Field(min_length=min_name_length, max_length=max_name_length)\n    hashed_password: str = Field(max_length=2**10)\n    email: EmailStr = Field(index=True)\n    is_active: bool = True\n    is_superuser: bool = False\n    is_verified: bool = False\n\n    @classmethod\n    async def get_from_email(\n        cls: type[_T], session: AsyncSession, email: str\n    ) -> _T | None:\n        is_user_cur = await session.exec(\n            cast(Select[_T], select(cls).where(cls.email == email))\n        )\n        return is_user_cur.first()\n```\n\n> ì•„ì§ **`sqlmodel`** ì˜ `async` ì§€ì›ì´ ë¶€ì¡±í•´ì„œ, `typing.cast`ë¥¼ ì´ìš©í•´ì„œ `Select` íƒ€ì…ìœ¼ë¡œ ê°•ì œí•´ì„œ ì‚¬ìš©í–ˆë‹¤.\n\n> `user`ì™€ `user_model`ì„ í•˜ë‚˜ë¡œ í•©ì¹  ìˆ˜ ìˆì„ ê²ƒ ê°™ì€ë°, ì´ê±´ ë‚˜ì¤‘ì— ì‹œê°„ë‚´ì„œ í™•ì¸í•´ë³¼ ìƒê°.\n\nì´ì œ **`fastapi-users`** ë¥¼ ì‚¬ìš©í•  ë•Œê°€ ì™”ë‹¤. ìš°ì„  í…ŒìŠ¤íŠ¸ ì½”ë“œë¶€í„° ì‘ì„±í•œë‹¤.\n\n```python\n# backend/tests/test_users.py\nfrom app.models import user\nfrom sqlalchemy.ext.asyncio import AsyncEngine\nfrom sqlmodel.ext.asyncio.session import AsyncSession\n\n(...)\n\nclass TestUserRegistration:\n    api_name = \"users:register-new-user\"\n\n    async def test_users_can_register_successfully(\n        self, app: FastAPI, client: AsyncClient, engine: AsyncEngine\n    ) -> None:\n        new_user = {\n            \"email\": \"shakira@shakira.io\",\n            \"name\": \"shakirashakira\",\n            \"password\": \"chantaje@1\",\n        }\n        # make sure user doesn't exist yet\n        async with AsyncSession(engine, autocommit=False) as session:\n            is_user = await user.user_model.get_from_email(\n                session=session, email=new_user[\"email\"]\n            )\n        assert is_user is None\n        # send post request to create user and ensure it is successful\n        res = await client.post(\n            app.url_path_for(self.api_name), json={\"new_user\": new_user}\n        )\n        assert res.status_code == status.HTTP_201_CREATED\n        # ensure that the user now exists in the db\n        async with AsyncSession(engine, autocommit=False) as session:\n            is_user = await user.user_model.get_from_email(\n                session=session, email=new_user[\"email\"]\n            )\n        assert is_user is not None\n        assert is_user.email == new_user[\"email\"]\n        assert is_user.name == new_user[\"name\"]\n        # check that the user returned in the response is equal to the user in the database\n        created_user = user.user_model.validate(\n            res.json() | {\"hashed_password\": \"whatever\"}\n        )\n        exclude_attr_set = user.user_model.datetime_attrs | {\"id\", \"hashed_password\"}\n        assert created_user.dict(exclude=exclude_attr_set) == is_user.dict(\n            exclude=exclude_attr_set\n        )\n\n    @pytest.mark.parametrize(\n        \"attr, value, status_code\",\n        (\n            (\"email\", \"shakira@shakira.io\", 400),\n            (\"name\", \"sha\", 422),\n            (\"name\", \"shafasdfsdwerewfsdfxcvxcvxcv\", 422),\n            (\"email\", \"invalid_email@one@two.io\", 422),\n            (\"password\", \"short\", 422),\n            (\n                \"password\",\n                (\n                    \"longlonglonglonglonglonglonglonglonglonglonglong\"\n                    \"longlonglonglonglonglonglonglonglonglonglonglong\"\n                    \"longlonglonglonglonglonglonglonglonglonglonglong\"\n                ),\n                422,\n            ),\n            (\"password\", \"pattern@\", 422),\n            (\"name\", \"shakira@#$%^<>\", 422),\n            (\"name\", \"ab\", 422),\n        ),\n    )\n    async def test_user_registration_fails_when_credentials_are_taken(\n        self,\n        app: FastAPI,\n        client: AsyncClient,\n        attr: str,\n        value: str,\n        status_code: int,\n    ) -> None:\n        new_user = {\n            \"email\": \"nottaken@email.io\",\n            \"name\": \"not_taken_username\",\n            \"password\": \"freepassword@1\",\n        }\n        new_user[attr] = value\n        res = await client.post(\n            app.url_path_for(self.api_name), json={\"new_user\": new_user}\n        )\n        assert res.status_code == status_code\n```\n\nì´ì œ ìœ„ í…ŒìŠ¤íŠ¸ ì½”ë“œë¥¼ í†µê³¼í•  ìˆ˜ ìˆì„ ê²ƒ ê°™ì€ apië¥¼ ìƒì„±í•œë‹¤.\n\n```python\nimport re\n\nimport orjson\nfrom fastapi import Body, HTTPException, Request\nfrom fastapi_users.manager import InvalidPasswordException, UserAlreadyExists\nfrom pydantic import ValidationError\n\nfrom ...models import user\nfrom ...services.authentication import user_manager_type\n\n(...)\n\nre_deny_name = re.compile(r\"[^a-zA-Z0-9_-]\")\n\n(...)\n\n@router.post(\n    \"\",\n    name=\"users:register-new-user\",\n    response_model=user.user_read,\n    status_code=status.HTTP_201_CREATED,\n)\nasync def register_new_user(\n    request: Request,\n    new_user: user.user_create = Body(..., embed=True),\n    user_manager: user_manager_type = fastapi_user.user_manager_depends,\n):\n    if re_deny_name.search(new_user.name):\n        raise HTTPException(\n            status_code=status.HTTP_422_UNPROCESSABLE_ENTITY,\n            detail=(\n                \"The name can only contain the following characters: \"\n                f\"{re_deny_name.pattern.replace('^','')}\"\n            ),\n        )\n\n    try:\n        return await user_manager.create(new_user, safe=True, request=request)\n    except UserAlreadyExists as exc:\n        raise HTTPException(\n            status_code=status.HTTP_400_BAD_REQUEST,\n            detail=(\n                \"That email is already taken. \"\n                \"Login with that email or register with another one.\"\n            ),\n        )\n    except ValidationError as exc:\n        raise HTTPException(\n            status_code=status.HTTP_422_UNPROCESSABLE_ENTITY,\n            detail=orjson.loads(exc.json()),\n        )\n    except InvalidPasswordException as exc:\n        raise HTTPException(\n            status_code=status.HTTP_422_UNPROCESSABLE_ENTITY,\n            detail=exc.reason,\n        )\n\n```\n\n> ë”°ë¡œ ì ì§€ëŠ” ì•Šì•˜ì§€ë§Œ, **TDD** ë°©ë²•ë¡ ì„ ì¶©ì‹¤íˆ ì´í–‰í•˜ë©´ì„œ ë§Œë“¤ì–´ì§„ í…ŒìŠ¤íŠ¸ ì½”ë“œì™€ apië‹¤.\n\nìœ„ ì½”ë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•´ë³´ë©´, ëª¨ë‘ ì •ìƒì ìœ¼ë¡œ ì‹¤í–‰ë˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.\n\n### í† í°\n\n**`fastapi-users`** ë•ë¶„ì— í† í° ë“±ì— ëŒ€í•œ ë³„ë‹¤ë¥¸ ì‘ì—… ì—†ì´ ê¹”ë”í•˜ê²Œ ëë‚¬ì§€ë§Œ, ì› ì˜ˆì œì—ì„œëŠ” í† í°ê³¼ ê´€ë ¨ëœ ëª‡ê°€ì§€ ì‘ì—…ì´ ì§„í–‰ëœë‹¤. í•´ë‹¹ ê³¼ì • ì¤‘ í•´ë³´ë©´ ì¢‹ì„ ê²ƒ ê°™ì€ ë¶€ë¶„ë§Œ ë”°ë¼ì„œ ì§„í–‰í•œë‹¤.\n\n#### í† í° ê´€ë ¨ ì„¤ì • ìˆ˜ì • ë° ì¶”ê°€\n\nì´ˆê¸°ì— ëŒ€ì¶© ì‘ì„±í•´ë†¨ë˜ `SECRET_KEY` ë“±ì˜ ê°’ì„ ì§€ì •í•´ì¤€ë‹¤. ì´ ê°’ì„ ì§ì ‘ ì‘ì„±í•˜ê¸° ë³´ë‹¤ëŠ” ê·¸ëƒ¥ í„°ë¯¸ë„ ëª…ë ¹ì–´ë¡œ ìƒì„±ëœ ì„ì˜ì˜ ê°’ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¢‹ë‹¤.\n\n```bash\nâ¯ openssl rand -hex 32\n```\n\nì´ì œ ì´ ê°’ì„ `.env` íŒŒì¼ì— ì¶”ê°€í•˜ë©´ ëœë‹¤. ì´ ì™¸ì—ë„ ëª‡ëª‡ ê°’ì„ ì¶”ê°€ë¡œ ë” ì„¤ì •í•˜ëŠ”ë° ê° ê°’ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.\n\n> `ACCESS_TOKEN_EXPIRE_SECONDS`: í† í°ì˜ ë§Œë£Œì‹œê°„(ì´ˆ)\n> `JWT_ALGORITHM`: í† í° ì•”í˜¸í™” ì•Œê³ ë¦¬ì¦˜\n> `JWT_AUDIENCE`: í† í° ë°œê¸‰/ìˆ˜ì‹  ëŒ€ìƒ\n> `JWT_TOKEN_PREFIX`: í† í° íƒ€ì…?(ì–˜ëŠ” í™•ì‹¤í•˜ì§€ ì•ŠìŒ)\n\nì´ì œ `config.py`ê°€ ìœ„ ê°’ì„ ì˜ ì½ì„ ìˆ˜ ìˆê²Œ ìˆ˜ì •í•œë‹¤.\n\n```python\n# backend/app/core/config.py\n(...)\n\nACCESS_TOKEN_EXPIRE_MINUTES = config(\n    \"ACCESS_TOKEN_EXPIRE_MINUTES\", cast=int, default=60 * 60\n)\nJWT_ALGORITHM = config(\"JWT_ALGORITHM\", cast=str, default=\"HS256\")\nJWT_AUDIENCE = config(\"JWT_AUDIENCE\", cast=str, default=\"phresh:auth\")\nJWT_TOKEN_PREFIX = config(\"JWT_TOKEN_PREFIX\", cast=str, default=\"Bearer\")\n\n(...)\n```\n\nê·¸ë¦¬ê³  ì´ ê°’ì„ ì˜ ì°¸ì¡°í•  ìˆ˜ ìˆë„ë¡ ìˆ˜ì •í•œë‹¤.\n\n```python\n# backend/app/services/authentication.py\n(...)\n\nclass token_model(BaseModel):\n    access_token: str\n    token_type: str = config.JWT_TOKEN_PREFIX\n\n    @classmethod\n    def from_token(cls, token: str) -> \"token_model\":\n        return cls(access_token=token)\n\n(...)\n\ndef create_strategy() -> Strategy[user.user_create, user.user]:\n    return JWTStrategy(\n        secret=str(config.SECRET_KEY),\n        lifetime_seconds=config.ACCESS_TOKEN_EXPIRE_SECONDS,\n        token_audience=[config.JWT_AUDIENCE],\n        algorithm=config.JWT_ALGORITHM,\n    )\n\n(...)\n```\n\ní…ŒìŠ¤íŠ¸ ì½”ë“œì—ì„œ ì‚¬ìš©í•  `fixture`ë¥¼ ì •ì˜í•œë‹¤. ì¤‘ë³µ ì´ë©”ì¼ì„ í—ˆìš©í•˜ì§€ ì•Šê¸°ì— ì£¼ì˜í•´ì„œ ì‘ì„±í•œë‹¤.\n\n```python\n# backend/tests/conftest.py\nfrom app.models import user\nfrom app.services.authentication import UserManager\nfrom fastapi_users.db import SQLAlchemyUserDatabase\nfrom sqlmodel.ext.asyncio.session import AsyncSession\n\n(...)\n\n@pytest.fixture\nasync def test_user(engine: AsyncEngine) -> user.user_model:\n    new_user = user.user_create.parse_obj(\n        dict(\n            email=\"lebron@james.io\",\n            name=\"lebronjames\",\n            password=\"heatcavslakers@1\",\n        )\n    )\n\n    async with AsyncSession(engine, autocommit=False) as session:\n        db = SQLAlchemyUserDatabase(user.user, session, user.user_model)  # type: ignore\n        manager = UserManager(db)\n\n        try:\n            new_user_db = await manager.get_by_email(new_user.email)\n        except UserNotExists:\n            new_user_db = await manager.create(new_user, safe=True)\n\n    return new_user_db.to_model()\n```\n\nì´ì œ ì´ `fixture`ë¥¼ ì´ìš©í•´ì„œ í† í°ì„ ë°œê¸‰ë°›ê³ , ê²€ì¦í•˜ëŠ” í…ŒìŠ¤íŠ¸ ì½”ë“œë¥¼ ì‘ì„±í•œë‹¤.\n\n> 2022.05.06. ì•„ë˜ í…ŒìŠ¤íŠ¸ ì½”ë“œëŠ” ì‚¬ì‹¤ìƒ ë¬´ì˜ë¯¸í•˜ê¸°ì—, ì—†ì–´ë„ ì¢‹ë‹¤. **TDD**ì— ìµìˆ™í•˜ì§€ ì•Šì€ ê²ƒë„ ìˆê³ , ì› ì˜ˆì œì˜ ë‚´ìš©ê³¼ ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ apië¥¼ ìƒì„±í•˜ë‹¤ë³´ë‹ˆ í—·ê°ˆë ¤ì„œ ì˜ëª» ì‘ì„±í•œ ê²ƒ ê°™ë‹¤. ë‹¤ìŒ ì±•í„°ì˜ ë¡œê·¸ì¸ í…ŒìŠ¤íŠ¸ ì½”ë“œë¥¼ í™•ì¸í•˜ì.\n\n```python\nclass TestAuthTokens:\n    api_name = \"users:create-token\"\n\n    async def test_can_create_access_token_successfully(\n        self,\n        app: FastAPI,\n        client: AsyncClient,\n        test_user: user.user_model,\n        strategy: JWTStrategy,\n        engine: AsyncEngine,\n    ) -> None:\n        access_token = await strategy.write_token(user=test_user)\n        creds = decode_jwt(\n            access_token,\n            str(config.SECRET_KEY),\n            [config.JWT_AUDIENCE],\n            [config.JWT_ALGORITHM],\n        )\n\n        assert creds.get(\"user_id\") is not None\n        user_id = creds[\"user_id\"]\n        assert config.JWT_AUDIENCE in creds[\"aud\"]\n\n        async with AsyncSession(engine, autocommit=False) as session:\n            user_model = await session.get(user.user_model, user_id)\n        assert user_model is not None\n\n        assert user_model.name == test_user.name\n\n    async def test_token_missing_user_is_invalid(\n        self, app: FastAPI, client: AsyncClient\n    ) -> None:\n        res = await client.post(\n            url=app.url_path_for(self.api_name),\n            data={\"username\": \"unknown\", \"password\": \"testpassword@1\"},\n        )\n        assert res.status_code == status.HTTP_422_UNPROCESSABLE_ENTITY\n```\n\nì› ì˜ˆì œëŠ” í…ŒìŠ¤íŠ¸ ì½”ë“œê°€ ì¡°ê¸ˆ ë” í’ë¶€í•˜ì§€ë§Œ, **`fastapi-users`** ë¥¼ ì‚¬ìš©ì¤‘ì´ê¸°ì—, ë¶ˆí•„ìš”í•œ ê³¼ì •ì´ë¼ ìƒê°ëë‹¤. ìœ„ í…ŒìŠ¤íŠ¸ ì½”ë“œì—ì„œ `strategy`ë¥¼ ì´ìš©í•˜ì—¬ ì§ì ‘ `access_token`ì„ ìƒì„±í•´ë³´ê¸°ë„ í•˜ê³  ë³µí˜¸í™”í•´ë³´ê¸°ë„ í•˜ë©°, `access_token`ë¡œ ë¶€í„° ìœ ì €ë¥¼ ë¶ˆëŸ¬ì˜¤ê¸°ë„ í•œë‹¤. ëìœ¼ë¡œ ì´ëŸ¬í•œ ê³¼ì •ì´ ì§„í–‰ë˜ëŠ” apië¥¼ í˜¸ì¶œí•´ë³´ê¸°ë„ í•œë‹¤.\n\ní…ŒìŠ¤íŠ¸ëŠ” ë¬¸ì œì—†ì´ ì˜ ì§„í–‰ëë‹¤.\n\në‹¤ìŒ ì±•í„°ì—ì„œëŠ” ì§€ê¸ˆê¹Œì§€ ë§Œë“  ìœ ì € apië¡œ ë¡œê·¸ì¸ ë“±ì„ ì‹œë„í•œë‹¤. ì°¸ê³ ë¡œ, í˜„ì¬ ì„ íƒí•œ ì „ëµìœ¼ë¡œëŠ”, ì„œë²„ê°€ ì´ë¯¸ ë°œê¸‰í•œ í† í°ì— ëŒ€í•´ ì²˜ë¦¬ê°€ ë¶ˆê°€ëŠ¥í•˜ë¯€ë¡œ, ë¡œê·¸ì•„ì›ƒ ê¸°ëŠ¥ì„ ìƒì„±í•  ìˆ˜ ì—†ë‹¤.\n","mtime":"2022-08-13T00:12:20.000+09:00","href":"velog/fastapi íŠœí† ë¦¬ì–¼ -7- FastAPI Usersë¥¼ ì‚¬ìš©í•œ ìœ ì € api ìƒì„± 2","data":{"title":"fastapi íŠœí† ë¦¬ì–¼ -7- FastAPI Usersë¥¼ ì‚¬ìš©í•œ ìœ ì € api ìƒì„± 2","date":"2022-05-05T06:13:07.421+09:00","tags":["fastapi","fastapi-users","python","@all"],"page":"fastapi íŠœí† ë¦¬ì–¼","summary":"fastapi ì‚¬ìš©ë²•ì„ ë‹¤ì‹œ ê³µë¶€í• ê²¸, ì°¸ê³ í• ë§Œí•œ ì¢‹ì€ ì˜ˆì œê°€ ìˆì–´ì„œ ì´ ì‹œë¦¬ì¦ˆë¥¼ ì•½ê°„ì˜ ë³€ê²½ì„ ì£¼ê³  ë”°ë¼ê°€ë³´ë ¤ í•œë‹¤."}},{"name":"fastapi íŠœí† ë¦¬ì–¼ -8- FastAPI Usersë¥¼ ì‚¬ìš©í•œ ìœ ì € api ìƒì„± 3","content":"\n**`fastapi`** ì‚¬ìš©ë²•ì„ ë‹¤ì‹œ ê³µë¶€í• ê²¸, ì°¸ê³ í• ë§Œí•œ ì¢‹ì€ [ì˜ˆì œ](https://www.jeffastor.com/blog/populating-cleaning-jobs-with-user-offers-in-fastapi)ê°€ ìˆì–´ì„œ ì´ ì‹œë¦¬ì¦ˆë¥¼ ì•½ê°„ì˜ ë³€ê²½ì„ ì£¼ê³  ë”°ë¼ê°€ë³´ë ¤ í•œë‹¤.\nì§€ë‚œë²ˆì²˜ëŸ¼ ì–´ì©Œë‹¤ ê·¸ë§Œë‘˜ ìˆ˜ë„ ìˆê¸´ í•˜ì§€ë§Œ...\n\n---\n\n## í† í° ë°œí–‰ ë°©ì‹ ìˆ˜ì •\n\n### ê¸°ì¡´ ì½”ë“œ ìˆ˜ì •\n\nì´ì „ì— í† í° ë°œí–‰ apië¥¼ ì§ì ‘ ì‘ì„±í–ˆëŠ”ë°, ì¢€ ë” ì•Œì•„ë³´ë‹ˆ, **`fastapi-users`** ì—ì„œ ì œê³µí•˜ëŠ” `login` apiì™€ ë™ì¼í•˜ë‹¤. ë”°ë¼ì„œ í† í° ë°œí–‰ê³¼ ê´€ë ¨í•´ì„œ ì•½ê°„ì˜ ìˆ˜ì •ì„ ì§„í–‰í•œë‹¤.\n\n> #### backend/app/core/config.py\n>\n> í† í° ê²½ë¡œ ìˆ˜ì •\n\n```python\nTOKEN_PREFIX = API_PREFIX + \"/token/login\"\n```\n\n---\n\n`AUTH_BACKEND_NAME` ì¶”ê°€\n\n```python\nAUTH_BACKEND_NAME = config(\n    \"AUTH_BACKEND_NAME\", cast=str, default=f\"{JWT_TOKEN_PREFIX}-jwt\"\n)\n```\n\n> #### backend/app/services/authentication.py\n>\n> í† í° ëª¨ë¸ ì œê±°\n\n```python\n# class token_model(BaseModel):\n#     access_token: str\n#     token_type: str = config.JWT_TOKEN_PREFIX\n>\n#     @classmethod\n#     def from_token(cls, token: str) -> \"token_model\":\n#         return cls(access_token=toke\n```\n\n---\n\n`AUTH_BACKEND_NAME` ì°¸ì¡° ì¶”ê°€\n\n```python\ndef create_backend() -> list[AuthenticationBackend[user.user_create, user.user]]:\n    transport = create_transport()\n    return [\n        AuthenticationBackend(\n            name=config.AUTH_BACKEND_NAME,\n            transport=transport,\n            get_strategy=create_strategy,\n        )\n    ]\n```\n\n> #### backend/app/api/routes/token.py\n>\n> **`fastapi-users`** ë¼ìš°í„° ì¶”ê°€\n> í¸ì˜ìƒ ë‹¹ë¶„ê°„ `requires_verification=False`ë¡œ í•œë‹¤.\n\n```python\n# name: auth:{backend.name}.login\nrouter.include_router(\n    fastapi_user.users.get_auth_router(\n        fastapi_user.backends[0], requires_verification=False\n    )\n)\n```\n\n---\n\nê¸°ì¡´ api ì œê±°\n\n```python\n# @router.post(\"\", name=\"users:create-token\")\n# async def create_token(\n#     credentials: OAuth2PasswordRequestForm = Depends(),\n#     user_manager: user_manager_type = fastapi_user.user_manager_depends,\n#     strategy: strategy_type = fastapi_user.strategy_depends(),\n# ) -> token_model:\n#     get_user = await user_manager.authenticate(credentials)\n#     if get_user is None or not get_user.is_active:\n#         raise HTTPException(\n#             status_code=status.HTTP_400_BAD_REQUEST,\n#             detail=ErrorCode.LOGIN_BAD_CREDENTIALS,\n#         )\n#     if not get_user.is_verified:\n#         raise HTTPException(\n#             status_code=status.HTTP_400_BAD_REQUEST,\n#             detail=ErrorCode.LOGIN_USER_NOT_VERIFIED,\n#         )\n>\n#     token = await strategy.write_token(get_user)\n#     return token_model.from_token(token)\n```\n\n> #### backend/tests/test_users.py\n>\n> `api_name` ìˆ˜ì •\n\n```python\nclass TestAuthTokens:\n    api_name = f\"auth:{config.AUTH_BACKEND_NAME}.login\"\n```\n\n### **`fastapi-users`** ê°€ ì œê³µí•˜ëŠ” `api`ì˜ ê²€ì¦ ë°©ì‹\n\n> í˜„ì¬ ì‚¬ìš©ì¤‘ì¸ **`fastapi-users`** ì˜ ë²„ì „ì€ `9.3.1`ì´ë¼ëŠ” ê²ƒì— ìœ ì˜í•œë‹¤.\n\nìš°ì„  ì´ë©”ì¼ì„ ê¸°ì¤€ìœ¼ë¡œ ìœ ì €ë¥¼ ì¡°íšŒ í•œ ë‹¤ìŒ, ë¹„ë°€ë²ˆí˜¸ë¥¼ ê²€ì¦í•œë‹¤.\nê·¸ë¦¬ê³  í•´ë‹¹ ìœ ì € ë ˆì½”ë“œì˜ `is_active`ê°€ `True`ì¸ì§€ í™•ì¸í•˜ê³ , `requires_verification` ê°’ì— ë”°ë¼ `is_verified`ê°€ `True`ì¸ì§€ í™•ì¸í•œë‹¤.\n\nìœ ì €ê°€ ì¡´ì¬í•˜ì§€ ì•Šê±°ë‚˜, `is_active=False`ì´ê±°ë‚˜, `requires_verification=True`ì´ë©´ì„œ `is_verified=False`ì¸ ê²½ìš° ì—ëŸ¬(400)ì„ ë°˜í™˜í•œë‹¤.\n\n## `TDD` ë°©ë²•ë¡ ì— ë”°ë¥¸ ë¡œê·¸ì¸ `api`\n\n### ì¼ë°˜ì ì¸ ë¡œê·¸ì¸ ë°©ì‹\n\n| ì‚¬ìš©ì                             | í”„ë¡ íŠ¸ì—”ë“œ                                    | ë°±ì—”ë“œ                         |\n| ---------------------------------- | --------------------------------------------- | ------------------------------ |\n| `name`, `password` ì…ë ¥            |                                               |                                |\n|                                    | `name`, `password` ë°±ì—”ë“œë¡œ ì „ì†¡              |                                |\n|                                    |                                               | `name`, `password` ìœ íš¨ì„± ê²€ì‚¬ |\n|                                    |                                               | í† í° ìƒì„±                      |\n|                                    |                                               | í† í° í”„ë¡ íŠ¸ì—”ë“œë¡œ ì „ì†¡         |\n|                                    | í† í° ì„ì‹œ ì €ì¥                                |\n| ë¡œê·¸ì¸ì´ í•„ìš”í•œ íŠ¹ì • í˜ì´ì§€ë¡œ ì´ë™ |                                               |                                |\n|                                    | ì €ì¥ëœ í† í°(Authorization í—¤ë”) ë°±ì—”ë“œë¡œ ì „ì†¡ |                                |\n|                                    |                                               | í† í° ìœ íš¨ì„± ê²€ì‚¬               |\n|                                    |                                               | ì»¨í…ì¸  ì „ì†¡                    |\n| ...                                | ...                                           | ...                            |\n\n### ë¡œê·¸ì¸ í…ŒìŠ¤íŠ¸ ì½”ë“œ ì‘ì„±\n\n```python\n# backend/tests/test_users.py\nfrom app.services.authentication import UserManager\nfrom fastapi_users.db import SQLAlchemyUserDatabase\n(...)\n\nclass TestUserLogin:\n    api_name = \"users:login-email-and-password\"\n\n    async def test_user_can_login_successfully_and_receives_valid_token(\n        self,\n        app: FastAPI,\n        client: AsyncClient,\n        test_user: user.user_model,\n        strategy: JWTStrategy,\n        engine: AsyncEngine,\n    ) -> None:\n        client.headers[\"content-type\"] = \"application/x-www-form-urlencoded\"\n        login_data = {\"email\": test_user.email, \"password\": \"heatcavslakers@1\"}\n        res = await client.post(app.url_path_for(self.api_name), data=login_data)\n        assert res.status_code == status.HTTP_200_OK\n        # check that token exists in response and has user encoded within it\n        token = res.json().get(\"access_token\")\n\n        async with AsyncSession(engine, autocommit=False) as session:\n            db = SQLAlchemyUserDatabase(user.user, session, user.user_model)  # type: ignore\n            manager = UserManager(db)\n\n            read_user: user.user_model | None = await strategy.read_token(\n                token, manager\n            )\n        assert read_user is not None\n        assert read_user.name == test_user.name\n        assert read_user.email == test_user.email\n        # check that token is proper type\n        assert \"token_type\" in res.json()\n        assert res.json().get(\"token_type\") == \"bearer\"\n\n    @pytest.mark.parametrize(\n        \"credential, wrong_value, status_code\",\n        (\n            (\"email\", \"wrong@email.com\", 401),\n            (\"email\", None, 401),\n            (\"email\", \"notemail\", 401),\n            (\"password\", \"wrongpassword@1\", 401),\n            (\"password\", None, 401),\n        ),\n    )\n    async def test_user_with_wrong_creds_doesnt_receive_token(\n        self,\n        app: FastAPI,\n        client: AsyncClient,\n        test_user: user.user_model,\n        credential: str,\n        wrong_value: str,\n        status_code: int,\n    ) -> None:\n        client.headers[\"content-type\"] = \"application/x-www-form-urlencoded\"\n        user_data = test_user.dict()\n        user_data[\"password\"] = \"heatcavslakers@1\"\n        user_data[credential] = wrong_value\n        login_data = {\n            \"username\": user_data[\"email\"],\n            \"password\": user_data[\"password\"],  # insert password from parameters\n        }\n        res = await client.post(app.url_path_for(self.api_name), data=login_data)\n        assert res.status_code == status_code\n        assert \"access_token\" not in res.json()\n```\n\nì‚¬ìš©ìê°€ `email`ê³¼ `password`ë¥¼ ì˜¬ë°”ë¥´ê²Œ ë³´ëƒˆì„ ë•Œ ì–»ê²Œ ë˜ëŠ” í† í°ìœ¼ë¡œ ë¶€í„°, **`fastapi_users`** ë¥¼ ì´ìš©í•´ì„œ ë¶ˆëŸ¬ì˜¨ ìœ ì € ë ˆì½”ë“œê°€ `test_user`ì™€ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸í•œë‹¤.\n\nì—¬ê¸°ì„œ ë¡œê·¸ì¸ì˜ ê²½ìš° `json` íŒŒë¼ë¯¸í„°ê°€ ì•„ë‹Œ `data` íŒŒë¼ë¯¸í„°ë¡œ ë°ì´í„°ë¥¼ ì „ì†¡í•˜ê³ , `content-type` í—¤ë”ë¡œ `application/x-www-form-urlencoded`ë¥¼ ê°€ì§€ê³  ìˆì–´ì•¼ í•œë‹¤ëŠ” ì ì— ìœ ì˜í•œë‹¤.\n\n### ë¡œê·¸ì¸ `api` ì‘ì„±\n\ní† í° ë°œí–‰ apiê°€ ë¡œê·¸ì¸ apiì´ë¯€ë¡œ, ë”°ë¡œ ì‘ì„±í•  í•„ìš”ê°€ ì—†ë‹¤.\në§Œì•½ 400ì—ëŸ¬ê°€ ì•„ë‹Œ 401ì—ëŸ¬ë¥¼ ë°˜í™˜í•˜ê³  ì‹¶ë‹¤ë©´, ì´ì „ ì±•í„°ì²˜ëŸ¼ ì§ì ‘ ì‘ì„±í•˜ë©´ ëœë‹¤.\n\n### ì¸ì¦ `Depends` ìƒì„±\n\nì´ì œ í† í°ì„ ë°œê¸‰ë°›ì€ ê²½ìš°ì—ë§Œ ì‚¬ìš©ì´ ê°€ëŠ¥í•œ apiì— ëŒ€í•œ ì¸ì¦ ì ˆì°¨ë¥¼ ì •ì˜í•´ì•¼í•œë‹¤. **`fastapi`** ì—ì„œëŠ” ì´ëŸ¬í•œ ê¸°ëŠ¥ì€ `Depends`ë¥¼ ì‚¬ìš©í•´ì„œ ìƒì„±í•  ìˆ˜ ìˆë‹¤. ë˜í•œ, **`fastapi-users`** ì—ì„œ ê´€ë ¨ëœ í•¨ìˆ˜ë¥¼ ì´ë¯¸ ë§Œë“¤ì–´ì„œ ì œê³µí•˜ê³  ìˆë‹¤. ìš°ì„  í…ŒìŠ¤íŠ¸ ì½”ë“œë¶€í„° ì‘ì„±í•œë‹¤.\n\n```python\n# backend/tests/conftest.py\nfrom app.services.authentication import create_strategy\nfrom sqlmodel import select\n\n(...)\n\n@pytest.fixture\nasync def authorized_client(\n    client: AsyncClient, test_user: user.user_model\n) -> AsyncClient:\n    from app.core import config\n\n    strategy = create_strategy()\n    access_token = await strategy.write_token(user=test_user)  # type: ignore\n\n    client.headers[\"Authorization\"] = f\"{config.JWT_TOKEN_PREFIX} {access_token}\"\n    return client\n```\n\në°©ê¸ˆ ì‘ì„±í•œ `authorized_client`ë¥¼ ì´ìš©í•´ì„œ ì¸ì¦ì´ í•„ìš”í•œ ë¼ìš°í„°ì— ì ‘ê·¼ì´ ê°€ëŠ¥í•˜ë‹¤.\n\n> ì“°ë‹¤ë³´ë‹ˆ `user.user`ì™€ `user.user_model`ì´ ë”°ë¡œ ìˆëŠ”ê²Œ ë„ˆë¬´ ë¶ˆí¸í•œë°, ì–¸ì œ í•œë²ˆ í•©ì¹˜ëŠ” ì‹œë„ë¥¼ í•´ë´ì•¼ í• ë“¯. `AsyncSession` ê´€ë ¨í•´ì„œë„ ì–¸ì œí•œë²ˆ í•´ê²°ì„ í•´ì•¼í•  ê²ƒ ê°™ê³ ..\n\n```python\n# backend/tests/test_users.py\n(...)\n\nclass TestUserMe:\n    api_name = \"users:get-current-user\"\n\n    async def test_authenticated_user_can_retrieve_own_data(\n        self,\n        app: FastAPI,\n        authorized_client: AsyncClient,\n        test_user: user.user_model,\n    ) -> None:\n        res = await authorized_client.get(app.url_path_for(self.api_name))\n        assert res.status_code == status.HTTP_200_OK\n        res_dict: dict = res.json()\n        res_dict[\"hashed_password\"] = \"testpassword@1\"\n        read_user = user.user_model.validate(res_dict)\n        assert read_user.email == test_user.email\n        assert read_user.name == test_user.name\n        assert read_user.id == test_user.id\n\n    async def test_user_cannot_access_own_data_if_not_authenticated(\n        self,\n        app: FastAPI,\n        client: AsyncClient,\n        test_user: user.user_model,\n    ) -> None:\n        res = await client.get(app.url_path_for(\"users:get-current-user\"))\n        assert res.status_code == status.HTTP_401_UNAUTHORIZED\n\n    @pytest.mark.parametrize(\n        \"jwt_prefix\",\n        (\n            (\"\",),\n            (\"value\",),\n            (\"Token\",),\n            (\"JWT\",),\n            (\"Swearer\",),\n        ),\n    )\n    async def test_user_cannot_access_own_data_with_incorrect_jwt_prefix(\n        self,\n        app: FastAPI,\n        client: AsyncClient,\n        test_user: user.user_model,\n        strategy: JWTStrategy,\n        jwt_prefix: str,\n    ) -> None:\n        token = await strategy.write_token(test_user)\n        res = await client.get(\n            app.url_path_for(\"users:get-current-user\"),\n            headers={\"Authorization\": f\"{jwt_prefix} {token}\"},\n        )\n        assert res.status_code == status.HTTP_401_UNAUTHORIZED\n```\n\nìœ„ í…ŒìŠ¤íŠ¸ë¥¼ í†µê³¼í•  ìˆ˜ ìˆëŠ” apië¥¼ ì‘ì„±í•œë‹¤.\n\n```python\nfrom fastapi import Depends\n\n(...)\n\nget_current_user = fastapi_user.users.current_user(\n    optional=False, active=True, verified=False, superuser=False\n)\n\n(...)\n\n@router.get(\"/me\", response_model=user.user_read, name=\"users:get-current-user\")\nasync def get_currently_authenticated_user(\n    current_user: user.user = Depends(get_current_user),\n) -> user.user_model:\n    return current_user.to_model()\n```\n\n`optional=False, active=True, verified=False, superuser=False`ìœ¼ë¡œ ê°’ì„ ì§€ì •í–ˆê¸°ì—, í•´ë‹¹ í•¨ìˆ˜ëŠ” ì¼ì¹˜í•˜ëŠ” ìœ ì €ê°€ ì—†ê±°ë‚˜ `is_active` ê°’ì´ `False`ì´ë©´ ì—ëŸ¬(401)ì„ ë°˜í™˜í•œë‹¤.\n\ní…ŒìŠ¤íŠ¸ í†µê³¼ë„ ì˜ë˜ê³ , **`swagger`** ì—ì„œë„ í™•ì¸ì´ ê°„ë‹¨í•œ apiê°€ ìƒì„±ëë‹¤. ìœ ì € ì¸ì¦ ê´€ë ¨í•´ì„œëŠ” ì‚¬ì‹¤ìƒ ì´ê²Œ ëì´ë‹¤. ì½”ë“œë¥¼ ì¡°ê¸ˆ ë” ì •ë¦¬í•  ìˆ˜ëŠ” ìˆì§€ë§Œ í•µì‹¬ì€ ë¹„ìŠ·í•  ê²ƒì´ë‹¤.\n\në‹¤ìŒ ì±•í„°ì—ì„œëŠ” ìœ ì € í”„ë¡œí•„ì„ ì„¤ì •í•œë‹¤.\nê·¸ ì „ì— ì•ì—ì„œ ì–¸ê¸‰í•œ ìœ ì € ëª¨ë¸ê³¼ ê´€ë ¨ëœ ìˆ˜ì •ì„ ì§„í–‰í•  ìˆ˜ë„ ìˆë‹¤.\n","mtime":"2022-08-13T00:12:20.000+09:00","href":"velog/fastapi íŠœí† ë¦¬ì–¼ -8- FastAPI Usersë¥¼ ì‚¬ìš©í•œ ìœ ì € api ìƒì„± 3","data":{"title":"fastapi íŠœí† ë¦¬ì–¼ -8- FastAPI Usersë¥¼ ì‚¬ìš©í•œ ìœ ì € api ìƒì„± 3","date":"2022-05-06T06:26:51.932+09:00","tags":["fastapi","fastapi-users","python","@all"],"page":"fastapi íŠœí† ë¦¬ì–¼","summary":"fastapi ì‚¬ìš©ë²•ì„ ë‹¤ì‹œ ê³µë¶€í• ê²¸, ì°¸ê³ í• ë§Œí•œ ì¢‹ì€ ì˜ˆì œê°€ ìˆì–´ì„œ ì´ ì‹œë¦¬ì¦ˆë¥¼ ì•½ê°„ì˜ ë³€ê²½ì„ ì£¼ê³  ë”°ë¼ê°€ë³´ë ¤ í•œë‹¤."}},{"name":"fastapi íŠœí† ë¦¬ì–¼ -8.1- SQLModel AsyncSession ê´€ë ¨ íƒ€ì… ë¬¸ì œ ì„ì‹œ í•´ê²° + ì¶”ê°€ ìˆ˜ì •","content":"\n**`fastapi`** ì‚¬ìš©ë²•ì„ ë‹¤ì‹œ ê³µë¶€í• ê²¸, ì°¸ê³ í• ë§Œí•œ ì¢‹ì€ [ì˜ˆì œ](https://www.jeffastor.com/blog/populating-cleaning-jobs-with-user-offers-in-fastapi)ê°€ ìˆì–´ì„œ ì´ ì‹œë¦¬ì¦ˆë¥¼ ì•½ê°„ì˜ ë³€ê²½ì„ ì£¼ê³  ë”°ë¼ê°€ë³´ë ¤ í•œë‹¤.\nì§€ë‚œë²ˆì²˜ëŸ¼ ì–´ì©Œë‹¤ ê·¸ë§Œë‘˜ ìˆ˜ë„ ìˆê¸´ í•˜ì§€ë§Œ...\n\n---\n\n## `Session`ì˜ ì½”ë“œë¥¼ ê·¸ëŒ€ë¡œ ë³µë¶™\n\nì´ì „ê¹Œì§€ ê¸€ì—ì„œ ê³„ì†í•´ì„œ `AsyncSession`ì˜ íƒ€ì… ê´€ë ¨ ë¬¸ì œê°€ ë°œìƒí•˜ëŠ”ê²Œ ë„ˆë¬´ ì§œì¦ë‚˜ì„œ, ì„ì‹œë¡œ ë•œë¹µìš© í´ë˜ìŠ¤ë¥¼ ìƒì„±í•´ì„œ ì‚¬ìš©í•˜ê¸°ë¡œ í–ˆë‹¤.\n\n````python\n# backend/app/db/session.py\n(...)\n\n_TSelectParam = TypeVar(\"_TSelectParam\")\n\nclass async_session(AsyncSession):\n    # sqlmodel.orm.session.Session\n    @overload\n    async def exec(\n        self,\n        statement: Select[_TSelectParam],\n        *,\n        params: Optional[Union[Mapping[str, Any], Sequence[Mapping[str, Any]]]] = None,\n        execution_options: Mapping[str, Any] = util.EMPTY_DICT,\n        bind_arguments: Optional[Mapping[str, Any]] = None,\n        _parent_execute_state: Optional[Any] = None,\n        _add_event: Optional[Any] = None,\n        **kw: Any,\n    ) -> Result[_TSelectParam]:\n        ...\n\n    @overload\n    async def exec(\n        self,\n        statement: SelectOfScalar[_TSelectParam],\n        *,\n        params: Optional[Union[Mapping[str, Any], Sequence[Mapping[str, Any]]]] = None,\n        execution_options: Mapping[str, Any] = util.EMPTY_DICT,\n        bind_arguments: Optional[Mapping[str, Any]] = None,\n        _parent_execute_state: Optional[Any] = None,\n        _add_event: Optional[Any] = None,\n        **kw: Any,\n    ) -> ScalarResult[_TSelectParam]:\n        ...\n\n    async def exec(\n        self,\n        statement: Union[\n            Select[_TSelectParam],\n            SelectOfScalar[_TSelectParam],\n            Executable[_TSelectParam],\n        ],\n        *,\n        params: Optional[Union[Mapping[str, Any], Sequence[Mapping[str, Any]]]] = None,\n        execution_options: Mapping[str, Any] = util.EMPTY_DICT,\n        bind_arguments: Optional[Mapping[str, Any]] = None,\n        _parent_execute_state: Optional[Any] = None,\n        _add_event: Optional[Any] = None,\n        **kw: Any,\n    ) -> Union[Result[_TSelectParam], ScalarResult[_TSelectParam]]:\n        \"\"\"\n        sqlmodel.orm.session.Session\n        \"\"\"\n        return await super().exec(\n            statement,  # type: ignore\n            params=params,\n            execution_options=execution_options,\n            bind_arguments=bind_arguments,\n            _parent_execute_state=_parent_execute_state,\n            _add_event=_add_event,\n            **kw,\n        )\n\n    async def execute(\n        self,\n        statement: _Executable,\n        params: Optional[Union[Mapping[str, Any], Sequence[Mapping[str, Any]]]] = None,\n        execution_options: Optional[Mapping[str, Any]] = util.EMPTY_DICT,\n        bind_arguments: Optional[Mapping[str, Any]] = None,\n        _parent_execute_state: Optional[Any] = None,\n        _add_event: Optional[Any] = None,\n        **kw: Any,\n    ) -> Result[Any]:\n        \"\"\"\n        sqlmodel.orm.session.Session\n        ***\n\n        ğŸš¨ You probably want to use `session.exec()` instead of `session.execute()`.\n\n        This is the original SQLAlchemy `session.execute()` method that returns objects\n        of type `Row`, and that you have to call `scalars()` to get the model objects.\n\n        For example:\n\n        ```Python\n        heroes = session.execute(select(Hero)).scalars().all()\n        ```\n\n        instead you could use `exec()`:\n\n        ```Python\n        heroes = session.exec(select(Hero)).all()\n        ```\n        \"\"\"\n        return await super().execute(  # type: ignore\n            statement,\n            params=params,\n            execution_options=execution_options,\n            bind_arguments=bind_arguments,\n            _parent_execute_state=_parent_execute_state,\n            _add_event=_add_event,\n            **kw,\n        )\n\n    async def get(\n        self,\n        entity: Type[_TSelectParam],\n        ident: Any,\n        options: Optional[Sequence[Any]] = None,\n        populate_existing: bool = False,\n        with_for_update: Optional[Union[Literal[True], Mapping[str, Any]]] = None,\n        identity_token: Optional[Any] = None,\n    ) -> Optional[_TSelectParam]:\n        \"\"\"\n        sqlmodel.orm.session.Session\n        \"\"\"\n        return await super().get(\n            entity,\n            ident,\n            options=options,\n            populate_existing=populate_existing,\n            with_for_update=with_for_update,\n            identity_token=identity_token,\n        )\n````\n\nì£¼ì„ì„ ë³´ë©´ ì•Œê² ì§€ë§Œ, ê·¸ëƒ¥ `sqlmodel.orm.session.Session` ê°ì²´ì˜ ê° ë©”ì†Œë“œì˜ íƒ€ì… íŒíŠ¸ë¥¼ ê·¸ëŒ€ë¡œ ê°€ì ¸ì™”ë‹¤. ì´ì— ë§ì¶°ì„œ ë‹¤ë¥¸ ìŠ¤í¬ë¦½íŠ¸ì˜ `AsyncSession`ë„ ëª¨ë‘ `async_session`ì— ëŒ€í•œ ìŠ¤í¬ë¦½íŠ¸ë¡œ ë³€í™˜í•´ì¤€ë‹¤. ê·¸ë¦¬ê³  í…ŒìŠ¤íŠ¸ ì½”ë“œë¥¼ ì‹¤í–‰í•´ë³´ë©´ ë¬¸ì œì—†ì´ ì‹¤í–‰ë˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.\n\n---\n\n## `datetime_model` ê´€ë ¨ ë¬¸ì œ í•´ê²°\n\n`datetime_model`ì˜ `datetime_attrs` ì†ì„±ì´ ì˜ë„í•œëŒ€ë¡œ ì¶œë ¤ë˜ì§€ ì•ŠëŠ” ë¬¸ì œê°€ ìˆì–´ì„œ ì¶”ê°€ë¡œ ìˆ˜ì •í–ˆë‹¤. `cls.__fields__.keys()` ë¥¼ `datetime_model.__fields__.keys()`ë¡œ ìˆ˜ì •í•œ ê²ƒì™¸ì— ëª¨ë‘ ë™ì¼í•˜ë‹¤.\n\n```python\n# backend/app/models/core.py\n(...)\n\nclass datetime_model(fix_return_type_model):\n    created_at: datetime = Field(default_factory=datetime.now)\n    updated_at: datetime = Field(default_factory=datetime.now)\n\n    def update(self: _D) -> _D:\n        self.updated_at = datetime.now()\n        return self\n\n    @classmethod\n    @property\n    def datetime_attrs(cls) -> set[str]:\n        return set(datetime_model.__fields__.keys())\n```\n\n## `id_model` ì„¸ë¶„í™”\n\nê¸°ì¡´ì— ì‚¬ìš©í•˜ë˜ `id_model`ì„ `int_id_model`ê³¼ `uuid_id_model`ë¡œ ì„¸ë¶„í™”í•´ì„œ ì‚¬ìš©í•˜ê¸°ë¡œ í–ˆë‹¤.\n\n```python\n# backend/app/models/core.py\nfrom uuid import uuid4\nfrom pydantic import UUID4\n\n(...)\n\nclass id_model(fix_return_type_model):\n    @classmethod\n    @property\n    def id_type(cls) -> Any:\n        return cls.__fields__[\"id\"].type_\n\n\nclass int_id_model(id_model):\n    id: int | None = Field(None, primary_key=True)\n\n\nclass uuid_id_model(id_model):\n    id: UUID4 | None = Field(default_factory=uuid4, primary_key=True)\n```\n\n## `dependencies` ëª¨ë“ˆ ìƒì„±\n\nê¸°ì¡´ì— ì‚¬ìš©í•˜ë˜ `get_session`ì´ë‚˜ `get_current_user`ê°™ì€ `Depends`ì™€ í•¨ê»˜ ì‚¬ìš©í•˜ë˜ í•¨ìˆ˜ë¥¼ ë”°ë¡œ ê´€ë¦¬í•˜ê¸°ë¡œ í–ˆë‹¤.\n\n```python\n# backend/app/dependencies/database.py\nfrom typing import AsyncIterator\n\nfrom fastapi import Depends, Request\nfrom sqlalchemy.ext.asyncio.engine import AsyncEngine\n\nfrom ..db.session import async_session\n\n\nasync def get_database(request: Request) -> AsyncEngine:\n    if (engine := getattr(request.app.state, \"_db\", None)) is None:\n        raise AttributeError(\"there is no database engine in request as state\")\n    return engine\n\n\nasync def get_session(\n    engine: AsyncEngine = Depends(get_database),\n) -> AsyncIterator[async_session]:\n    async with async_session(engine, autoflush=False, autocommit=False) as session:\n        yield session\n```\n\n```python\n# backend/app/dependencies/auth.py\nfrom ..services.authentication import fastapi_user_class\n\nfastapi_user = fastapi_user_class.init()\n\nget_current_user = fastapi_user.users.current_user(\n    optional=False, active=True, verified=False, superuser=False\n)\nget_user_manager = fastapi_user.get_user_manager\nget_backend = fastapi_user.get_backend\nget_transport = fastapi_user.get_transport\nget_strategy = fastapi_user.get_strategy\n```\n\n```python\n# backend/app/services/authentication/authentication.py\n(...)\n\n@dataclass(frozen=True)\nclass fastapi_user_class:\n    users: fastapi_users_class[user.user, user_id_type]\n    named_backends: dict[str, auth_backend_type] = field(default_factory=dict)\n\n    @classmethod\n    def init(cls) -> \"fastapi_user_class\":\n        users = create_fastapi_users(*create_backend())\n        return cls(users=users)\n\n    @property\n    def backends(self) -> Sequence[auth_backend_type]:\n        return self.users.authenticator.backends  # type: ignore\n\n    @property\n    def get_user_manager(self):\n        return self.users.get_user_manager\n\n    def find_backend(self, _val: str, /) -> auth_backend_type:\n        for backend in self.backends:\n            if backend.name == _val:\n                return backend\n        raise IndexError(f\"there is not auth_backend name: {_val}\")\n\n    def get_backend(self, _val: int | str = 0, /) -> auth_backend_type:\n        if isinstance(_val, int):\n            return self.backends[_val]\n\n        if (backend := self.named_backends.get(_val)) is None:\n            backend = self.named_backends[_val] = self.find_backend(_val)\n        return backend\n\n    def get_transport(self, _val: int | str = 0, /) -> Transport:\n        backend = self.get_backend(_val)\n        return backend.transport\n\n    def get_strategy(self, _val: int | str = 0, /):\n        backend = self.get_backend(_val)\n        return backend.get_strategy\n```\n","mtime":"2022-08-13T00:12:20.000+09:00","href":"velog/fastapi íŠœí† ë¦¬ì–¼ -8.1- SQLModel AsyncSession ê´€ë ¨ íƒ€ì… ë¬¸ì œ ì„ì‹œ í•´ê²° + ì¶”ê°€ ìˆ˜ì •","data":{"title":"fastapi íŠœí† ë¦¬ì–¼ -8.1- SQLModel AsyncSession ê´€ë ¨ íƒ€ì… ë¬¸ì œ ì„ì‹œ í•´ê²° + ì¶”ê°€ ìˆ˜ì •","date":"2022-05-07T22:08:12.781+09:00","tags":["fastapi","python","sqlmodel","@all"],"page":"fastapi íŠœí† ë¦¬ì–¼","summary":"fastapi ì‚¬ìš©ë²•ì„ ë‹¤ì‹œ ê³µë¶€í• ê²¸, ì°¸ê³ í• ë§Œí•œ ì¢‹ì€ ì˜ˆì œê°€ ìˆì–´ì„œ ì´ ì‹œë¦¬ì¦ˆë¥¼ ì•½ê°„ì˜ ë³€ê²½ì„ ì£¼ê³  ë”°ë¼ê°€ë³´ë ¤ í•œë‹¤."}},{"name":"fastapi íŠœí† ë¦¬ì–¼ -8.2- FastAPI Users v10 ëŒ€ì‘","content":"\n**`fastapi`** ì‚¬ìš©ë²•ì„ ë‹¤ì‹œ ê³µë¶€í• ê²¸, ì°¸ê³ í• ë§Œí•œ ì¢‹ì€ [ì˜ˆì œ](https://www.jeffastor.com/blog/populating-cleaning-jobs-with-user-offers-in-fastapi)ê°€ ìˆì–´ì„œ ì´ ì‹œë¦¬ì¦ˆë¥¼ ì•½ê°„ì˜ ë³€ê²½ì„ ì£¼ê³  ë”°ë¼ê°€ë³´ë ¤ í•œë‹¤.\nì§€ë‚œë²ˆì²˜ëŸ¼ ì–´ì©Œë‹¤ ê·¸ë§Œë‘˜ ìˆ˜ë„ ìˆê¸´ í•˜ì§€ë§Œ...\n\n---\n\n## `Breaking` `changes`\n\nì´í‹€ì „ **`fastapi-users`** ì— í° ë³€í™”ê°€ ìƒê²¼ë‹¤. `v10` ë¦´ë¦¬ì¦ˆê°€ ê³µê°œëëŠ”ë°, `db` ëª¨ë¸ê³¼ ì—¬ëŸ¬ ì œë„¤ë¦­ íƒ€ì…ì— ëŒ€í•œ ë³€í™”ê°€ ìƒê²¨ì„œ, `v10`ì„ ì´ìš©í•˜ë ¤ë©´ ëŒ€ì‘ íŒ¨ì¹˜ê°€ í•„ìˆ˜ì ì¸ ìƒí™©..\n\nì•„ë˜ëŠ” í•´ë‹¹ ë¦´ë¦¬ì¦ˆì— ëŒ€í•œ ì „ë¬¸ì´ë‹¤.\n\n> ### [Breaking changes](https://github.com/fastapi-users/fastapi-users/releases/tag/v10.0.0)\n>\n> Version 10 marks important changes in how we manage User models and their ID.\n>\n> Before, we were relying only on Pydantic models to work with users. In particular the current_user dependency would return you an instance of UserDB, a Pydantic model. This proved to be quite problematic with some ORM if you ever needed to retrieve relationship data or make specific requests.\n>\n> Now, FastAPI Users is designed to always return you a native object for your ORM model, whether it's an SQLAlchemy model or a Beanie document. Pydantic models are now only used for validation and serialization inside the API.\n>\n> Before, we were forcing the use of UUID as primary key ID; a consequence of the design above. This proved to be quite problematic on some databases, like MongoDB which uses a special ObjectID format by default. Some SQL folks also prefer to use traditional auto-increment integers.\n>\n> Now, FastAPI Users is designed to use generic ID type. It means that you can use any type you want for your user's ID. By default, SQLAlchemy adapter still use UUID; but you can quite easily switch to another thing, like an integer. Beanie adapter for MongoDB will use native ObjectID by default, but it also can be overriden.\n\n### ìœ ì € ëª¨ë¸ ìƒì„± ë° ìˆ˜ì •\n\nê¸°ì¡´ `fastapi_users.models` ì—ì„œ `fastapi_users.schemas`ë¡œ ë°”ë€ ê²ƒ ì™¸ì— í¬ê²Œ ë‹¬ë¼ì§„ ê²ƒì€ ì—†ë‹¤. ì‚¬ì‹¤ ì´ì „ì— ì–˜ê¸°í–ˆë˜ `user` ì™€ `user_model`ì„ í†µí•©í•˜ëŠ” ì‘ì—…ì„ ì´ë¯¸ í•œ ë‹¤ìŒ `v10` ë¦´ë¦¬ì¦ˆë¥¼ í™•ì¸í–ˆê¸°ì— ë”ìš± ê·¸ë ‡ê²Œ ëŠê»´ì¡Œë‹¤...\n\n```python\n# backend/app/models/user.py\nfrom typing import TypeVar\n\nfrom fastapi_users import schemas\nfrom pydantic import EmailStr\nfrom pydantic import Field as _Field\nfrom sqlmodel import Field, select\n\nfrom ..db.session import async_session\nfrom .core import base_model, datetime_model, uuid_id_model\n\nmin_name_length = 4\nmax_name_length = 20\n\n\n_T = TypeVar(\"_T\", bound=\"user\")\nid_model = uuid_id_model\nuser_id_type = id_model.id_type\n\n\nclass user(id_model, datetime_model, base_model, table=True):\n    __tablename__: str = \"users\"\n\n    name: str = Field(min_length=min_name_length, max_length=max_name_length)\n    hashed_password: str = Field(max_length=2**10)\n    email: EmailStr = Field(index=True)\n    is_active: bool = True\n    is_superuser: bool = False\n    is_verified: bool = False\n\n    @classmethod\n    async def get_from_email(\n        cls: type[_T], session: async_session, email: str\n    ) -> _T | None:\n        is_user_cur = await session.exec(select(cls).where(cls.email == email))\n        return is_user_cur.first()\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.validate(self)\n\n\nclass user_read(schemas.BaseUser[user_id_type], datetime_model):\n    name: str = _Field(min_length=min_name_length, max_length=max_name_length)\n\n\nclass user_create(schemas.BaseUserCreate):\n    name: str = _Field(min_length=min_name_length, max_length=max_name_length)\n\n\nclass user_update(schemas.BaseUserUpdate):\n    name: str = _Field(min_length=min_name_length, max_length=max_name_length)\n```\n\n### ì¸ì¦ ëª¨ë“ˆ ì œë„¤ë¦­ íƒ€ì… ë®ì–´ì”Œìš°ê¸°\n\n**`fastapi-users`** ì—ì„œ ì›í•˜ëŠ” í˜•íƒœëŠ” `SQLAlchemyBaseUserTable`ë¥¼ ìƒì†í•œ í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ì§€ë§Œ, **`sqlmodel`** ë„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ê³  **`fastapi-users`** ì˜ íƒ€ì… íŒíŠ¸ë„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ê³  ì‹¶ê¸°ì—, ë‘ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì—®ì–´ì¤„ ìƒˆë¡œìš´ ì œë„¤ë¦­ í´ë˜ìŠ¤ë¥¼ ìƒì„±í•œë‹¤.\n`# type: ignore`ë¥¼ ë‚¨ë°œí•˜ê¸°ì— ê·¸ë‹¤ì§€ ì¢‹ì€ ëª¨ìŠµì´ë¼ê³  ìƒê°ë˜ì§€ ì•Šì§€ë§Œ, ì´ê±° ì™¸ì— ë‹¹ì¥ ìƒê°ë‚˜ëŠ” ë°©ë²•ì´ ì—†ê¸°ì— ì¼ë‹¨ ë„˜ì–´ê°€ì.\n\n```bash\nâ¯ mkdir backend/app/services/authentication\nâ¯ mv backend/app/services/authentication.py backend/app/services/authentication/authentication.py\nâ¯ touch backend/app/services/authentication/__init__.py backend/app/services/authentication/convert.py\n```\n\n```python\n# backend/app/services/authentication/__init__.py\nfrom .authentication import *\n```\n\n```python\n# backend/app/services/authentication/convert.py\nfrom typing import Generic, TypeVar\n\nfrom fastapi_users import BaseUserManager, FastAPIUsers\nfrom fastapi_users.authentication import AuthenticationBackend, JWTStrategy, Strategy\nfrom fastapi_users.db import SQLAlchemyUserDatabase\n\nfrom ...models.core import base_model\nfrom ...models.user import user\n\nuser_id_type = user.id_type\n_T = TypeVar(\"_T\", bound=base_model)\n_D = TypeVar(\"_D\")\n\n# fmt: off\nclass user_db_class(SQLAlchemyUserDatabase[_T, _D], Generic[_T, _D]): ... # type: ignore\nclass strategy_class(Strategy[_T, _D], Generic[_T, _D]): ... # type: ignore\nclass jwt_strategy_class(JWTStrategy[_T, _D], Generic[_T, _D]): ... # type: ignore\nclass auth_backend_class(AuthenticationBackend[_T, _D], Generic[_T, _D]): ... # type: ignore\nclass user_manager_class(BaseUserManager[_T, _D], Generic[_T, _D]): ...  # type: ignore\nclass fastapi_users_class(FastAPIUsers[_T, _D], Generic[_T, _D]): ...  # type: ignore\n# fmt: on\n\n\nuser_manager_type = user_manager_class[user, user_id_type]\nstrategy_type = strategy_class[user, user_id_type]\n```\n\n### ë³€ê²½ì  ì¸ì¦ ëª¨ë“ˆì— ì ìš©\n\n```python\n# backend/app/services/authentication/authentication.py\nimport re\nfrom dataclasses import dataclass\nfrom re import Pattern\nfrom typing import AsyncGenerator, Sequence\n\nfrom fastapi import Depends, Request\nfrom fastapi_users import IntegerIDMixin, InvalidPasswordException\nfrom fastapi_users.authentication import BearerTransport, Transport\n\nfrom ...core import config\nfrom ...db.session import async_session, get_session\nfrom ...models import user\nfrom .convert import (\n    auth_backend_class,\n    fastapi_users_class,\n    jwt_strategy_class,\n    strategy_class,\n    strategy_type,\n    user_db_class,\n    user_id_type,\n    user_manager_class,\n    user_manager_type,\n)\n\n\nasync def get_user_db(\n    session: async_session = Depends(get_session),\n) -> AsyncGenerator[user_db_class[user.user, user_id_type], None]:\n    yield user_db_class(session, user.user)\n\n\ndef create_transport() -> Transport:\n    return BearerTransport(tokenUrl=config.TOKEN_PREFIX)\n\n\ndef create_strategy() -> strategy_class[user.user, user_id_type]:\n    return jwt_strategy_class(  # type: ignore\n        secret=str(config.SECRET_KEY),\n        lifetime_seconds=config.ACCESS_TOKEN_EXPIRE_SECONDS,\n        token_audience=[config.JWT_AUDIENCE],\n        algorithm=config.JWT_ALGORITHM,\n    )\n\n\ndef create_backend() -> list[auth_backend_class[user.user, user_id_type]]:\n    transport = create_transport()\n    return [\n        auth_backend_class(\n            name=config.AUTH_BACKEND_NAME,\n            transport=transport,\n            get_strategy=create_strategy,\n        )\n    ]\n\n\nclass UserManager(IntegerIDMixin, user_manager_class[user.user, user_id_type]):\n    reset_password_token_secret = str(config.SECRET_KEY)\n    verification_token_secret = str(config.SECRET_KEY)\n\n    min_password_length: int = 10\n    max_password_length: int = 30\n    re_password_need_list: list[Pattern] = [\n        re.compile(r\"[a-zA-Z]\"),\n        re.compile(r\"[0-9]\"),\n        re.compile(r\"[\\{\\}\\[\\]\\/?.,;:|\\)*~`!^\\-_+<>@\\#$%&\\\\\\=\\(\\'\\\"]\"),\n    ]\n    re_password_deny_list: list[Pattern] = []\n\n    async def validate_password(\n        self, password: str, user: user.user_create | user.user\n    ) -> None:\n        if len(password) < self.min_password_length:\n            raise InvalidPasswordException(\n                reason=f\"Password should be at least {self.min_password_length} characters\"\n            )\n        elif len(password) > self.max_password_length:\n            raise InvalidPasswordException(\n                reason=f\"Password should be at most {self.max_password_length} characters\"\n            )\n\n        for pattern in self.re_password_deny_list:\n            if pattern.search(password):\n                raise InvalidPasswordException(\n                    reason=f\"Password should not include {pattern.pattern}\"\n                )\n\n        for pattern in self.re_password_need_list:\n            if not pattern.search(password):\n                raise InvalidPasswordException(\n                    reason=f\"Password must include {pattern.pattern}\"\n                )\n\n    async def on_after_register(self, user: user.user, request: Request | None = None):\n        print(f\"User {user.id} has registered.\")\n\n    async def on_after_forgot_password(\n        self, user: user.user, token: str, request: Request | None = None\n    ):\n        print(f\"User {user.id} has forgot their password. Reset token: {token}\")\n\n    async def on_after_request_verify(\n        self, user: user.user, token: str, request: Request | None = None\n    ):\n        print(f\"Verification requested for user {user.id}. Verification token: {token}\")\n\n\nasync def get_user_manager(\n    user_db=Depends(get_user_db),\n) -> AsyncGenerator[UserManager, None]:\n    yield UserManager(user_db)\n\n\ndef create_fastapi_users(\n    *backends: auth_backend_class[user.user, user_id_type],\n) -> fastapi_users_class[user.user, user_id_type]:\n    return fastapi_users_class(\n        get_user_manager=get_user_manager, auth_backends=backends\n    )\n\n\n@dataclass(frozen=True)\nclass fastapi_user_class:\n    users: fastapi_users_class[user.user, user_id_type]\n\n    @classmethod\n    def init(cls) -> \"fastapi_user_class\":\n        users = create_fastapi_users(*create_backend())\n        return cls(users=users)\n\n    @property\n    def backends(self) -> Sequence[auth_backend_class[user.user, user_id_type]]:\n        return self.users.authenticator.backends  # type: ignore\n\n    @property\n    def user_manager_depends(self) -> user_manager_type:\n        return Depends(self.users.get_user_manager)\n\n    def strategy_depends(self, num: int = 0, /) -> strategy_type:\n        backend = self.backends[num]\n        return Depends(backend.get_strategy)\n```\n\nê½¤ ë§ì´ ë°”ë€Œê¸´ í–ˆì§€ë§Œ, ì‹¤ì œë¡œ ì‚¬ìš©í• ë•ŒëŠ” ì´ë¦„ì •ë„ë§Œ ë°”ë€Œì§€ ì‚¬ìš©ë²• ìì²´ëŠ” ë³€í•œê²Œ ì—†ë‹¤. ë°”ë€ ì´ë¦„ì— ë§ì¶°ì„œ ë¼ìš°í„°ì™€ í…ŒìŠ¤íŠ¸ ì½”ë“œë¥¼ ìˆ˜ì •í•´ì£¼ë©´, ì •ìƒì ìœ¼ë¡œ ì‘ë™í•˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.\n\nì´ë²ˆ ê¸°íšŒì— í…ŒìŠ¤íŠ¸ ì½”ë“œê°€ ì–¼ë§ˆë‚˜ ì¢‹ì€ê±´ì§€ ì•Œê²Œëë‹¤.. ê¸´ê°€ë¯¼ê°€í• ë•Œ `pytest --tb=short` í•œë°©ì´ë©´ ì˜ë¬¸ì´ í•´ê²°ëœë‹¤.\n\nì‚¬ì‹¤ ë³€ê²½í• ê²Œ í•˜ë‚˜ ë” ë‚¨ê¸´ í–ˆì§€ë§Œ, ì´ê±° ì•„ì§ ì‹œë„í•´ë³´ì§€ ì•Šì•˜ë‹¤.\ní˜„ì¬ í—¤ë”ë¥¼ ì‚¬ìš©í•œ ì¸ì¦ ë°©ì‹ì¸ë°, ì¿ í‚¤ë¥¼ ì‚¬ìš©í•˜ê³ , `access-token`ê³¼ `refresh-token`ì„ ì‚¬ìš©í•œ ë°©ì‹ìœ¼ë¡œ ë³€ê²½í•´ë³´ë ¤ í•œë‹¤. ë‹¤ë§Œ **`fastapi-users`** ìì²´ì ìœ¼ë¡œëŠ” ì§€ì›í•˜ì§€ ì•Šê¸°ì—, ì§ì ‘ ì‘ì„±í•  í•„ìš”ê°€ ìˆì–´ì„œ ì•½ê°„ ê³ ë¯¼ì´ í•„ìš”í• ë“¯.\n","mtime":"2022-08-13T00:12:20.000+09:00","href":"velog/fastapi íŠœí† ë¦¬ì–¼ -8.2- FastAPI Users v10 ëŒ€ì‘","data":{"title":"fastapi íŠœí† ë¦¬ì–¼ -8.2- FastAPI Users v10 ëŒ€ì‘","date":"2022-05-07T23:00:58.369+09:00","tags":["fastapi","fastapi-users","python","sqlmodel","@all"],"page":"fastapi íŠœí† ë¦¬ì–¼","summary":"fastapi ì‚¬ìš©ë²•ì„ ë‹¤ì‹œ ê³µë¶€í• ê²¸, ì°¸ê³ í• ë§Œí•œ ì¢‹ì€ ì˜ˆì œê°€ ìˆì–´ì„œ ì´ ì‹œë¦¬ì¦ˆë¥¼ ì•½ê°„ì˜ ë³€ê²½ì„ ì£¼ê³  ë”°ë¼ê°€ë³´ë ¤ í•œë‹¤."}}]},"__N_SSG":true}